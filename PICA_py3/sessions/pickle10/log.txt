[DEBUG][2021-08-28 04:21:03]	TFboard files will be stored in sessions/pickle10/tfboard if applicable
[DEBUG][2021-08-28 04:21:03]	Provided arguments will be stored in sessions/pickle10/config.yaml
[INFO][2021-08-28 04:21:03]	Start to declare training variable
[INFO][2021-08-28 04:21:03]	Session will be ran in device: [cuda]
[INFO][2021-08-28 04:21:03]	Start to prepare data
[INFO][2021-08-28 04:21:04]	otrainset----------------------: length 20000
[INFO][2021-08-28 04:21:05]	ptrainset----------------------: length 20000
[INFO][2021-08-28 04:21:06]	testset-------------: length 5000
[INFO][2021-08-28 04:21:06]	Start to build model
[DEBUG][2021-08-28 04:21:06]	Backbone [resnet34] is declared with cin [1] and cout [1000] [with] sobel
[DEBUG][2021-08-28 04:21:06]	Backbone will be created wit the following heads: [14, 10]
[DEBUG][2021-08-28 04:21:06]	Number of trainable parameters is [112]
[DEBUG][2021-08-28 04:21:06]	Number of frozen parameters is [2]
[DEBUG][2021-08-28 04:21:06]	Name of frozen parameters are: dict_keys(['sobel.0.weight', 'sobel.0.bias'])
[DEBUG][2021-08-28 04:21:06]	Going to use [Adam] optimizer for training with betas (0.9, 0.999), eps 0.000000, weight decay 0.000000 without amsgrad
[DEBUG][2021-08-28 04:21:06]	Going to use [fixed] learning policy for optimization with base learning rate [0.00001]
[INFO][2021-08-28 04:21:06]	Data parallel will be used for acceleration purpose
[INFO][2021-08-28 04:21:06]	Start to train at 0 epoch with learning rate 0.000010
[INFO][2021-08-28 04:21:06]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-28 04:21:06]	hidx, head: 0, 14
[INFO][2021-08-28 04:21:06]	hidx, head: 1, 10
[INFO][2021-08-28 04:21:06]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-28 04:21:34]	Batch: [  0/313] Head: [0/2] Epoch: [  0/350] Progress: [0:00:27/2:22:56] Time: 27.399 (27.399) Data: 17.072 (17.072) Loss: 2.9649 (2.9649)
[INFO][2021-08-28 04:25:37]	Batch: [ 30/313] Head: [0/2] Epoch: [  0/350] Progress: [0:04:30/0:45:35] Time: 14.404 (8.740) Data: 12.119 (6.128) Loss: 2.2509 (2.4029)
[INFO][2021-08-28 04:29:50]	Batch: [ 60/313] Head: [0/2] Epoch: [  0/350] Progress: [0:08:43/0:44:44] Time: 14.398 (8.576) Data: 12.113 (6.087) Loss: 2.0991 (2.2939)
[INFO][2021-08-28 04:34:02]	Batch: [ 90/313] Head: [0/2] Epoch: [  0/350] Progress: [0:12:55/0:44:26] Time: 14.659 (8.519) Data: 12.264 (6.084) Loss: 2.0984 (2.2239)
[INFO][2021-08-28 04:38:15]	Batch: [120/313] Head: [0/2] Epoch: [  0/350] Progress: [0:17:08/0:44:19] Time: 14.720 (8.498) Data: 12.432 (6.090) Loss: 2.0049 (2.1795)
[INFO][2021-08-28 04:42:26]	Batch: [150/313] Head: [0/2] Epoch: [  0/350] Progress: [0:21:19/0:44:12] Time: 14.363 (8.476) Data: 11.962 (6.076) Loss: 2.0027 (2.1475)
[INFO][2021-08-28 04:46:39]	Batch: [180/313] Head: [0/2] Epoch: [  0/350] Progress: [0:25:32/0:44:09] Time: 14.419 (8.465) Data: 12.023 (6.073) Loss: 2.0033 (2.1277)
[INFO][2021-08-28 04:50:50]	Batch: [210/313] Head: [0/2] Epoch: [  0/350] Progress: [0:29:43/0:44:06] Time: 14.542 (8.454) Data: 12.252 (6.070) Loss: 2.0077 (2.1128)
[INFO][2021-08-28 04:55:02]	Batch: [240/313] Head: [0/2] Epoch: [  0/350] Progress: [0:33:55/0:44:03] Time: 14.830 (8.447) Data: 12.436 (6.068) Loss: 2.0457 (2.0992)
[INFO][2021-08-28 04:59:14]	Batch: [270/313] Head: [0/2] Epoch: [  0/350] Progress: [0:38:07/0:44:01] Time: 14.212 (8.441) Data: 11.923 (6.071) Loss: 1.9614 (2.0883)
[INFO][2021-08-28 05:03:24]	Batch: [300/313] Head: [0/2] Epoch: [  0/350] Progress: [0:42:18/0:43:59] Time: 14.340 (8.432) Data: 12.052 (6.065) Loss: 1.9970 (2.0791)
[INFO][2021-08-28 05:04:57]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-28 05:05:16]	Batch: [  0/313] Head: [1/2] Epoch: [  0/350] Progress: [0:00:19/1:41:44] Time: 19.505 (19.505) Data: 17.107 (17.107) Loss: 2.2253 (2.2253)
[INFO][2021-08-28 05:09:30]	Batch: [ 30/313] Head: [1/2] Epoch: [  0/350] Progress: [0:04:33/0:45:59] Time: 14.510 (8.817) Data: 12.111 (6.464) Loss: 1.6656 (1.8361)
[INFO][2021-08-28 05:13:42]	Batch: [ 60/313] Head: [1/2] Epoch: [  0/350] Progress: [0:08:45/0:44:56] Time: 14.506 (8.614) Data: 12.220 (6.270) Loss: 1.6604 (1.7496)
[INFO][2021-08-28 05:17:55]	Batch: [ 90/313] Head: [1/2] Epoch: [  0/350] Progress: [0:12:58/0:44:36] Time: 14.776 (8.552) Data: 12.378 (6.206) Loss: 1.6799 (1.7201)
[INFO][2021-08-28 05:22:08]	Batch: [120/313] Head: [1/2] Epoch: [  0/350] Progress: [0:17:10/0:44:26] Time: 14.604 (8.519) Data: 12.205 (6.177) Loss: 1.7154 (1.7081)
[INFO][2021-08-28 05:26:20]	Batch: [150/313] Head: [1/2] Epoch: [  0/350] Progress: [0:21:23/0:44:20] Time: 14.550 (8.498) Data: 12.150 (6.155) Loss: 1.6569 (1.7015)
[INFO][2021-08-28 05:30:33]	Batch: [180/313] Head: [1/2] Epoch: [  0/350] Progress: [0:25:36/0:44:17] Time: 14.638 (8.489) Data: 12.348 (6.152) Loss: 1.7202 (1.6974)
[INFO][2021-08-28 05:34:46]	Batch: [210/313] Head: [1/2] Epoch: [  0/350] Progress: [0:29:49/0:44:14] Time: 14.421 (8.482) Data: 12.131 (6.146) Loss: 1.6196 (1.6927)
[INFO][2021-08-28 05:38:59]	Batch: [240/313] Head: [1/2] Epoch: [  0/350] Progress: [0:34:02/0:44:12] Time: 14.408 (8.474) Data: 12.125 (6.136) Loss: 1.6869 (1.6886)
[INFO][2021-08-28 05:43:12]	Batch: [270/313] Head: [1/2] Epoch: [  0/350] Progress: [0:38:15/0:44:10] Time: 14.340 (8.469) Data: 12.053 (6.129) Loss: 1.6050 (1.6844)
[INFO][2021-08-28 05:47:24]	Batch: [300/313] Head: [1/2] Epoch: [  0/350] Progress: [0:42:27/0:44:09] Time: 14.672 (8.464) Data: 12.273 (6.124) Loss: 1.7008 (1.6815)
[INFO][2021-08-28 05:48:56]	Start to evaluate after 0 epoch of training
[INFO][2021-08-28 05:48:56]	len(loader.dataset)
[INFO][2021-08-28 05:48:56]	5000
[INFO][2021-08-28 05:52:04]	num_classes
[INFO][2021-08-28 05:52:04]	6
[DEBUG][2021-08-28 06:01:52]	Provided arguments will be stored in sessions/pickle10/config.yaml
[INFO][2021-08-28 06:01:52]	Start to declare training variable
[INFO][2021-08-28 06:01:52]	Session will be ran in device: [cuda]
[INFO][2021-08-28 06:01:52]	Start to prepare data
[INFO][2021-08-28 06:01:54]	otrainset----------------------: length 20000
[INFO][2021-08-28 06:01:55]	ptrainset----------------------: length 20000
[INFO][2021-08-28 06:01:55]	testset-------------: length 5000
[INFO][2021-08-28 06:01:55]	Start to build model
[DEBUG][2021-08-28 06:01:55]	Backbone [resnet34] is declared with cin [1] and cout [1000] [with] sobel
[DEBUG][2021-08-28 06:01:55]	Backbone will be created wit the following heads: [10, 10]
[DEBUG][2021-08-28 06:01:55]	Number of trainable parameters is [112]
[DEBUG][2021-08-28 06:01:55]	Number of frozen parameters is [2]
[DEBUG][2021-08-28 06:01:55]	Name of frozen parameters are: dict_keys(['sobel.0.weight', 'sobel.0.bias'])
[DEBUG][2021-08-28 06:01:56]	Going to use [Adam] optimizer for training with betas (0.9, 0.999), eps 0.000000, weight decay 0.000000 without amsgrad
[DEBUG][2021-08-28 06:01:56]	Going to use [fixed] learning policy for optimization with base learning rate [0.00001]
[INFO][2021-08-28 06:01:56]	Data parallel will be used for acceleration purpose
[INFO][2021-08-28 06:01:56]	Start to train at 0 epoch with learning rate 0.000010
[INFO][2021-08-28 06:01:56]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-28 06:01:56]	hidx, head: 0, 10
[INFO][2021-08-28 06:01:56]	hidx, head: 1, 10
[INFO][2021-08-28 06:01:56]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-28 06:02:23]	Batch: [  0/313] Head: [0/2] Epoch: [  0/350] Progress: [0:00:27/2:23:21] Time: 27.482 (27.482) Data: 17.217 (17.217) Loss: 2.5755 (2.5755)
[INFO][2021-08-28 06:06:32]	Batch: [ 30/313] Head: [0/2] Epoch: [  0/350] Progress: [0:04:36/0:46:31] Time: 14.745 (8.918) Data: 12.460 (6.268) Loss: 1.8331 (2.0102)
[INFO][2021-08-28 06:10:48]	Batch: [ 60/313] Head: [0/2] Epoch: [  0/350] Progress: [0:08:52/0:45:33] Time: 14.558 (8.733) Data: 12.156 (6.216) Loss: 1.7482 (1.9026)
[INFO][2021-08-28 06:15:04]	Batch: [ 90/313] Head: [0/2] Epoch: [  0/350] Progress: [0:13:08/0:45:10] Time: 14.750 (8.661) Data: 12.351 (6.188) Loss: 1.7655 (1.8494)
[INFO][2021-08-28 06:19:20]	Batch: [120/313] Head: [0/2] Epoch: [  0/350] Progress: [0:17:24/0:45:02] Time: 14.812 (8.633) Data: 12.525 (6.193) Loss: 1.7242 (1.8171)
[INFO][2021-08-28 06:23:37]	Batch: [150/313] Head: [0/2] Epoch: [  0/350] Progress: [0:21:40/0:44:56] Time: 14.533 (8.615) Data: 12.137 (6.197) Loss: 1.6991 (1.7916)
[INFO][2021-08-28 06:27:53]	Batch: [180/313] Head: [0/2] Epoch: [  0/350] Progress: [0:25:56/0:44:52] Time: 14.724 (8.601) Data: 12.326 (6.189) Loss: 1.7277 (1.7779)
[INFO][2021-08-28 06:32:08]	Batch: [210/313] Head: [0/2] Epoch: [  0/350] Progress: [0:30:12/0:44:48] Time: 14.449 (8.591) Data: 12.052 (6.181) Loss: 1.7267 (1.7661)
[INFO][2021-08-28 06:36:24]	Batch: [240/313] Head: [0/2] Epoch: [  0/350] Progress: [0:34:27/0:44:45] Time: 14.486 (8.581) Data: 12.088 (6.173) Loss: 1.6524 (1.7548)
[INFO][2021-08-28 06:40:37]	Batch: [270/313] Head: [0/2] Epoch: [  0/350] Progress: [0:38:41/0:44:41] Time: 14.445 (8.567) Data: 12.045 (6.161) Loss: 1.6239 (1.7460)
[INFO][2021-08-28 06:44:53]	Batch: [300/313] Head: [0/2] Epoch: [  0/350] Progress: [0:42:57/0:44:39] Time: 14.753 (8.562) Data: 12.463 (6.160) Loss: 1.6698 (1.7385)
[INFO][2021-08-28 06:46:27]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-28 06:46:47]	Batch: [  0/313] Head: [1/2] Epoch: [  0/350] Progress: [0:00:19/1:44:11] Time: 19.972 (19.972) Data: 17.672 (17.672) Loss: 2.2809 (2.2809)
[INFO][2021-08-28 06:51:06]	Batch: [ 30/313] Head: [1/2] Epoch: [  0/350] Progress: [0:04:38/0:46:53] Time: 14.639 (8.990) Data: 12.240 (6.645) Loss: 1.7211 (1.8837)
[INFO][2021-08-28 06:55:24]	Batch: [ 60/313] Head: [1/2] Epoch: [  0/350] Progress: [0:08:56/0:45:52] Time: 14.696 (8.794) Data: 12.298 (6.437) Loss: 1.6974 (1.7899)
[INFO][2021-08-28 06:59:41]	Batch: [ 90/313] Head: [1/2] Epoch: [  0/350] Progress: [0:13:13/0:45:29] Time: 14.315 (8.720) Data: 12.026 (6.353) Loss: 1.6603 (1.7543)
[INFO][2021-08-28 07:03:58]	Batch: [120/313] Head: [1/2] Epoch: [  0/350] Progress: [0:17:30/0:45:17] Time: 14.964 (8.683) Data: 12.566 (6.318) Loss: 1.6255 (1.7364)
[INFO][2021-08-28 07:08:16]	Batch: [150/313] Head: [1/2] Epoch: [  0/350] Progress: [0:21:48/0:45:12] Time: 15.052 (8.667) Data: 12.657 (6.303) Loss: 1.7804 (1.7225)
[INFO][2021-08-28 07:12:34]	Batch: [180/313] Head: [1/2] Epoch: [  0/350] Progress: [0:26:06/0:45:08] Time: 14.666 (8.652) Data: 12.377 (6.293) Loss: 1.6252 (1.7124)
[INFO][2021-08-28 07:16:49]	Batch: [210/313] Head: [1/2] Epoch: [  0/350] Progress: [0:30:22/0:45:02] Time: 14.120 (8.635) Data: 11.833 (6.283) Loss: 1.6633 (1.7050)
[INFO][2021-08-28 07:21:06]	Batch: [240/313] Head: [1/2] Epoch: [  0/350] Progress: [0:34:38/0:44:59] Time: 14.561 (8.623) Data: 12.270 (6.273) Loss: 1.7246 (1.6984)
[INFO][2021-08-28 07:25:22]	Batch: [270/313] Head: [1/2] Epoch: [  0/350] Progress: [0:38:54/0:44:56] Time: 14.935 (8.615) Data: 12.534 (6.266) Loss: 1.6992 (1.6937)
[INFO][2021-08-28 07:29:40]	Batch: [300/313] Head: [1/2] Epoch: [  0/350] Progress: [0:43:12/0:44:55] Time: 14.587 (8.612) Data: 12.188 (6.261) Loss: 1.6646 (1.6890)
[INFO][2021-08-28 07:31:14]	Start to evaluate after 0 epoch of training
[INFO][2021-08-28 07:31:14]	len(loader.dataset)
[INFO][2021-08-28 07:31:14]	5000
[INFO][2021-08-28 07:34:31]	num_classes
[INFO][2021-08-28 07:34:31]	10
[INFO][2021-08-28 07:34:31]	[[   0  789    0    0    0    0    0    0    0    0]
 [   0    0   12    0    0    0    0    0    0    0]
 [1590    0    2    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0  250    0    0    0    0    0    0    0]
 [   1    0  205    0    0    0    0    0    0    0]
 [   0 1211    0    0    0    0    0    0    0    0]
 [   0    0  493    0    0    0    0    0    0    0]
 [ 282    0   38    0    0    0    0    0    0    0]
 [ 127    0    0    0    0    0    0    0    0    0]]
[INFO][2021-08-28 07:34:31]	Evaluation results at epoch 0 are: ACC: 0.659, NMI: 0.747, ARI: 0.619
[INFO][2021-08-28 07:34:32]	Start to train at 1 epoch with learning rate 0.000010
[INFO][2021-08-28 07:34:32]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-28 07:34:32]	hidx, head: 0, 10
[INFO][2021-08-28 07:34:32]	hidx, head: 1, 10
[INFO][2021-08-28 07:34:32]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-28 07:34:52]	Batch: [  0/313] Head: [0/2] Epoch: [  1/350] Progress: [0:00:20/1:44:41] Time: 20.068 (20.068) Data: 17.650 (17.650) Loss: 1.7689 (1.7689)
[INFO][2021-08-28 07:39:10]	Batch: [ 30/313] Head: [0/2] Epoch: [  1/350] Progress: [0:04:37/0:46:46] Time: 14.885 (8.965) Data: 12.594 (6.615) Loss: 1.6546 (1.6729)
[INFO][2021-08-28 07:43:28]	Batch: [ 60/313] Head: [0/2] Epoch: [  1/350] Progress: [0:08:56/0:45:51] Time: 14.485 (8.792) Data: 12.196 (6.443) Loss: 1.6833 (1.6618)
[INFO][2021-08-28 07:47:46]	Batch: [ 90/313] Head: [0/2] Epoch: [  1/350] Progress: [0:13:13/0:45:29] Time: 14.934 (8.721) Data: 12.534 (6.370) Loss: 1.6070 (1.6559)
[INFO][2021-08-28 07:52:02]	Batch: [120/313] Head: [0/2] Epoch: [  1/350] Progress: [0:17:30/0:45:17] Time: 14.894 (8.681) Data: 12.492 (6.335) Loss: 1.6302 (1.6593)
[INFO][2021-08-28 07:56:19]	Batch: [150/313] Head: [0/2] Epoch: [  1/350] Progress: [0:21:46/0:45:08] Time: 14.574 (8.653) Data: 12.176 (6.309) Loss: 1.6557 (1.6609)
[INFO][2021-08-28 08:00:35]	Batch: [180/313] Head: [0/2] Epoch: [  1/350] Progress: [0:26:02/0:45:02] Time: 15.053 (8.634) Data: 12.654 (6.290) Loss: 1.6517 (1.6571)
[INFO][2021-08-28 08:04:51]	Batch: [210/313] Head: [0/2] Epoch: [  1/350] Progress: [0:30:18/0:44:57] Time: 14.535 (8.619) Data: 12.132 (6.276) Loss: 1.6267 (1.6569)
[INFO][2021-08-28 08:09:06]	Batch: [240/313] Head: [0/2] Epoch: [  1/350] Progress: [0:34:33/0:44:53] Time: 14.302 (8.605) Data: 12.013 (6.260) Loss: 1.6005 (1.6544)
[INFO][2021-08-28 08:13:21]	Batch: [270/313] Head: [0/2] Epoch: [  1/350] Progress: [0:38:49/0:44:50] Time: 14.779 (8.596) Data: 12.489 (6.250) Loss: 1.6807 (1.6535)
[INFO][2021-08-28 08:17:37]	Batch: [300/313] Head: [0/2] Epoch: [  1/350] Progress: [0:43:04/0:44:47] Time: 14.502 (8.587) Data: 12.103 (6.242) Loss: 1.6063 (1.6544)
[INFO][2021-08-28 08:19:10]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-28 08:19:30]	Batch: [  0/313] Head: [1/2] Epoch: [  1/350] Progress: [0:00:20/1:44:39] Time: 20.063 (20.063) Data: 17.762 (17.762) Loss: 1.7801 (1.7801)
[INFO][2021-08-28 08:23:47]	Batch: [ 30/313] Head: [1/2] Epoch: [  1/350] Progress: [0:04:37/0:46:40] Time: 14.673 (8.947) Data: 12.278 (6.606) Loss: 1.6838 (1.6475)
[INFO][2021-08-28 08:28:05]	Batch: [ 60/313] Head: [1/2] Epoch: [  1/350] Progress: [0:08:55/0:45:46] Time: 14.746 (8.775) Data: 12.464 (6.422) Loss: 1.6311 (1.6415)
[INFO][2021-08-28 08:32:24]	Batch: [ 90/313] Head: [1/2] Epoch: [  1/350] Progress: [0:13:13/0:45:30] Time: 14.786 (8.724) Data: 12.388 (6.370) Loss: 1.6079 (1.6483)
[INFO][2021-08-28 08:36:41]	Batch: [120/313] Head: [1/2] Epoch: [  1/350] Progress: [0:17:30/0:45:18] Time: 14.771 (8.686) Data: 12.376 (6.335) Loss: 1.6223 (1.6431)
[INFO][2021-08-28 08:40:56]	Batch: [150/313] Head: [1/2] Epoch: [  1/350] Progress: [0:21:45/0:45:06] Time: 14.759 (8.646) Data: 12.471 (6.296) Loss: 1.6160 (1.6423)
[INFO][2021-08-28 08:45:12]	Batch: [180/313] Head: [1/2] Epoch: [  1/350] Progress: [0:26:02/0:45:01] Time: 14.715 (8.630) Data: 12.320 (6.276) Loss: 1.6511 (1.6417)
[INFO][2021-08-28 08:49:29]	Batch: [210/313] Head: [1/2] Epoch: [  1/350] Progress: [0:30:18/0:44:58] Time: 14.626 (8.620) Data: 12.228 (6.266) Loss: 1.6588 (1.6434)
[INFO][2021-08-28 08:53:44]	Batch: [240/313] Head: [1/2] Epoch: [  1/350] Progress: [0:34:34/0:44:53] Time: 14.390 (8.606) Data: 12.105 (6.252) Loss: 1.6966 (1.6426)
[INFO][2021-08-28 08:58:00]	Batch: [270/313] Head: [1/2] Epoch: [  1/350] Progress: [0:38:50/0:44:51] Time: 14.969 (8.599) Data: 12.570 (6.245) Loss: 1.6443 (1.6447)
[INFO][2021-08-28 09:02:16]	Batch: [300/313] Head: [1/2] Epoch: [  1/350] Progress: [0:43:05/0:44:48] Time: 14.537 (8.590) Data: 12.141 (6.238) Loss: 1.6403 (1.6433)
[INFO][2021-08-28 09:03:48]	Start to evaluate after 1 epoch of training
[INFO][2021-08-28 09:03:48]	len(loader.dataset)
[INFO][2021-08-28 09:03:48]	5000
[INFO][2021-08-28 09:07:01]	num_classes
[INFO][2021-08-28 09:07:01]	10
[INFO][2021-08-28 09:07:01]	[[   0 1065    0    0    0    0    0    0    0    0]
 [   0    0    5    0    0    0    0    0    0    0]
 [ 555    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0  261    0    0    0    0    0    0    0]
 [  61    0  180    0    0    0    0    0    0    0]
 [   0  935    0    0    0    0    0    0    0    0]
 [   0    0  539    0    0    0    0    0    0    0]
 [1370    0   15    0    0    0    0    0    0    0]
 [  14    0    0    0    0    0    0    0    0    0]]
[INFO][2021-08-28 09:07:01]	Evaluation results at epoch 1 are: ACC: 0.595, NMI: 0.732, ARI: 0.565
[INFO][2021-08-28 09:07:01]	Start to train at 2 epoch with learning rate 0.000010
[INFO][2021-08-28 09:07:01]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-28 09:07:01]	hidx, head: 0, 10
[INFO][2021-08-28 09:07:01]	hidx, head: 1, 10
[INFO][2021-08-28 09:07:01]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-28 09:07:21]	Batch: [  0/313] Head: [0/2] Epoch: [  2/350] Progress: [0:00:19/1:43:43] Time: 19.884 (19.884) Data: 17.578 (17.578) Loss: 1.6938 (1.6938)
[INFO][2021-08-28 09:11:39]	Batch: [ 30/313] Head: [0/2] Epoch: [  2/350] Progress: [0:04:37/0:46:41] Time: 14.907 (8.951) Data: 12.513 (6.600) Loss: 1.6380 (1.6557)
[INFO][2021-08-28 09:15:56]	Batch: [ 60/313] Head: [0/2] Epoch: [  2/350] Progress: [0:08:55/0:45:45] Time: 14.702 (8.772) Data: 12.415 (6.423) Loss: 1.7257 (1.6561)
[INFO][2021-08-28 09:20:14]	Batch: [ 90/313] Head: [0/2] Epoch: [  2/350] Progress: [0:13:12/0:45:25] Time: 14.892 (8.707) Data: 12.493 (6.361) Loss: 1.6465 (1.6487)
[INFO][2021-08-28 09:24:29]	Batch: [120/313] Head: [0/2] Epoch: [  2/350] Progress: [0:17:27/0:45:09] Time: 14.825 (8.658) Data: 12.425 (6.306) Loss: 1.6538 (1.6455)
[INFO][2021-08-28 09:28:43]	Batch: [150/313] Head: [0/2] Epoch: [  2/350] Progress: [0:21:42/0:44:58] Time: 14.581 (8.623) Data: 12.294 (6.265) Loss: 1.6155 (1.6439)
[INFO][2021-08-28 09:32:59]	Batch: [180/313] Head: [0/2] Epoch: [  2/350] Progress: [0:25:57/0:44:53] Time: 14.794 (8.605) Data: 12.395 (6.246) Loss: 1.7171 (1.6430)
[INFO][2021-08-28 09:37:15]	Batch: [210/313] Head: [0/2] Epoch: [  2/350] Progress: [0:30:13/0:44:50] Time: 14.688 (8.596) Data: 12.292 (6.235) Loss: 1.6181 (1.6439)
[INFO][2021-08-28 09:41:32]	Batch: [240/313] Head: [0/2] Epoch: [  2/350] Progress: [0:34:30/0:44:49] Time: 14.390 (8.592) Data: 12.101 (6.228) Loss: 1.7697 (1.6419)
[INFO][2021-08-28 09:45:48]	Batch: [270/313] Head: [0/2] Epoch: [  2/350] Progress: [0:38:46/0:44:47] Time: 14.791 (8.586) Data: 12.399 (6.220) Loss: 1.6092 (1.6398)
[INFO][2021-08-28 09:50:03]	Batch: [300/313] Head: [0/2] Epoch: [  2/350] Progress: [0:43:01/0:44:44] Time: 13.145 (8.576) Data: 10.744 (6.210) Loss: 1.6429 (1.6382)
[INFO][2021-08-28 09:51:36]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-28 09:51:56]	Batch: [  0/313] Head: [1/2] Epoch: [  2/350] Progress: [0:00:19/1:43:29] Time: 19.839 (19.839) Data: 17.532 (17.532) Loss: 1.6869 (1.6869)
[INFO][2021-08-28 09:56:13]	Batch: [ 30/313] Head: [1/2] Epoch: [  2/350] Progress: [0:04:37/0:46:43] Time: 14.978 (8.956) Data: 12.691 (6.620) Loss: 1.5934 (1.6362)
[INFO][2021-08-28 10:00:32]	Batch: [ 60/313] Head: [1/2] Epoch: [  2/350] Progress: [0:08:55/0:45:50] Time: 15.050 (8.787) Data: 12.762 (6.469) Loss: 1.6048 (1.6320)
[INFO][2021-08-28 10:04:51]	Batch: [ 90/313] Head: [1/2] Epoch: [  2/350] Progress: [0:13:14/0:45:34] Time: 14.555 (8.736) Data: 12.265 (6.411) Loss: 1.6228 (1.6332)
[INFO][2021-08-28 10:09:10]	Batch: [120/313] Head: [1/2] Epoch: [  2/350] Progress: [0:17:34/0:45:26] Time: 14.896 (8.711) Data: 12.606 (6.383) Loss: 1.6071 (1.6340)
[INFO][2021-08-28 10:13:25]	Batch: [150/313] Head: [1/2] Epoch: [  2/350] Progress: [0:21:49/0:45:13] Time: 15.014 (8.669) Data: 12.616 (6.337) Loss: 1.5774 (1.6341)
[INFO][2021-08-28 10:17:42]	Batch: [180/313] Head: [1/2] Epoch: [  2/350] Progress: [0:26:05/0:45:07] Time: 14.440 (8.651) Data: 12.045 (6.311) Loss: 1.6195 (1.6347)
[INFO][2021-08-28 10:21:57]	Batch: [210/313] Head: [1/2] Epoch: [  2/350] Progress: [0:30:21/0:45:02] Time: 14.942 (8.633) Data: 12.545 (6.287) Loss: 1.6544 (1.6336)
[INFO][2021-08-28 10:26:14]	Batch: [240/313] Head: [1/2] Epoch: [  2/350] Progress: [0:34:38/0:44:59] Time: 14.533 (8.625) Data: 12.135 (6.281) Loss: 1.5667 (1.6334)
[INFO][2021-08-28 10:30:29]	Batch: [270/313] Head: [1/2] Epoch: [  2/350] Progress: [0:38:53/0:44:55] Time: 14.836 (8.611) Data: 12.550 (6.270) Loss: 1.6337 (1.6333)
[INFO][2021-08-28 10:34:47]	Batch: [300/313] Head: [1/2] Epoch: [  2/350] Progress: [0:43:10/0:44:54] Time: 14.727 (8.608) Data: 12.330 (6.264) Loss: 1.6947 (1.6324)
[INFO][2021-08-28 10:36:20]	Start to evaluate after 2 epoch of training
[INFO][2021-08-28 10:36:20]	len(loader.dataset)
[INFO][2021-08-28 10:36:20]	5000
[INFO][2021-08-28 10:39:28]	num_classes
[INFO][2021-08-28 10:39:28]	10
[INFO][2021-08-28 10:39:28]	[[   0 1466    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [1632    0    1    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0  181    0    0    0    0    0    0    0]
 [   1    0  298    0    0    0    0    0    0    0]
 [   0  534    0    0    0    0    0    0    0    0]
 [   0    0  474    0    0    0    0    0    0    0]
 [ 311    0   46    0    0    0    0    0    0    0]
 [  56    0    0    0    0    0    0    0    0    0]]
[INFO][2021-08-28 10:39:28]	Evaluation results at epoch 2 are: ACC: 0.714, NMI: 0.762, ARI: 0.670
[INFO][2021-08-28 10:39:29]	Start to train at 3 epoch with learning rate 0.000010
[INFO][2021-08-28 10:39:29]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-28 10:39:29]	hidx, head: 0, 10
[INFO][2021-08-28 10:39:29]	hidx, head: 1, 10
[INFO][2021-08-28 10:39:29]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-28 10:39:49]	Batch: [  0/313] Head: [0/2] Epoch: [  3/350] Progress: [0:00:19/1:43:04] Time: 19.758 (19.758) Data: 17.458 (17.458) Loss: 1.7435 (1.7435)
[INFO][2021-08-28 10:44:07]	Batch: [ 30/313] Head: [0/2] Epoch: [  3/350] Progress: [0:04:37/0:46:42] Time: 15.195 (8.955) Data: 12.801 (6.628) Loss: 1.6776 (1.6332)
[INFO][2021-08-28 10:48:23]	Batch: [ 60/313] Head: [0/2] Epoch: [  3/350] Progress: [0:08:54/0:45:40] Time: 14.786 (8.754) Data: 12.497 (6.422) Loss: 1.6157 (1.6341)
[INFO][2021-08-28 10:52:39]	Batch: [ 90/313] Head: [0/2] Epoch: [  3/350] Progress: [0:13:09/0:45:16] Time: 14.896 (8.678) Data: 12.608 (6.343) Loss: 1.5740 (1.6310)
[INFO][2021-08-28 10:56:54]	Batch: [120/313] Head: [0/2] Epoch: [  3/350] Progress: [0:17:24/0:45:02] Time: 14.711 (8.635) Data: 12.423 (6.300) Loss: 1.7155 (1.6324)
[INFO][2021-08-28 11:01:10]	Batch: [150/313] Head: [0/2] Epoch: [  3/350] Progress: [0:21:40/0:44:56] Time: 14.885 (8.615) Data: 12.597 (6.282) Loss: 1.6425 (1.6326)
[INFO][2021-08-28 11:05:24]	Batch: [180/313] Head: [0/2] Epoch: [  3/350] Progress: [0:25:54/0:44:48] Time: 13.195 (8.591) Data: 10.911 (6.264) Loss: 1.6326 (1.6305)
[INFO][2021-08-28 11:09:40]	Batch: [210/313] Head: [0/2] Epoch: [  3/350] Progress: [0:30:10/0:44:46] Time: 12.356 (8.582) Data: 10.075 (6.260) Loss: 1.6446 (1.6295)
[INFO][2021-08-28 11:13:55]	Batch: [240/313] Head: [0/2] Epoch: [  3/350] Progress: [0:34:25/0:44:43] Time: 8.628 (8.572) Data: 6.232 (6.253) Loss: 1.5830 (1.6294)
[INFO][2021-08-28 11:18:09]	Batch: [270/313] Head: [0/2] Epoch: [  3/350] Progress: [0:38:40/0:44:39] Time: 7.578 (8.561) Data: 5.180 (6.241) Loss: 1.6069 (1.6282)
[INFO][2021-08-28 11:22:23]	Batch: [300/313] Head: [0/2] Epoch: [  3/350] Progress: [0:42:54/0:44:36] Time: 5.164 (8.552) Data: 2.883 (6.233) Loss: 1.5993 (1.6273)
[INFO][2021-08-28 11:24:02]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-28 11:24:22]	Batch: [  0/313] Head: [1/2] Epoch: [  3/350] Progress: [0:00:19/1:43:55] Time: 19.921 (19.921) Data: 17.511 (17.511) Loss: 1.5784 (1.5784)
[INFO][2021-08-28 11:28:39]	Batch: [ 30/313] Head: [1/2] Epoch: [  3/350] Progress: [0:04:36/0:46:34] Time: 14.741 (8.929) Data: 12.343 (6.549) Loss: 1.6208 (1.6273)
[INFO][2021-08-28 11:32:56]	Batch: [ 60/313] Head: [1/2] Epoch: [  3/350] Progress: [0:08:54/0:45:41] Time: 14.761 (8.759) Data: 12.364 (6.395) Loss: 1.5927 (1.6264)
[INFO][2021-08-28 11:37:13]	Batch: [ 90/313] Head: [1/2] Epoch: [  3/350] Progress: [0:13:10/0:45:20] Time: 14.734 (8.690) Data: 12.336 (6.332) Loss: 1.5550 (1.6222)
[INFO][2021-08-28 11:41:28]	Batch: [120/313] Head: [1/2] Epoch: [  3/350] Progress: [0:17:25/0:45:04] Time: 14.679 (8.641) Data: 12.284 (6.280) Loss: 1.5898 (1.6234)
[INFO][2021-08-28 11:45:41]	Batch: [150/313] Head: [1/2] Epoch: [  3/350] Progress: [0:21:38/0:44:52] Time: 11.922 (8.603) Data: 9.635 (6.242) Loss: 1.6151 (1.6228)
[INFO][2021-08-28 11:49:54]	Batch: [180/313] Head: [1/2] Epoch: [  3/350] Progress: [0:25:51/0:44:43] Time: 10.248 (8.574) Data: 7.962 (6.212) Loss: 1.6053 (1.6231)
[INFO][2021-08-28 11:54:08]	Batch: [210/313] Head: [1/2] Epoch: [  3/350] Progress: [0:30:05/0:44:38] Time: 5.932 (8.556) Data: 3.645 (6.199) Loss: 1.5978 (1.6217)
[INFO][2021-08-28 11:58:24]	Batch: [240/313] Head: [1/2] Epoch: [  3/350] Progress: [0:34:21/0:44:37] Time: 3.736 (8.554) Data: 1.338 (6.203) Loss: 1.5929 (1.6205)
[INFO][2021-08-28 12:02:38]	Batch: [270/313] Head: [1/2] Epoch: [  3/350] Progress: [0:38:35/0:44:34] Time: 2.411 (8.546) Data: 0.127 (6.196) Loss: 1.6128 (1.6193)
[INFO][2021-08-28 12:06:54]	Batch: [300/313] Head: [1/2] Epoch: [  3/350] Progress: [0:42:52/0:44:34] Time: 3.059 (8.545) Data: 0.665 (6.195) Loss: 1.6554 (1.6181)
[INFO][2021-08-28 12:08:35]	Start to evaluate after 3 epoch of training
[INFO][2021-08-28 12:08:35]	len(loader.dataset)
[INFO][2021-08-28 12:08:35]	5000
[INFO][2021-08-28 12:11:46]	num_classes
[INFO][2021-08-28 12:11:46]	10
[INFO][2021-08-28 12:11:46]	[[   0 1856    0    0    0    0    0    0    0    0]
 [   0    0    1    0    0    0    0    0    0    0]
 [1272    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0   69    0    0    0    0    0    0    0]
 [   5    0  311    0    0    0    0    0    0    0]
 [   0  144    0    0    0    0    0    0    0    0]
 [   0    0  586    0    0    0    0    0    0    0]
 [ 680    0   33    0    0    0    0    0    0    0]
 [  43    0    0    0    0    0    0    0    0    0]]
[INFO][2021-08-28 12:11:46]	Evaluation results at epoch 3 are: ACC: 0.743, NMI: 0.782, ARI: 0.714
[INFO][2021-08-28 12:11:47]	Start to train at 4 epoch with learning rate 0.000010
[INFO][2021-08-28 12:11:47]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-28 12:11:47]	hidx, head: 0, 10
[INFO][2021-08-28 12:11:47]	hidx, head: 1, 10
[INFO][2021-08-28 12:11:47]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-28 12:12:07]	Batch: [  0/313] Head: [0/2] Epoch: [  4/350] Progress: [0:00:20/1:45:46] Time: 20.275 (20.275) Data: 17.860 (17.860) Loss: 1.6781 (1.6781)
[INFO][2021-08-28 12:16:28]	Batch: [ 30/313] Head: [0/2] Epoch: [  4/350] Progress: [0:04:40/0:47:15] Time: 15.037 (9.058) Data: 12.635 (6.727) Loss: 1.6312 (1.6364)
[INFO][2021-08-28 12:20:44]	Batch: [ 60/313] Head: [0/2] Epoch: [  4/350] Progress: [0:08:57/0:45:58] Time: 11.979 (8.812) Data: 9.689 (6.468) Loss: 1.6896 (1.6337)
[INFO][2021-08-28 12:25:02]	Batch: [ 90/313] Head: [0/2] Epoch: [  4/350] Progress: [0:13:15/0:45:36] Time: 8.622 (8.743) Data: 6.332 (6.403) Loss: 1.6619 (1.6283)
[INFO][2021-08-28 12:29:19]	Batch: [120/313] Head: [0/2] Epoch: [  4/350] Progress: [0:17:32/0:45:22] Time: 8.032 (8.698) Data: 5.631 (6.350) Loss: 1.6153 (1.6269)
[INFO][2021-08-28 12:33:36]	Batch: [150/313] Head: [0/2] Epoch: [  4/350] Progress: [0:21:49/0:45:14] Time: 8.112 (8.672) Data: 5.828 (6.317) Loss: 1.6191 (1.6257)
[INFO][2021-08-28 12:37:52]	Batch: [180/313] Head: [0/2] Epoch: [  4/350] Progress: [0:26:04/0:45:06] Time: 7.223 (8.646) Data: 4.935 (6.286) Loss: 1.6533 (1.6240)
[INFO][2021-08-28 12:42:09]	Batch: [210/313] Head: [0/2] Epoch: [  4/350] Progress: [0:30:22/0:45:03] Time: 6.751 (8.638) Data: 4.358 (6.275) Loss: 1.5655 (1.6241)
[INFO][2021-08-28 12:46:26]	Batch: [240/313] Head: [0/2] Epoch: [  4/350] Progress: [0:34:39/0:45:00] Time: 5.524 (8.629) Data: 3.238 (6.262) Loss: 1.6177 (1.6222)
[INFO][2021-08-28 12:50:44]	Batch: [270/313] Head: [0/2] Epoch: [  4/350] Progress: [0:38:56/0:44:58] Time: 5.665 (8.623) Data: 3.380 (6.257) Loss: 1.5826 (1.6223)
[INFO][2021-08-28 12:55:01]	Batch: [300/313] Head: [0/2] Epoch: [  4/350] Progress: [0:43:13/0:44:57] Time: 7.002 (8.617) Data: 4.717 (6.254) Loss: 1.5916 (1.6210)
[INFO][2021-08-28 12:56:38]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-28 12:56:58]	Batch: [  0/313] Head: [1/2] Epoch: [  4/350] Progress: [0:00:19/1:44:19] Time: 19.999 (19.999) Data: 17.695 (17.695) Loss: 1.6588 (1.6588)
[INFO][2021-08-28 13:01:12]	Batch: [ 30/313] Head: [1/2] Epoch: [  4/350] Progress: [0:04:34/0:46:07] Time: 14.560 (8.843) Data: 12.160 (6.472) Loss: 1.5733 (1.6109)
[INFO][2021-08-28 13:05:25]	Batch: [ 60/313] Head: [1/2] Epoch: [  4/350] Progress: [0:08:47/0:45:06] Time: 14.182 (8.648) Data: 11.784 (6.282) Loss: 1.6202 (1.6172)
[INFO][2021-08-28 13:09:38]	Batch: [ 90/313] Head: [1/2] Epoch: [  4/350] Progress: [0:13:00/0:44:45] Time: 12.576 (8.579) Data: 10.178 (6.226) Loss: 1.6072 (1.6177)
[INFO][2021-08-28 13:13:53]	Batch: [120/313] Head: [1/2] Epoch: [  4/350] Progress: [0:17:15/0:44:37] Time: 11.911 (8.554) Data: 9.619 (6.206) Loss: 1.6241 (1.6161)
[INFO][2021-08-28 13:18:05]	Batch: [150/313] Head: [1/2] Epoch: [  4/350] Progress: [0:21:27/0:44:28] Time: 8.951 (8.525) Data: 6.660 (6.175) Loss: 1.5681 (1.6127)
[INFO][2021-08-28 13:22:19]	Batch: [180/313] Head: [1/2] Epoch: [  4/350] Progress: [0:25:41/0:44:26] Time: 10.529 (8.518) Data: 8.245 (6.168) Loss: 1.6220 (1.6129)
[INFO][2021-08-28 13:26:33]	Batch: [210/313] Head: [1/2] Epoch: [  4/350] Progress: [0:29:55/0:44:22] Time: 9.297 (8.507) Data: 6.900 (6.155) Loss: 1.6698 (1.6154)
[INFO][2021-08-28 13:30:49]	Batch: [240/313] Head: [1/2] Epoch: [  4/350] Progress: [0:34:11/0:44:24] Time: 12.528 (8.511) Data: 10.240 (6.160) Loss: 1.5984 (1.6149)
[INFO][2021-08-28 13:35:05]	Batch: [270/313] Head: [1/2] Epoch: [  4/350] Progress: [0:38:27/0:44:25] Time: 13.867 (8.515) Data: 11.576 (6.163) Loss: 1.5891 (1.6163)
[INFO][2021-08-28 13:39:19]	Batch: [300/313] Head: [1/2] Epoch: [  4/350] Progress: [0:42:41/0:44:23] Time: 12.886 (8.509) Data: 10.596 (6.157) Loss: 1.6047 (1.6160)
[INFO][2021-08-28 13:40:52]	Start to evaluate after 4 epoch of training
[INFO][2021-08-28 13:40:52]	len(loader.dataset)
[INFO][2021-08-28 13:40:52]	5000
[INFO][2021-08-28 13:44:01]	num_classes
[INFO][2021-08-28 13:44:01]	10
[INFO][2021-08-28 13:44:01]	[[   0 1801    0    0    0    0    0    0    0    0]
 [   0    0    6    0    0    0    0    0    0    0]
 [ 873    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0  329    0    0    0    0    0    0    0]
 [  99    0  120    0    0    0    0    0    0    0]
 [   0  199    0    0    0    0    0    0    0    0]
 [   0    0  535    0    0    0    0    0    0    0]
 [1024    0   10    0    0    0    0    0    0    0]
 [   4    0    0    0    0    0    0    0    0    0]]
[INFO][2021-08-28 13:44:01]	Evaluation results at epoch 4 are: ACC: 0.672, NMI: 0.758, ARI: 0.665
[INFO][2021-08-28 13:44:02]	Start to train at 5 epoch with learning rate 0.000010
[INFO][2021-08-28 13:44:02]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-28 13:44:02]	hidx, head: 0, 10
[INFO][2021-08-28 13:44:02]	hidx, head: 1, 10
[INFO][2021-08-28 13:44:02]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-28 13:44:22]	Batch: [  0/313] Head: [0/2] Epoch: [  5/350] Progress: [0:00:20/1:44:21] Time: 20.006 (20.006) Data: 17.593 (17.593) Loss: 1.6068 (1.6068)
[INFO][2021-08-28 13:48:40]	Batch: [ 30/313] Head: [0/2] Epoch: [  5/350] Progress: [0:04:38/0:46:50] Time: 15.063 (8.979) Data: 12.663 (6.616) Loss: 1.5675 (1.6218)
[INFO][2021-08-28 13:52:59]	Batch: [ 60/313] Head: [0/2] Epoch: [  5/350] Progress: [0:08:56/0:45:53] Time: 14.745 (8.798) Data: 12.442 (6.446) Loss: 1.6395 (1.6161)
[INFO][2021-08-28 13:57:17]	Batch: [ 90/313] Head: [0/2] Epoch: [  5/350] Progress: [0:13:15/0:45:34] Time: 14.781 (8.738) Data: 12.492 (6.381) Loss: 1.6659 (1.6166)
[INFO][2021-08-28 14:01:35]	Batch: [120/313] Head: [0/2] Epoch: [  5/350] Progress: [0:17:32/0:45:22] Time: 14.382 (8.699) Data: 12.101 (6.339) Loss: 1.5998 (1.6144)
[INFO][2021-08-28 14:05:52]	Batch: [150/313] Head: [0/2] Epoch: [  5/350] Progress: [0:21:49/0:45:14] Time: 15.206 (8.673) Data: 12.807 (6.314) Loss: 1.5872 (1.6121)
[INFO][2021-08-28 14:10:05]	Batch: [180/313] Head: [0/2] Epoch: [  5/350] Progress: [0:26:02/0:45:02] Time: 14.939 (8.635) Data: 12.541 (6.277) Loss: 1.5911 (1.6098)
[INFO][2021-08-28 14:14:22]	Batch: [210/313] Head: [0/2] Epoch: [  5/350] Progress: [0:30:20/0:44:59] Time: 14.899 (8.626) Data: 12.503 (6.271) Loss: 1.6358 (1.6110)
[INFO][2021-08-28 14:18:40]	Batch: [240/313] Head: [0/2] Epoch: [  5/350] Progress: [0:34:38/0:44:59] Time: 14.712 (8.624) Data: 12.312 (6.270) Loss: 1.5802 (1.6107)
[INFO][2021-08-28 14:22:57]	Batch: [270/313] Head: [0/2] Epoch: [  5/350] Progress: [0:38:54/0:44:56] Time: 14.571 (8.616) Data: 12.169 (6.261) Loss: 1.6030 (1.6100)
[INFO][2021-08-28 14:27:14]	Batch: [300/313] Head: [0/2] Epoch: [  5/350] Progress: [0:43:11/0:44:55] Time: 14.881 (8.611) Data: 12.485 (6.256) Loss: 1.5882 (1.6095)
[INFO][2021-08-28 14:28:47]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-28 14:29:07]	Batch: [  0/313] Head: [1/2] Epoch: [  5/350] Progress: [0:00:19/1:43:25] Time: 19.825 (19.825) Data: 17.410 (17.410) Loss: 1.5841 (1.5841)
[INFO][2021-08-28 14:33:25]	Batch: [ 30/313] Head: [1/2] Epoch: [  5/350] Progress: [0:04:37/0:46:44] Time: 14.941 (8.960) Data: 12.544 (6.599) Loss: 1.6923 (1.6155)
[INFO][2021-08-28 14:37:40]	Batch: [ 60/313] Head: [1/2] Epoch: [  5/350] Progress: [0:08:52/0:45:34] Time: 14.880 (8.736) Data: 12.475 (6.374) Loss: 1.5744 (1.6100)
[INFO][2021-08-28 14:41:57]	Batch: [ 90/313] Head: [1/2] Epoch: [  5/350] Progress: [0:13:09/0:45:14] Time: 14.831 (8.674) Data: 12.546 (6.319) Loss: 1.5813 (1.6104)
[INFO][2021-08-28 14:46:12]	Batch: [120/313] Head: [1/2] Epoch: [  5/350] Progress: [0:17:24/0:45:02] Time: 14.712 (8.634) Data: 12.317 (6.277) Loss: 1.6298 (1.6125)
[INFO][2021-08-28 14:50:29]	Batch: [150/313] Head: [1/2] Epoch: [  5/350] Progress: [0:21:41/0:44:57] Time: 14.728 (8.619) Data: 12.332 (6.255) Loss: 1.6030 (1.6111)
[INFO][2021-08-28 14:54:45]	Batch: [180/313] Head: [1/2] Epoch: [  5/350] Progress: [0:25:57/0:44:53] Time: 14.478 (8.607) Data: 12.193 (6.241) Loss: 1.5841 (1.6099)
[INFO][2021-08-28 14:59:02]	Batch: [210/313] Head: [1/2] Epoch: [  5/350] Progress: [0:30:14/0:44:51] Time: 14.726 (8.599) Data: 12.332 (6.229) Loss: 1.6072 (1.6100)
[INFO][2021-08-28 15:03:20]	Batch: [240/313] Head: [1/2] Epoch: [  5/350] Progress: [0:34:33/0:44:52] Time: 14.993 (8.602) Data: 12.600 (6.235) Loss: 1.5927 (1.6081)
[INFO][2021-08-28 15:07:39]	Batch: [270/313] Head: [1/2] Epoch: [  5/350] Progress: [0:38:51/0:44:52] Time: 14.920 (8.603) Data: 12.636 (6.239) Loss: 1.6533 (1.6075)
[INFO][2021-08-28 15:11:55]	Batch: [300/313] Head: [1/2] Epoch: [  5/350] Progress: [0:43:07/0:44:50] Time: 14.590 (8.596) Data: 12.305 (6.237) Loss: 1.5707 (1.6082)
[INFO][2021-08-28 15:13:28]	Start to evaluate after 5 epoch of training
[INFO][2021-08-28 15:13:28]	len(loader.dataset)
[INFO][2021-08-28 15:13:28]	5000
[INFO][2021-08-28 15:16:37]	num_classes
[INFO][2021-08-28 15:16:37]	10
[INFO][2021-08-28 15:16:37]	[[   0 1368    0    0    0    0    0    0    0    0]
 [   0    0    6    0    0    0    0    0    0    0]
 [1017    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0  178    0    0    0    0    0    0    0]
 [  48    0  193    0    0    0    0    0    0    0]
 [   0  632    0    0    0    0    0    0    0    0]
 [   0    0  611    0    0    0    0    0    0    0]
 [ 897    0   12    0    0    0    0    0    0    0]
 [  38    0    0    0    0    0    0    0    0    0]]
[INFO][2021-08-28 15:16:37]	Evaluation results at epoch 5 are: ACC: 0.599, NMI: 0.735, ARI: 0.564
[INFO][2021-08-28 15:16:38]	Start to train at 6 epoch with learning rate 0.000010
[INFO][2021-08-28 15:16:38]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-28 15:16:38]	hidx, head: 0, 10
[INFO][2021-08-28 15:16:38]	hidx, head: 1, 10
[INFO][2021-08-28 15:16:38]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-28 15:16:58]	Batch: [  0/313] Head: [0/2] Epoch: [  6/350] Progress: [0:00:19/1:43:17] Time: 19.801 (19.801) Data: 17.384 (17.384) Loss: 1.6042 (1.6042)
[INFO][2021-08-28 15:21:15]	Batch: [ 30/313] Head: [0/2] Epoch: [  6/350] Progress: [0:04:36/0:46:34] Time: 15.089 (8.927) Data: 12.693 (6.593) Loss: 1.5869 (1.6066)
[INFO][2021-08-28 15:25:31]	Batch: [ 60/313] Head: [0/2] Epoch: [  6/350] Progress: [0:08:53/0:45:36] Time: 14.729 (8.742) Data: 12.446 (6.399) Loss: 1.5835 (1.6079)
[INFO][2021-08-28 15:29:48]	Batch: [ 90/313] Head: [0/2] Epoch: [  6/350] Progress: [0:13:10/0:45:17] Time: 14.676 (8.683) Data: 12.280 (6.339) Loss: 1.5981 (1.6053)
[INFO][2021-08-28 15:34:06]	Batch: [120/313] Head: [0/2] Epoch: [  6/350] Progress: [0:17:27/0:45:10] Time: 14.659 (8.661) Data: 12.370 (6.314) Loss: 1.6379 (1.6026)
[INFO][2021-08-28 15:38:23]	Batch: [150/313] Head: [0/2] Epoch: [  6/350] Progress: [0:21:44/0:45:04] Time: 14.898 (8.642) Data: 12.609 (6.298) Loss: 1.6296 (1.6051)
[INFO][2021-08-28 15:42:38]	Batch: [180/313] Head: [0/2] Epoch: [  6/350] Progress: [0:26:00/0:44:58] Time: 14.804 (8.621) Data: 12.403 (6.275) Loss: 1.6669 (1.6049)
[INFO][2021-08-28 15:46:52]	Batch: [210/313] Head: [0/2] Epoch: [  6/350] Progress: [0:30:14/0:44:51] Time: 14.653 (8.600) Data: 12.361 (6.253) Loss: 1.5936 (1.6046)
[INFO][2021-08-28 15:51:07]	Batch: [240/313] Head: [0/2] Epoch: [  6/350] Progress: [0:34:29/0:44:47] Time: 14.488 (8.587) Data: 12.200 (6.245) Loss: 1.5826 (1.6037)
[INFO][2021-08-28 15:55:24]	Batch: [270/313] Head: [0/2] Epoch: [  6/350] Progress: [0:38:46/0:44:46] Time: 14.672 (8.584) Data: 12.278 (6.239) Loss: 1.6234 (1.6042)
[INFO][2021-08-28 15:59:39]	Batch: [300/313] Head: [0/2] Epoch: [  6/350] Progress: [0:43:00/0:44:43] Time: 14.966 (8.574) Data: 12.569 (6.228) Loss: 1.6402 (1.6044)
[INFO][2021-08-28 16:01:12]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-28 16:01:31]	Batch: [  0/313] Head: [1/2] Epoch: [  6/350] Progress: [0:00:19/1:42:41] Time: 19.685 (19.685) Data: 17.376 (17.376) Loss: 1.5784 (1.5784)
[INFO][2021-08-28 16:05:46]	Batch: [ 30/313] Head: [1/2] Epoch: [  6/350] Progress: [0:04:34/0:46:09] Time: 14.443 (8.847) Data: 12.157 (6.501) Loss: 1.5782 (1.5990)
[INFO][2021-08-28 16:09:59]	Batch: [ 60/313] Head: [1/2] Epoch: [  6/350] Progress: [0:08:47/0:45:06] Time: 10.946 (8.646) Data: 8.547 (6.282) Loss: 1.5583 (1.6001)
[INFO][2021-08-28 16:14:13]	Batch: [ 90/313] Head: [1/2] Epoch: [  6/350] Progress: [0:13:01/0:44:47] Time: 8.574 (8.587) Data: 6.179 (6.234) Loss: 1.5661 (1.5995)
[INFO][2021-08-28 16:18:26]	Batch: [120/313] Head: [1/2] Epoch: [  6/350] Progress: [0:17:14/0:44:34] Time: 4.372 (8.546) Data: 2.084 (6.198) Loss: 1.5624 (1.5984)
[INFO][2021-08-28 16:22:41]	Batch: [150/313] Head: [1/2] Epoch: [  6/350] Progress: [0:21:29/0:44:32] Time: 2.394 (8.539) Data: 0.001 (6.195) Loss: 1.6303 (1.5997)
[INFO][2021-08-28 16:26:59]	Batch: [180/313] Head: [1/2] Epoch: [  6/350] Progress: [0:25:47/0:44:36] Time: 2.398 (8.551) Data: 0.001 (6.206) Loss: 1.5736 (1.6004)
[INFO][2021-08-28 16:31:16]	Batch: [210/313] Head: [1/2] Epoch: [  6/350] Progress: [0:30:04/0:44:36] Time: 2.397 (8.551) Data: 0.001 (6.207) Loss: 1.6333 (1.6009)
[INFO][2021-08-28 16:35:31]	Batch: [240/313] Head: [1/2] Epoch: [  6/350] Progress: [0:34:19/0:44:34] Time: 2.394 (8.546) Data: 0.001 (6.199) Loss: 1.5795 (1.6005)
[INFO][2021-08-28 16:39:48]	Batch: [270/313] Head: [1/2] Epoch: [  6/350] Progress: [0:38:36/0:44:35] Time: 2.392 (8.548) Data: 0.001 (6.199) Loss: 1.5996 (1.6007)
[INFO][2021-08-28 16:44:05]	Batch: [300/313] Head: [1/2] Epoch: [  6/350] Progress: [0:42:53/0:44:36] Time: 2.395 (8.550) Data: 0.001 (6.199) Loss: 1.6052 (1.6016)
[INFO][2021-08-28 16:45:48]	Start to evaluate after 6 epoch of training
[INFO][2021-08-28 16:45:48]	len(loader.dataset)
[INFO][2021-08-28 16:45:48]	5000
[INFO][2021-08-28 16:48:57]	num_classes
[INFO][2021-08-28 16:48:57]	10
[INFO][2021-08-28 16:48:57]	[[   0 1870    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [1146    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0   91    0    0    0    0    0    0    0]
 [   3    0  377    0    0    0    0    0    0    0]
 [   0  130    0    0    0    0    0    0    0    0]
 [   0    0  501    0    0    0    0    0    0    0]
 [ 806    0   31    0    0    0    0    0    0    0]
 [  45    0    0    0    0    0    0    0    0    0]]
[INFO][2021-08-28 16:48:57]	Evaluation results at epoch 6 are: ACC: 0.703, NMI: 0.779, ARI: 0.702
[INFO][2021-08-28 16:48:57]	Start to train at 7 epoch with learning rate 0.000010
[INFO][2021-08-28 16:48:57]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-28 16:48:57]	hidx, head: 0, 10
[INFO][2021-08-28 16:48:57]	hidx, head: 1, 10
[INFO][2021-08-28 16:48:57]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-28 16:49:17]	Batch: [  0/313] Head: [0/2] Epoch: [  7/350] Progress: [0:00:19/1:42:54] Time: 19.728 (19.728) Data: 17.418 (17.418) Loss: 1.6129 (1.6129)
[INFO][2021-08-28 16:53:33]	Batch: [ 30/313] Head: [0/2] Epoch: [  7/350] Progress: [0:04:35/0:46:21] Time: 14.578 (8.888) Data: 12.176 (6.519) Loss: 1.5702 (1.6068)
[INFO][2021-08-28 16:57:49]	Batch: [ 60/313] Head: [0/2] Epoch: [  7/350] Progress: [0:08:51/0:45:28] Time: 14.426 (8.718) Data: 12.138 (6.357) Loss: 1.5933 (1.6080)
[INFO][2021-08-28 17:02:07]	Batch: [ 90/313] Head: [0/2] Epoch: [  7/350] Progress: [0:13:10/0:45:17] Time: 14.563 (8.682) Data: 12.275 (6.329) Loss: 1.5724 (1.6081)
[INFO][2021-08-28 17:06:25]	Batch: [120/313] Head: [0/2] Epoch: [  7/350] Progress: [0:17:27/0:45:10] Time: 14.748 (8.659) Data: 12.344 (6.311) Loss: 1.5678 (1.6077)
[INFO][2021-08-28 17:10:42]	Batch: [150/313] Head: [0/2] Epoch: [  7/350] Progress: [0:21:44/0:45:03] Time: 14.845 (8.638) Data: 12.556 (6.294) Loss: 1.5849 (1.6058)
[INFO][2021-08-28 17:14:59]	Batch: [180/313] Head: [0/2] Epoch: [  7/350] Progress: [0:26:01/0:45:00] Time: 14.764 (8.627) Data: 12.366 (6.283) Loss: 1.5796 (1.6057)
[INFO][2021-08-28 17:19:17]	Batch: [210/313] Head: [0/2] Epoch: [  7/350] Progress: [0:30:19/0:44:58] Time: 14.638 (8.621) Data: 12.241 (6.275) Loss: 1.5961 (1.6054)
[INFO][2021-08-28 17:23:33]	Batch: [240/313] Head: [0/2] Epoch: [  7/350] Progress: [0:34:35/0:44:55] Time: 14.614 (8.613) Data: 12.323 (6.268) Loss: 1.5876 (1.6049)
[INFO][2021-08-28 17:27:50]	Batch: [270/313] Head: [0/2] Epoch: [  7/350] Progress: [0:38:52/0:44:53] Time: 14.980 (8.606) Data: 12.692 (6.265) Loss: 1.6098 (1.6044)
[INFO][2021-08-28 17:32:07]	Batch: [300/313] Head: [0/2] Epoch: [  7/350] Progress: [0:43:09/0:44:52] Time: 14.690 (8.603) Data: 12.401 (6.261) Loss: 1.6488 (1.6039)
[INFO][2021-08-28 17:33:40]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-28 17:34:00]	Batch: [  0/313] Head: [1/2] Epoch: [  7/350] Progress: [0:00:19/1:43:20] Time: 19.808 (19.808) Data: 17.496 (17.496) Loss: 1.6263 (1.6263)
[INFO][2021-08-28 17:38:16]	Batch: [ 30/313] Head: [1/2] Epoch: [  7/350] Progress: [0:04:36/0:46:28] Time: 14.663 (8.909) Data: 12.373 (6.556) Loss: 1.6821 (1.6078)
[INFO][2021-08-28 17:42:32]	Batch: [ 60/313] Head: [1/2] Epoch: [  7/350] Progress: [0:08:52/0:45:30] Time: 11.610 (8.724) Data: 9.212 (6.378) Loss: 1.6772 (1.6181)
[INFO][2021-08-28 17:46:47]	Batch: [ 90/313] Head: [1/2] Epoch: [  7/350] Progress: [0:13:06/0:45:05] Time: 7.592 (8.643) Data: 5.192 (6.294) Loss: 1.5867 (1.6164)
[DEBUG][2021-08-29 05:29:26]	Provided arguments will be stored in sessions/pickle10/config.yaml
[INFO][2021-08-29 05:29:26]	Start to declare training variable
[INFO][2021-08-29 05:29:26]	Session will be ran in device: [cuda]
[INFO][2021-08-29 05:29:26]	Start to prepare data
[INFO][2021-08-29 05:29:28]	otrainset----------------------: length 20000
[INFO][2021-08-29 05:29:28]	ptrainset----------------------: length 20000
[INFO][2021-08-29 05:29:29]	testset-------------: length 5000
[INFO][2021-08-29 05:29:29]	Start to build model
[DEBUG][2021-08-29 05:29:29]	Backbone [resnet34] is declared with cin [1] and cout [1000] [with] sobel
[DEBUG][2021-08-29 05:29:29]	Backbone will be created wit the following heads: [10, 10]
[DEBUG][2021-08-29 05:29:29]	Number of trainable parameters is [112]
[DEBUG][2021-08-29 05:29:29]	Number of frozen parameters is [2]
[DEBUG][2021-08-29 05:29:29]	Name of frozen parameters are: dict_keys(['sobel.0.weight', 'sobel.0.bias'])
[DEBUG][2021-08-29 05:29:29]	Going to use [Adam] optimizer for training with betas (0.9, 0.999), eps 0.000000, weight decay 0.000000 without amsgrad
[DEBUG][2021-08-29 05:29:29]	Going to use [fixed] learning policy for optimization with base learning rate [0.00001]
[INFO][2021-08-29 05:29:29]	Start to resume session for file: [sessions/pickle10/checkpoint/latest.ckpt]
[DEBUG][2021-08-29 05:29:29]	Totally loaded [222] parameters
[INFO][2021-08-29 05:29:29]	Data parallel will be used for acceleration purpose
[INFO][2021-08-29 05:29:29]	Start to train at 7 epoch with learning rate 0.000010
[INFO][2021-08-29 05:29:29]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-29 05:29:29]	hidx, head: 0, 10
[INFO][2021-08-29 05:29:29]	hidx, head: 1, 10
[INFO][2021-08-29 05:29:29]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-29 05:29:57]	Batch: [  0/313] Head: [0/2] Epoch: [  7/350] Progress: [0:00:27/2:24:53] Time: 27.776 (27.776) Data: 16.600 (16.600) Loss: 1.6220 (1.6220)
[INFO][2021-08-29 05:33:53]	Batch: [ 30/313] Head: [0/2] Epoch: [  7/350] Progress: [0:04:23/0:44:17] Time: 13.912 (8.490) Data: 11.624 (5.893) Loss: 1.6397 (1.6103)
[INFO][2021-08-29 05:37:57]	Batch: [ 60/313] Head: [0/2] Epoch: [  7/350] Progress: [0:08:27/0:43:23] Time: 13.863 (8.317) Data: 11.574 (5.854) Loss: 1.7456 (1.6158)
[INFO][2021-08-29 05:42:01]	Batch: [ 90/313] Head: [0/2] Epoch: [  7/350] Progress: [0:12:31/0:43:04] Time: 13.975 (8.257) Data: 11.561 (5.831) Loss: 1.5794 (1.6116)
[INFO][2021-08-29 05:46:05]	Batch: [120/313] Head: [0/2] Epoch: [  7/350] Progress: [0:16:35/0:42:54] Time: 13.741 (8.226) Data: 11.450 (5.816) Loss: 1.5822 (1.6110)
[INFO][2021-08-29 05:50:09]	Batch: [150/313] Head: [0/2] Epoch: [  7/350] Progress: [0:20:39/0:42:49] Time: 13.976 (8.210) Data: 11.575 (5.814) Loss: 1.5725 (1.6082)
[INFO][2021-08-29 05:54:14]	Batch: [180/313] Head: [0/2] Epoch: [  7/350] Progress: [0:24:44/0:42:46] Time: 14.177 (8.201) Data: 11.776 (5.811) Loss: 1.5936 (1.6067)
[INFO][2021-08-29 05:58:18]	Batch: [210/313] Head: [0/2] Epoch: [  7/350] Progress: [0:28:48/0:42:44] Time: 13.904 (8.192) Data: 11.503 (5.811) Loss: 1.5722 (1.6046)
[INFO][2021-08-29 06:02:22]	Batch: [240/313] Head: [0/2] Epoch: [  7/350] Progress: [0:32:52/0:42:41] Time: 13.940 (8.184) Data: 11.653 (5.806) Loss: 1.5848 (1.6049)
[INFO][2021-08-29 06:06:26]	Batch: [270/313] Head: [0/2] Epoch: [  7/350] Progress: [0:36:56/0:42:40] Time: 13.849 (8.180) Data: 11.453 (5.803) Loss: 1.5653 (1.6049)
[INFO][2021-08-29 06:10:30]	Batch: [300/313] Head: [0/2] Epoch: [  7/350] Progress: [0:41:01/0:42:39] Time: 13.867 (8.176) Data: 11.471 (5.800) Loss: 1.5784 (1.6042)
[INFO][2021-08-29 06:11:59]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-29 06:12:19]	Batch: [  0/313] Head: [1/2] Epoch: [  7/350] Progress: [0:00:19/1:39:31] Time: 19.079 (19.079) Data: 16.667 (16.667) Loss: 1.5826 (1.5826)
[INFO][2021-08-29 06:16:25]	Batch: [ 30/313] Head: [1/2] Epoch: [  7/350] Progress: [0:04:25/0:44:41] Time: 14.099 (8.567) Data: 11.810 (6.216) Loss: 1.5763 (1.6064)
[INFO][2021-08-29 06:20:32]	Batch: [ 60/313] Head: [1/2] Epoch: [  7/350] Progress: [0:08:32/0:43:49] Time: 14.043 (8.400) Data: 11.640 (6.039) Loss: 1.6517 (1.6070)
[INFO][2021-08-29 06:24:38]	Batch: [ 90/313] Head: [1/2] Epoch: [  7/350] Progress: [0:12:38/0:43:30] Time: 14.132 (8.340) Data: 11.733 (5.987) Loss: 1.5728 (1.6044)
[INFO][2021-08-29 06:28:45]	Batch: [120/313] Head: [1/2] Epoch: [  7/350] Progress: [0:16:45/0:43:20] Time: 14.253 (8.308) Data: 11.852 (5.961) Loss: 1.7335 (1.6038)
[INFO][2021-08-29 06:32:51]	Batch: [150/313] Head: [1/2] Epoch: [  7/350] Progress: [0:20:51/0:43:14] Time: 14.222 (8.288) Data: 11.933 (5.950) Loss: 1.5816 (1.6024)
[INFO][2021-08-29 06:36:56]	Batch: [180/313] Head: [1/2] Epoch: [  7/350] Progress: [0:24:56/0:43:07] Time: 13.880 (8.267) Data: 11.590 (5.935) Loss: 1.6434 (1.6027)
[INFO][2021-08-29 06:41:00]	Batch: [210/313] Head: [1/2] Epoch: [  7/350] Progress: [0:29:00/0:43:02] Time: 13.974 (8.249) Data: 11.686 (5.919) Loss: 1.6417 (1.6037)
[INFO][2021-08-29 06:45:05]	Batch: [240/313] Head: [1/2] Epoch: [  7/350] Progress: [0:33:05/0:42:58] Time: 14.013 (8.238) Data: 11.725 (5.907) Loss: 1.5549 (1.6023)
[INFO][2021-08-29 06:49:10]	Batch: [270/313] Head: [1/2] Epoch: [  7/350] Progress: [0:37:10/0:42:56] Time: 13.922 (8.230) Data: 11.629 (5.899) Loss: 1.6562 (1.6029)
[INFO][2021-08-29 06:53:15]	Batch: [300/313] Head: [1/2] Epoch: [  7/350] Progress: [0:41:15/0:42:53] Time: 13.698 (8.223) Data: 11.407 (5.892) Loss: 1.5865 (1.6022)
[INFO][2021-08-29 06:54:44]	Start to evaluate after 7 epoch of training
[INFO][2021-08-29 06:54:44]	len(loader.dataset)
[INFO][2021-08-29 06:54:44]	5000
[INFO][2021-08-29 06:57:47]	num_classes
[INFO][2021-08-29 06:57:47]	10
[INFO][2021-08-29 06:57:47]	[[   0 1830    0    0    0    0    0    0    0    0]
 [   0    0    4    0    0    0    0    0    0    0]
 [1371    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0  209    0    0    0    0    0    0    0]
 [   5    0  260    0    0    0    0    0    0    0]
 [   0  170    0    0    0    0    0    0    0    0]
 [   0    0  493    0    0    0    0    0    0    0]
 [ 569    0   34    0    0    0    0    0    0    0]
 [  55    0    0    0    0    0    0    0    0    0]]
[INFO][2021-08-29 06:57:47]	Evaluation results at epoch 7 are: ACC: 0.739, NMI: 0.773, ARI: 0.709
[INFO][2021-08-29 06:57:48]	Start to train at 8 epoch with learning rate 0.000010
[INFO][2021-08-29 06:57:48]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-29 06:57:48]	hidx, head: 0, 10
[INFO][2021-08-29 06:57:48]	hidx, head: 1, 10
[INFO][2021-08-29 06:57:48]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-29 06:58:07]	Batch: [  0/313] Head: [0/2] Epoch: [  8/350] Progress: [0:00:19/1:39:22] Time: 19.049 (19.049) Data: 16.746 (16.746) Loss: 1.6375 (1.6375)
[INFO][2021-08-29 07:02:13]	Batch: [ 30/313] Head: [0/2] Epoch: [  8/350] Progress: [0:04:24/0:44:31] Time: 14.101 (8.535) Data: 11.809 (6.216) Loss: 1.6780 (1.5982)
[INFO][2021-08-29 07:06:18]	Batch: [ 60/313] Head: [0/2] Epoch: [  8/350] Progress: [0:08:30/0:43:37] Time: 13.882 (8.363) Data: 11.587 (6.031) Loss: 1.6714 (1.6016)
[INFO][2021-08-29 07:10:24]	Batch: [ 90/313] Head: [0/2] Epoch: [  8/350] Progress: [0:12:35/0:43:17] Time: 13.865 (8.300) Data: 11.576 (5.970) Loss: 1.5599 (1.6011)
[INFO][2021-08-29 07:14:29]	Batch: [120/313] Head: [0/2] Epoch: [  8/350] Progress: [0:16:41/0:43:09] Time: 14.247 (8.274) Data: 11.847 (5.947) Loss: 1.5560 (1.5984)
[INFO][2021-08-29 07:18:35]	Batch: [150/313] Head: [0/2] Epoch: [  8/350] Progress: [0:20:46/0:43:03] Time: 14.025 (8.255) Data: 11.622 (5.924) Loss: 1.6553 (1.5967)
[INFO][2021-08-29 07:22:40]	Batch: [180/313] Head: [0/2] Epoch: [  8/350] Progress: [0:24:51/0:42:59] Time: 13.930 (8.241) Data: 11.528 (5.902) Loss: 1.6033 (1.5979)
[INFO][2021-08-29 07:26:45]	Batch: [210/313] Head: [0/2] Epoch: [  8/350] Progress: [0:28:57/0:42:56] Time: 14.080 (8.233) Data: 11.678 (5.886) Loss: 1.6106 (1.5982)
[INFO][2021-08-29 07:30:51]	Batch: [240/313] Head: [0/2] Epoch: [  8/350] Progress: [0:33:02/0:42:55] Time: 13.945 (8.227) Data: 11.545 (5.876) Loss: 1.5576 (1.5969)
[INFO][2021-08-29 07:34:56]	Batch: [270/313] Head: [0/2] Epoch: [  8/350] Progress: [0:37:08/0:42:53] Time: 13.950 (8.222) Data: 11.660 (5.870) Loss: 1.6102 (1.5958)
[INFO][2021-08-29 07:39:01]	Batch: [300/313] Head: [0/2] Epoch: [  8/350] Progress: [0:41:13/0:42:51] Time: 13.867 (8.216) Data: 11.575 (5.869) Loss: 1.6124 (1.5948)
[INFO][2021-08-29 07:40:30]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-29 07:40:49]	Batch: [  0/313] Head: [1/2] Epoch: [  8/350] Progress: [0:00:19/1:39:09] Time: 19.007 (19.007) Data: 16.706 (16.706) Loss: 1.6127 (1.6127)
[INFO][2021-08-29 07:44:54]	Batch: [ 30/313] Head: [1/2] Epoch: [  8/350] Progress: [0:04:23/0:44:16] Time: 13.855 (8.488) Data: 11.567 (6.134) Loss: 1.5619 (1.6036)
[INFO][2021-08-29 07:48:58]	Batch: [ 60/313] Head: [1/2] Epoch: [  8/350] Progress: [0:08:27/0:43:23] Time: 10.553 (8.318) Data: 8.151 (5.965) Loss: 1.5877 (1.6038)
[INFO][2021-08-29 07:53:02]	Batch: [ 90/313] Head: [1/2] Epoch: [  8/350] Progress: [0:12:31/0:43:05] Time: 6.600 (8.261) Data: 4.204 (5.907) Loss: 1.5757 (1.6009)
[INFO][2021-08-29 07:57:06]	Batch: [120/313] Head: [1/2] Epoch: [  8/350] Progress: [0:16:35/0:42:56] Time: 2.458 (8.230) Data: 0.058 (5.877) Loss: 1.6528 (1.5990)
[INFO][2021-08-29 08:01:13]	Batch: [150/313] Head: [1/2] Epoch: [  8/350] Progress: [0:20:42/0:42:55] Time: 2.290 (8.229) Data: 0.001 (5.873) Loss: 1.5837 (1.5982)
[INFO][2021-08-29 08:05:19]	Batch: [180/313] Head: [1/2] Epoch: [  8/350] Progress: [0:24:48/0:42:53] Time: 2.289 (8.224) Data: 0.001 (5.868) Loss: 1.5518 (1.5966)
[INFO][2021-08-29 08:09:25]	Batch: [210/313] Head: [1/2] Epoch: [  8/350] Progress: [0:28:54/0:42:53] Time: 2.401 (8.222) Data: 0.001 (5.868) Loss: 1.5790 (1.5949)
[INFO][2021-08-29 08:13:31]	Batch: [240/313] Head: [1/2] Epoch: [  8/350] Progress: [0:33:00/0:42:52] Time: 2.289 (8.220) Data: 0.001 (5.866) Loss: 1.7357 (1.5944)
[INFO][2021-08-29 08:17:38]	Batch: [270/313] Head: [1/2] Epoch: [  8/350] Progress: [0:37:07/0:42:52] Time: 2.289 (8.218) Data: 0.001 (5.866) Loss: 1.5423 (1.5935)
[INFO][2021-08-29 08:21:44]	Batch: [300/313] Head: [1/2] Epoch: [  8/350] Progress: [0:41:13/0:42:52] Time: 2.399 (8.219) Data: 0.001 (5.868) Loss: 1.5967 (1.5942)
[INFO][2021-08-29 08:23:22]	Start to evaluate after 8 epoch of training
[INFO][2021-08-29 08:23:22]	len(loader.dataset)
[INFO][2021-08-29 08:23:22]	5000
[INFO][2021-08-29 08:26:26]	num_classes
[INFO][2021-08-29 08:26:26]	10
[INFO][2021-08-29 08:26:27]	[[   0 1614    0    0    0    0    0    0    0    0]
 [   0    0    4    0    0    0    0    0    0    0]
 [1355    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0  483    0    0    0    0    0    0    0]
 [  10    0  194    0    0    0    0    0    0    0]
 [   0  386    0    0    0    0    0    0    0    0]
 [   0    0  296    0    0    0    0    0    0    0]
 [ 588    0   23    0    0    0    0    0    0    0]
 [  47    0    0    0    0    0    0    0    0    0]]
[INFO][2021-08-29 08:26:27]	Evaluation results at epoch 8 are: ACC: 0.690, NMI: 0.757, ARI: 0.644
[INFO][2021-08-29 08:26:27]	Start to train at 9 epoch with learning rate 0.000010
[INFO][2021-08-29 08:26:27]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-29 08:26:27]	hidx, head: 0, 10
[INFO][2021-08-29 08:26:27]	hidx, head: 1, 10
[INFO][2021-08-29 08:26:27]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-29 08:26:46]	Batch: [  0/313] Head: [0/2] Epoch: [  9/350] Progress: [0:00:18/1:39:00] Time: 18.978 (18.978) Data: 16.673 (16.673) Loss: 1.5938 (1.5938)
[INFO][2021-08-29 08:30:52]	Batch: [ 30/313] Head: [0/2] Epoch: [  9/350] Progress: [0:04:24/0:44:32] Time: 14.073 (8.538) Data: 11.673 (6.163) Loss: 1.5994 (1.6028)
[INFO][2021-08-29 08:34:57]	Batch: [ 60/313] Head: [0/2] Epoch: [  9/350] Progress: [0:08:29/0:43:34] Time: 13.932 (8.354) Data: 11.531 (5.986) Loss: 1.6275 (1.5976)
[INFO][2021-08-29 08:39:02]	Batch: [ 90/313] Head: [0/2] Epoch: [  9/350] Progress: [0:12:34/0:43:16] Time: 13.930 (8.296) Data: 11.528 (5.919) Loss: 1.5755 (1.5948)
[INFO][2021-08-29 08:43:07]	Batch: [120/313] Head: [0/2] Epoch: [  9/350] Progress: [0:16:40/0:43:06] Time: 13.983 (8.265) Data: 11.583 (5.882) Loss: 1.6313 (1.5928)
[INFO][2021-08-29 08:47:12]	Batch: [150/313] Head: [0/2] Epoch: [  9/350] Progress: [0:20:45/0:43:01] Time: 13.923 (8.248) Data: 11.525 (5.866) Loss: 1.5858 (1.5950)
[INFO][2021-08-29 08:51:18]	Batch: [180/313] Head: [0/2] Epoch: [  9/350] Progress: [0:24:50/0:42:58] Time: 13.982 (8.237) Data: 11.584 (5.853) Loss: 1.6214 (1.5948)
[INFO][2021-08-29 08:55:23]	Batch: [210/313] Head: [0/2] Epoch: [  9/350] Progress: [0:28:55/0:42:54] Time: 13.869 (8.226) Data: 11.475 (5.842) Loss: 1.6669 (1.5966)
[INFO][2021-08-29 08:59:28]	Batch: [240/313] Head: [0/2] Epoch: [  9/350] Progress: [0:33:00/0:42:52] Time: 14.000 (8.220) Data: 11.600 (5.836) Loss: 1.5912 (1.5940)
[INFO][2021-08-29 09:03:34]	Batch: [270/313] Head: [0/2] Epoch: [  9/350] Progress: [0:37:06/0:42:51] Time: 14.009 (8.216) Data: 11.719 (5.838) Loss: 1.6076 (1.5940)
[INFO][2021-08-29 09:07:39]	Batch: [300/313] Head: [0/2] Epoch: [  9/350] Progress: [0:41:11/0:42:50] Time: 14.075 (8.212) Data: 11.756 (5.843) Loss: 1.5721 (1.5926)
[INFO][2021-08-29 09:09:08]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-29 09:09:27]	Batch: [  0/313] Head: [1/2] Epoch: [  9/350] Progress: [0:00:19/1:39:59] Time: 19.167 (19.167) Data: 16.757 (16.757) Loss: 1.5802 (1.5802)
[INFO][2021-08-29 09:13:33]	Batch: [ 30/313] Head: [1/2] Epoch: [  9/350] Progress: [0:04:24/0:44:33] Time: 13.936 (8.541) Data: 11.537 (6.140) Loss: 1.5646 (1.6025)
[INFO][2021-08-29 09:17:37]	Batch: [ 60/313] Head: [1/2] Epoch: [  9/350] Progress: [0:08:29/0:43:32] Time: 13.878 (8.347) Data: 11.474 (5.962) Loss: 1.5872 (1.5980)
[INFO][2021-08-29 09:21:42]	Batch: [ 90/313] Head: [1/2] Epoch: [  9/350] Progress: [0:12:33/0:43:11] Time: 13.893 (8.281) Data: 11.606 (5.907) Loss: 1.5439 (1.5943)
[INFO][2021-08-29 09:25:46]	Batch: [120/313] Head: [1/2] Epoch: [  9/350] Progress: [0:16:38/0:43:01] Time: 13.951 (8.248) Data: 11.551 (5.870) Loss: 1.5784 (1.5902)
[INFO][2021-08-29 09:29:51]	Batch: [150/313] Head: [1/2] Epoch: [  9/350] Progress: [0:20:42/0:42:56] Time: 13.889 (8.230) Data: 11.487 (5.850) Loss: 1.5421 (1.5898)
[INFO][2021-08-29 09:33:56]	Batch: [180/313] Head: [1/2] Epoch: [  9/350] Progress: [0:24:47/0:42:52] Time: 13.888 (8.219) Data: 11.490 (5.835) Loss: 1.6882 (1.5886)
[INFO][2021-08-29 09:38:00]	Batch: [210/313] Head: [1/2] Epoch: [  9/350] Progress: [0:28:52/0:42:49] Time: 13.965 (8.210) Data: 11.566 (5.829) Loss: 1.6173 (1.5886)
[INFO][2021-08-29 09:42:05]	Batch: [240/313] Head: [1/2] Epoch: [  9/350] Progress: [0:32:56/0:42:47] Time: 13.988 (8.203) Data: 11.590 (5.821) Loss: 1.5500 (1.5894)
[INFO][2021-08-29 09:46:09]	Batch: [270/313] Head: [1/2] Epoch: [  9/350] Progress: [0:37:01/0:42:45] Time: 13.947 (8.196) Data: 11.547 (5.816) Loss: 1.6247 (1.5886)
[INFO][2021-08-29 09:50:13]	Batch: [300/313] Head: [1/2] Epoch: [  9/350] Progress: [0:41:04/0:42:43] Time: 13.827 (8.189) Data: 11.425 (5.813) Loss: 1.6309 (1.5886)
[INFO][2021-08-29 09:51:42]	Start to evaluate after 9 epoch of training
[INFO][2021-08-29 09:51:42]	len(loader.dataset)
[INFO][2021-08-29 09:51:42]	5000
[INFO][2021-08-29 09:54:45]	num_classes
[INFO][2021-08-29 09:54:45]	10
[INFO][2021-08-29 09:54:45]	[[   0 1388    0    0    0    0    0    0    0    0]
 [   0    0    3    0    0    0    0    0    0    0]
 [ 865    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0  344    0    0    0    0    0    0    0]
 [ 294    0   99    0    0    0    0    0    0    0]
 [   0  612    0    0    0    0    0    0    0    0]
 [   0    0  552    0    0    0    0    0    0    0]
 [ 833    0    2    0    0    0    0    0    0    0]
 [   8    0    0    0    0    0    0    0    0    0]]
[INFO][2021-08-29 09:54:45]	Evaluation results at epoch 9 are: ACC: 0.561, NMI: 0.720, ARI: 0.530
[INFO][2021-08-29 09:54:45]	Start to train at 10 epoch with learning rate 0.000010
[INFO][2021-08-29 09:54:45]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-29 09:54:45]	hidx, head: 0, 10
[INFO][2021-08-29 09:54:45]	hidx, head: 1, 10
[INFO][2021-08-29 09:54:45]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-29 09:55:04]	Batch: [  0/313] Head: [0/2] Epoch: [ 10/350] Progress: [0:00:18/1:39:01] Time: 18.982 (18.982) Data: 16.671 (16.671) Loss: 1.5672 (1.5672)
[INFO][2021-08-29 09:59:11]	Batch: [ 30/313] Head: [0/2] Epoch: [ 10/350] Progress: [0:04:25/0:44:42] Time: 14.143 (8.570) Data: 11.743 (6.197) Loss: 1.5885 (1.6103)
[INFO][2021-08-29 10:03:18]	Batch: [ 60/313] Head: [0/2] Epoch: [ 10/350] Progress: [0:08:32/0:43:48] Time: 14.172 (8.398) Data: 11.773 (6.025) Loss: 1.6192 (1.6124)
[INFO][2021-08-29 10:07:25]	Batch: [ 90/313] Head: [0/2] Epoch: [ 10/350] Progress: [0:12:39/0:43:31] Time: 14.062 (8.343) Data: 11.661 (5.964) Loss: 1.5594 (1.6063)
[INFO][2021-08-29 10:11:32]	Batch: [120/313] Head: [0/2] Epoch: [ 10/350] Progress: [0:16:46/0:43:22] Time: 14.252 (8.316) Data: 11.932 (5.937) Loss: 1.5755 (1.5996)
[INFO][2021-08-29 10:15:38]	Batch: [150/313] Head: [0/2] Epoch: [ 10/350] Progress: [0:20:52/0:43:17] Time: 14.179 (8.297) Data: 11.889 (5.926) Loss: 1.6134 (1.6008)
[INFO][2021-08-29 10:19:45]	Batch: [180/313] Head: [0/2] Epoch: [ 10/350] Progress: [0:24:59/0:43:13] Time: 13.946 (8.287) Data: 11.657 (5.919) Loss: 1.5813 (1.5985)
[INFO][2021-08-29 10:23:52]	Batch: [210/313] Head: [0/2] Epoch: [ 10/350] Progress: [0:29:06/0:43:10] Time: 13.949 (8.278) Data: 11.659 (5.913) Loss: 1.5977 (1.5980)
[INFO][2021-08-29 10:27:59]	Batch: [240/313] Head: [0/2] Epoch: [ 10/350] Progress: [0:33:13/0:43:08] Time: 14.073 (8.271) Data: 11.783 (5.909) Loss: 1.6142 (1.5969)
[INFO][2021-08-29 10:32:06]	Batch: [270/313] Head: [0/2] Epoch: [ 10/350] Progress: [0:37:20/0:43:07] Time: 13.949 (8.267) Data: 11.659 (5.906) Loss: 1.6280 (1.5972)
[INFO][2021-08-29 10:36:12]	Batch: [300/313] Head: [0/2] Epoch: [ 10/350] Progress: [0:41:26/0:43:06] Time: 13.970 (8.262) Data: 11.683 (5.903) Loss: 1.5832 (1.5963)
[INFO][2021-08-29 10:37:42]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-29 10:38:01]	Batch: [  0/313] Head: [1/2] Epoch: [ 10/350] Progress: [0:00:18/1:38:53] Time: 18.957 (18.957) Data: 16.648 (16.648) Loss: 1.5579 (1.5579)
[INFO][2021-08-29 10:42:05]	Batch: [ 30/313] Head: [1/2] Epoch: [ 10/350] Progress: [0:04:23/0:44:17] Time: 14.023 (8.491) Data: 11.731 (6.173) Loss: 1.5743 (1.5846)
[INFO][2021-08-29 10:46:10]	Batch: [ 60/313] Head: [1/2] Epoch: [ 10/350] Progress: [0:08:27/0:43:25] Time: 12.184 (8.324) Data: 9.783 (6.015) Loss: 1.5810 (1.5874)
[INFO][2021-08-29 10:50:14]	Batch: [ 90/313] Head: [1/2] Epoch: [ 10/350] Progress: [0:12:31/0:43:06] Time: 9.575 (8.263) Data: 7.285 (5.952) Loss: 1.5474 (1.5884)
[INFO][2021-08-29 10:54:19]	Batch: [120/313] Head: [1/2] Epoch: [ 10/350] Progress: [0:16:36/0:42:58] Time: 7.409 (8.237) Data: 5.124 (5.929) Loss: 1.6044 (1.5928)
[INFO][2021-08-29 10:58:24]	Batch: [150/313] Head: [1/2] Epoch: [ 10/350] Progress: [0:20:41/0:42:53] Time: 5.225 (8.222) Data: 2.933 (5.913) Loss: 1.5489 (1.5917)
[INFO][2021-08-29 11:02:28]	Batch: [180/313] Head: [1/2] Epoch: [ 10/350] Progress: [0:24:45/0:42:49] Time: 2.725 (8.209) Data: 0.324 (5.900) Loss: 1.5366 (1.5904)
[INFO][2021-08-29 11:06:34]	Batch: [210/313] Head: [1/2] Epoch: [ 10/350] Progress: [0:28:51/0:42:49] Time: 2.288 (8.208) Data: 0.001 (5.899) Loss: 1.5932 (1.5893)
[INFO][2021-08-29 11:10:40]	Batch: [240/313] Head: [1/2] Epoch: [ 10/350] Progress: [0:32:57/0:42:48] Time: 2.288 (8.205) Data: 0.001 (5.895) Loss: 1.6309 (1.5880)
[INFO][2021-08-29 11:14:46]	Batch: [270/313] Head: [1/2] Epoch: [ 10/350] Progress: [0:37:03/0:42:48] Time: 2.288 (8.205) Data: 0.001 (5.896) Loss: 1.5441 (1.5876)
[INFO][2021-08-29 11:18:52]	Batch: [300/313] Head: [1/2] Epoch: [ 10/350] Progress: [0:41:09/0:42:48] Time: 2.291 (8.206) Data: 0.001 (5.893) Loss: 1.5687 (1.5877)
[INFO][2021-08-29 11:20:30]	Start to evaluate after 10 epoch of training
[INFO][2021-08-29 11:20:30]	len(loader.dataset)
[INFO][2021-08-29 11:20:30]	5000
[INFO][2021-08-29 11:23:34]	num_classes
[INFO][2021-08-29 11:23:34]	10
[INFO][2021-08-29 11:23:34]	[[   0 1962    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [1320    0    0    0    0    0    0    0    0    0]
 [   0    3    0    0    0    0    0    0    0    0]
 [   0    0   71    0    0    0    0    0    0    0]
 [   4    0  364    0    0    0    0    0    0    0]
 [   0   35    0    0    0    0    0    0    0    0]
 [   0    0  538    0    0    0    0    0    0    0]
 [ 635    0   27    0    0    0    0    0    0    0]
 [  41    0    0    0    0    0    0    0    0    0]]
[INFO][2021-08-29 11:23:34]	Evaluation results at epoch 10 are: ACC: 0.764, NMI: 0.802, ARI: 0.758
[INFO][2021-08-29 11:23:35]	Start to train at 11 epoch with learning rate 0.000010
[INFO][2021-08-29 11:23:35]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-29 11:23:35]	hidx, head: 0, 10
[INFO][2021-08-29 11:23:35]	hidx, head: 1, 10
[INFO][2021-08-29 11:23:35]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-29 11:23:54]	Batch: [  0/313] Head: [0/2] Epoch: [ 11/350] Progress: [0:00:19/1:39:07] Time: 19.002 (19.002) Data: 16.689 (16.689) Loss: 1.6018 (1.6018)
[INFO][2021-08-29 11:28:00]	Batch: [ 30/313] Head: [0/2] Epoch: [ 11/350] Progress: [0:04:25/0:44:38] Time: 13.877 (8.556) Data: 11.587 (6.208) Loss: 1.5991 (1.5912)
[INFO][2021-08-29 11:32:07]	Batch: [ 60/313] Head: [0/2] Epoch: [ 11/350] Progress: [0:08:31/0:43:44] Time: 14.199 (8.383) Data: 11.794 (6.031) Loss: 1.5952 (1.5963)
[INFO][2021-08-29 11:36:13]	Batch: [ 90/313] Head: [0/2] Epoch: [ 11/350] Progress: [0:12:37/0:43:25] Time: 13.915 (8.325) Data: 11.513 (5.963) Loss: 1.5658 (1.5920)
[INFO][2021-08-29 11:40:19]	Batch: [120/313] Head: [0/2] Epoch: [ 11/350] Progress: [0:16:43/0:43:15] Time: 13.983 (8.294) Data: 11.692 (5.929) Loss: 1.6539 (1.5908)
[INFO][2021-08-29 11:44:24]	Batch: [150/313] Head: [0/2] Epoch: [ 11/350] Progress: [0:20:49/0:43:09] Time: 14.034 (8.272) Data: 11.743 (5.914) Loss: 1.6050 (1.5897)
[INFO][2021-08-29 11:48:30]	Batch: [180/313] Head: [0/2] Epoch: [ 11/350] Progress: [0:24:54/0:43:05] Time: 13.898 (8.259) Data: 11.493 (5.900) Loss: 1.5689 (1.5883)
[INFO][2021-08-29 11:52:37]	Batch: [210/313] Head: [0/2] Epoch: [ 11/350] Progress: [0:29:01/0:43:03] Time: 14.084 (8.253) Data: 11.678 (5.892) Loss: 1.5753 (1.5870)
[INFO][2021-08-29 11:56:42]	Batch: [240/313] Head: [0/2] Epoch: [ 11/350] Progress: [0:33:07/0:43:00] Time: 13.956 (8.245) Data: 11.554 (5.882) Loss: 1.5701 (1.5867)
[INFO][2021-08-29 12:00:48]	Batch: [270/313] Head: [0/2] Epoch: [ 11/350] Progress: [0:37:12/0:42:58] Time: 13.811 (8.239) Data: 11.519 (5.875) Loss: 1.5884 (1.5860)
[INFO][2021-08-29 12:04:54]	Batch: [300/313] Head: [0/2] Epoch: [ 11/350] Progress: [0:41:18/0:42:57] Time: 13.980 (8.235) Data: 11.686 (5.871) Loss: 1.5514 (1.5857)
[INFO][2021-08-29 12:06:24]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-29 12:06:43]	Batch: [  0/313] Head: [1/2] Epoch: [ 11/350] Progress: [0:00:18/1:38:55] Time: 18.964 (18.964) Data: 16.650 (16.650) Loss: 1.6359 (1.6359)
[INFO][2021-08-29 12:10:47]	Batch: [ 30/313] Head: [1/2] Epoch: [ 11/350] Progress: [0:04:23/0:44:21] Time: 13.948 (8.504) Data: 11.657 (6.156) Loss: 1.6281 (1.5880)
[INFO][2021-08-29 12:14:52]	Batch: [ 60/313] Head: [1/2] Epoch: [ 11/350] Progress: [0:08:28/0:43:28] Time: 14.025 (8.335) Data: 11.623 (5.973) Loss: 1.6005 (1.5909)
[INFO][2021-08-29 12:18:57]	Batch: [ 90/313] Head: [1/2] Epoch: [ 11/350] Progress: [0:12:33/0:43:10] Time: 13.906 (8.275) Data: 11.505 (5.900) Loss: 1.5426 (1.5936)
[INFO][2021-08-29 12:23:01]	Batch: [120/313] Head: [1/2] Epoch: [ 11/350] Progress: [0:16:37/0:43:00] Time: 13.928 (8.243) Data: 11.527 (5.864) Loss: 1.5644 (1.5915)
[INFO][2021-08-29 12:27:05]	Batch: [150/313] Head: [1/2] Epoch: [ 11/350] Progress: [0:20:41/0:42:53] Time: 13.798 (8.222) Data: 11.506 (5.844) Loss: 1.5789 (1.5898)
[INFO][2021-08-29 12:31:09]	Batch: [180/313] Head: [1/2] Epoch: [ 11/350] Progress: [0:24:45/0:42:49] Time: 13.910 (8.209) Data: 11.620 (5.830) Loss: 1.5255 (1.5886)
[INFO][2021-08-29 12:35:14]	Batch: [210/313] Head: [1/2] Epoch: [ 11/350] Progress: [0:28:50/0:42:46] Time: 13.958 (8.200) Data: 11.554 (5.825) Loss: 1.5979 (1.5875)
[INFO][2021-08-29 12:39:18]	Batch: [240/313] Head: [1/2] Epoch: [ 11/350] Progress: [0:32:54/0:42:44] Time: 13.991 (8.194) Data: 11.590 (5.819) Loss: 1.6142 (1.5863)
[INFO][2021-08-29 12:43:23]	Batch: [270/313] Head: [1/2] Epoch: [ 11/350] Progress: [0:36:59/0:42:43] Time: 13.860 (8.189) Data: 11.455 (5.814) Loss: 1.6519 (1.5860)
[INFO][2021-08-29 12:47:27]	Batch: [300/313] Head: [1/2] Epoch: [ 11/350] Progress: [0:41:03/0:42:41] Time: 13.941 (8.184) Data: 11.652 (5.809) Loss: 1.5925 (1.5846)
[INFO][2021-08-29 12:48:56]	Start to evaluate after 11 epoch of training
[INFO][2021-08-29 12:48:56]	len(loader.dataset)
[INFO][2021-08-29 12:48:56]	5000
[INFO][2021-08-29 12:51:58]	num_classes
[INFO][2021-08-29 12:51:58]	10
[INFO][2021-08-29 12:51:58]	[[   0 2000    0    0    0    0    0    0    0    0]
 [   0    0    5    0    0    0    0    0    0    0]
 [1141    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0  356    0    0    0    0    0    0    0]
 [  54    0  150    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0  476    0    0    0    0    0    0    0]
 [ 734    0   13    0    0    0    0    0    0    0]
 [  71    0    0    0    0    0    0    0    0    0]]
[INFO][2021-08-29 12:51:58]	Evaluation results at epoch 11 are: ACC: 0.723, NMI: 0.784, ARI: 0.738
[INFO][2021-08-29 12:51:59]	Start to train at 12 epoch with learning rate 0.000010
[INFO][2021-08-29 12:51:59]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-29 12:51:59]	hidx, head: 0, 10
[INFO][2021-08-29 12:51:59]	hidx, head: 1, 10
[INFO][2021-08-29 12:51:59]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-29 12:52:18]	Batch: [  0/313] Head: [0/2] Epoch: [ 12/350] Progress: [0:00:19/1:39:21] Time: 19.045 (19.045) Data: 16.727 (16.727) Loss: 1.5695 (1.5695)
[INFO][2021-08-29 12:56:22]	Batch: [ 30/313] Head: [0/2] Epoch: [ 12/350] Progress: [0:04:23/0:44:18] Time: 13.856 (8.492) Data: 11.567 (6.144) Loss: 1.5826 (1.5847)
[INFO][2021-08-29 13:00:26]	Batch: [ 60/313] Head: [0/2] Epoch: [ 12/350] Progress: [0:08:27/0:43:22] Time: 13.698 (8.316) Data: 11.404 (5.964) Loss: 1.5565 (1.5799)
[INFO][2021-08-29 13:04:31]	Batch: [ 90/313] Head: [0/2] Epoch: [ 12/350] Progress: [0:12:31/0:43:04] Time: 13.389 (8.259) Data: 10.987 (5.902) Loss: 1.6158 (1.5861)
[INFO][2021-08-29 13:08:35]	Batch: [120/313] Head: [0/2] Epoch: [ 12/350] Progress: [0:16:35/0:42:56] Time: 13.590 (8.230) Data: 11.188 (5.874) Loss: 1.6156 (1.5840)
[INFO][2021-08-29 13:12:39]	Batch: [150/313] Head: [0/2] Epoch: [ 12/350] Progress: [0:20:40/0:42:50] Time: 13.900 (8.213) Data: 11.497 (5.855) Loss: 1.6022 (1.5864)
[INFO][2021-08-29 13:16:43]	Batch: [180/313] Head: [0/2] Epoch: [ 12/350] Progress: [0:24:44/0:42:46] Time: 13.855 (8.200) Data: 11.561 (5.843) Loss: 1.5575 (1.5866)
[INFO][2021-08-29 13:20:47]	Batch: [210/313] Head: [0/2] Epoch: [ 12/350] Progress: [0:28:48/0:42:43] Time: 13.937 (8.191) Data: 11.533 (5.835) Loss: 1.5608 (1.5850)
[INFO][2021-08-29 13:24:51]	Batch: [240/313] Head: [0/2] Epoch: [ 12/350] Progress: [0:32:52/0:42:41] Time: 13.823 (8.184) Data: 11.530 (5.829) Loss: 1.5767 (1.5846)
[INFO][2021-08-29 13:28:55]	Batch: [270/313] Head: [0/2] Epoch: [ 12/350] Progress: [0:36:56/0:42:39] Time: 13.968 (8.178) Data: 11.565 (5.823) Loss: 1.5792 (1.5847)
[INFO][2021-08-29 13:32:59]	Batch: [300/313] Head: [0/2] Epoch: [ 12/350] Progress: [0:41:00/0:42:38] Time: 13.963 (8.173) Data: 11.562 (5.819) Loss: 1.5451 (1.5840)
[INFO][2021-08-29 13:34:28]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-29 13:34:47]	Batch: [  0/313] Head: [1/2] Epoch: [ 12/350] Progress: [0:00:19/1:39:46] Time: 19.126 (19.126) Data: 16.707 (16.707) Loss: 1.5852 (1.5852)
[INFO][2021-08-29 13:38:51]	Batch: [ 30/313] Head: [1/2] Epoch: [ 12/350] Progress: [0:04:23/0:44:16] Time: 13.886 (8.487) Data: 11.595 (6.151) Loss: 1.6098 (1.5810)
[INFO][2021-08-29 13:42:55]	Batch: [ 60/313] Head: [1/2] Epoch: [ 12/350] Progress: [0:08:27/0:43:23] Time: 13.869 (8.319) Data: 11.468 (5.962) Loss: 1.5796 (1.5789)
[INFO][2021-08-29 13:47:00]	Batch: [ 90/313] Head: [1/2] Epoch: [ 12/350] Progress: [0:12:31/0:43:06] Time: 14.026 (8.263) Data: 11.625 (5.904) Loss: 1.6404 (1.5829)
[INFO][2021-08-29 13:51:04]	Batch: [120/313] Head: [1/2] Epoch: [ 12/350] Progress: [0:16:36/0:42:56] Time: 14.032 (8.233) Data: 11.631 (5.876) Loss: 1.5487 (1.5813)
[INFO][2021-08-29 13:55:08]	Batch: [150/313] Head: [1/2] Epoch: [ 12/350] Progress: [0:20:40/0:42:51] Time: 14.002 (8.215) Data: 11.599 (5.860) Loss: 1.5297 (1.5817)
[INFO][2021-08-29 13:59:12]	Batch: [180/313] Head: [1/2] Epoch: [ 12/350] Progress: [0:24:44/0:42:47] Time: 13.901 (8.203) Data: 11.608 (5.848) Loss: 1.5562 (1.5805)
[INFO][2021-08-29 14:03:17]	Batch: [210/313] Head: [1/2] Epoch: [ 12/350] Progress: [0:28:49/0:42:45] Time: 13.976 (8.196) Data: 11.572 (5.843) Loss: 1.5623 (1.5807)
[INFO][2021-08-29 14:07:21]	Batch: [240/313] Head: [1/2] Epoch: [ 12/350] Progress: [0:32:53/0:42:43] Time: 13.995 (8.190) Data: 11.591 (5.836) Loss: 1.5415 (1.5800)
[INFO][2021-08-29 14:11:26]	Batch: [270/313] Head: [1/2] Epoch: [ 12/350] Progress: [0:36:58/0:42:41] Time: 13.890 (8.185) Data: 11.487 (5.827) Loss: 1.5962 (1.5806)
[INFO][2021-08-29 14:15:30]	Batch: [300/313] Head: [1/2] Epoch: [ 12/350] Progress: [0:41:02/0:42:40] Time: 13.846 (8.181) Data: 11.555 (5.826) Loss: 1.7126 (1.5817)
[INFO][2021-08-29 14:16:59]	Start to evaluate after 12 epoch of training
[INFO][2021-08-29 14:16:59]	len(loader.dataset)
[INFO][2021-08-29 14:16:59]	5000
[INFO][2021-08-29 14:20:03]	num_classes
[INFO][2021-08-29 14:20:03]	10
[INFO][2021-08-29 14:20:03]	[[   0 1915    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [ 735   85    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0  253    0    0    0    0    0    0    0]
 [  98    0  159    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0  578    0    0    0    0    0    0    0]
 [1139    0   10    0    0    0    0    0    0    0]
 [  28    0    0    0    0    0    0    0    0    0]]
[INFO][2021-08-29 14:20:03]	Evaluation results at epoch 12 are: ACC: 0.726, NMI: 0.739, ARI: 0.698
[INFO][2021-08-29 14:20:04]	Start to train at 13 epoch with learning rate 0.000010
[INFO][2021-08-29 14:20:04]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-29 14:20:04]	hidx, head: 0, 10
[INFO][2021-08-29 14:20:04]	hidx, head: 1, 10
[INFO][2021-08-29 14:20:04]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-29 14:20:23]	Batch: [  0/313] Head: [0/2] Epoch: [ 13/350] Progress: [0:00:18/1:38:55] Time: 18.962 (18.962) Data: 16.656 (16.656) Loss: 1.5645 (1.5645)
[INFO][2021-08-29 14:24:28]	Batch: [ 30/313] Head: [0/2] Epoch: [ 13/350] Progress: [0:04:24/0:44:31] Time: 13.955 (8.536) Data: 11.666 (6.179) Loss: 1.5884 (1.5884)
[INFO][2021-08-29 14:28:34]	Batch: [ 60/313] Head: [0/2] Epoch: [ 13/350] Progress: [0:08:30/0:43:38] Time: 13.931 (8.366) Data: 11.531 (5.998) Loss: 1.5988 (1.5820)
[INFO][2021-08-29 14:32:40]	Batch: [ 90/313] Head: [0/2] Epoch: [ 13/350] Progress: [0:12:36/0:43:22] Time: 13.964 (8.314) Data: 11.562 (5.945) Loss: 1.5916 (1.5797)
[INFO][2021-08-29 14:36:46]	Batch: [120/313] Head: [0/2] Epoch: [ 13/350] Progress: [0:16:42/0:43:12] Time: 14.021 (8.283) Data: 11.623 (5.911) Loss: 1.5436 (1.5790)
[INFO][2021-08-29 14:40:52]	Batch: [150/313] Head: [0/2] Epoch: [ 13/350] Progress: [0:20:48/0:43:07] Time: 13.944 (8.266) Data: 11.653 (5.894) Loss: 1.5770 (1.5792)
[INFO][2021-08-29 14:44:57]	Batch: [180/313] Head: [0/2] Epoch: [ 13/350] Progress: [0:24:53/0:43:02] Time: 13.905 (8.252) Data: 11.612 (5.884) Loss: 1.6338 (1.5781)
[INFO][2021-08-29 14:49:03]	Batch: [210/313] Head: [0/2] Epoch: [ 13/350] Progress: [0:28:59/0:43:00] Time: 14.044 (8.243) Data: 11.644 (5.876) Loss: 1.5886 (1.5778)
[INFO][2021-08-29 14:53:09]	Batch: [240/313] Head: [0/2] Epoch: [ 13/350] Progress: [0:33:05/0:42:58] Time: 14.009 (8.238) Data: 11.602 (5.869) Loss: 1.5870 (1.5785)
[INFO][2021-08-29 14:57:15]	Batch: [270/313] Head: [0/2] Epoch: [ 13/350] Progress: [0:37:10/0:42:56] Time: 13.974 (8.232) Data: 11.573 (5.867) Loss: 1.5703 (1.5779)
[INFO][2021-08-29 15:01:21]	Batch: [300/313] Head: [0/2] Epoch: [ 13/350] Progress: [0:41:16/0:42:55] Time: 14.100 (8.229) Data: 11.696 (5.862) Loss: 1.6047 (1.5776)
[INFO][2021-08-29 15:02:50]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-29 15:03:09]	Batch: [  0/313] Head: [1/2] Epoch: [ 13/350] Progress: [0:00:19/1:39:49] Time: 19.135 (19.135) Data: 16.722 (16.722) Loss: 1.5510 (1.5510)
[INFO][2021-08-29 15:07:14]	Batch: [ 30/313] Head: [1/2] Epoch: [ 13/350] Progress: [0:04:24/0:44:27] Time: 13.866 (8.523) Data: 11.465 (6.169) Loss: 1.5610 (1.5725)
[INFO][2021-08-29 15:11:18]	Batch: [ 60/313] Head: [1/2] Epoch: [ 13/350] Progress: [0:08:28/0:43:29] Time: 13.847 (8.338) Data: 11.448 (5.971) Loss: 1.5742 (1.5720)
[INFO][2021-08-29 15:15:23]	Batch: [ 90/313] Head: [1/2] Epoch: [ 13/350] Progress: [0:12:33/0:43:09] Time: 14.035 (8.275) Data: 11.630 (5.913) Loss: 1.5729 (1.5736)
[INFO][2021-08-29 15:19:27]	Batch: [120/313] Head: [1/2] Epoch: [ 13/350] Progress: [0:16:37/0:43:00] Time: 13.833 (8.244) Data: 11.543 (5.879) Loss: 1.5503 (1.5749)
[INFO][2021-08-29 15:23:32]	Batch: [150/313] Head: [1/2] Epoch: [ 13/350] Progress: [0:20:42/0:42:54] Time: 13.882 (8.226) Data: 11.482 (5.863) Loss: 1.5611 (1.5761)
[INFO][2021-08-29 15:27:36]	Batch: [180/313] Head: [1/2] Epoch: [ 13/350] Progress: [0:24:46/0:42:50] Time: 13.879 (8.213) Data: 11.479 (5.849) Loss: 1.5729 (1.5766)
[INFO][2021-08-29 15:31:41]	Batch: [210/313] Head: [1/2] Epoch: [ 13/350] Progress: [0:28:50/0:42:47] Time: 14.081 (8.202) Data: 11.684 (5.842) Loss: 1.5626 (1.5766)
[INFO][2021-08-29 15:35:44]	Batch: [240/313] Head: [1/2] Epoch: [ 13/350] Progress: [0:32:54/0:42:44] Time: 13.751 (8.193) Data: 11.459 (5.832) Loss: 1.5624 (1.5774)
[INFO][2021-08-29 15:39:49]	Batch: [270/313] Head: [1/2] Epoch: [ 13/350] Progress: [0:36:58/0:42:42] Time: 13.766 (8.188) Data: 11.476 (5.828) Loss: 1.5830 (1.5771)
[INFO][2021-08-29 15:43:53]	Batch: [300/313] Head: [1/2] Epoch: [ 13/350] Progress: [0:41:03/0:42:41] Time: 13.863 (8.184) Data: 11.462 (5.824) Loss: 1.6286 (1.5770)
[INFO][2021-08-29 15:45:22]	Start to evaluate after 13 epoch of training
[INFO][2021-08-29 15:45:22]	len(loader.dataset)
[INFO][2021-08-29 15:45:22]	5000
[INFO][2021-08-29 15:48:26]	num_classes
[INFO][2021-08-29 15:48:26]	10
[INFO][2021-08-29 15:48:26]	[[   0 1978    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [ 331   22    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0  213    0    0    0    0    0    0    0]
 [ 110    0  175    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0  608    0    0    0    0    0    0    0]
 [1526    0    4    0    0    0    0    0    0    0]
 [  33    0    0    0    0    0    0    0    0    0]]
[INFO][2021-08-29 15:48:26]	Evaluation results at epoch 13 are: ACC: 0.822, NMI: 0.790, ARI: 0.793
[INFO][2021-08-29 15:48:27]	Start to train at 14 epoch with learning rate 0.000010
[INFO][2021-08-29 15:48:27]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-29 15:48:27]	hidx, head: 0, 10
[INFO][2021-08-29 15:48:27]	hidx, head: 1, 10
[INFO][2021-08-29 15:48:27]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-29 15:48:46]	Batch: [  0/313] Head: [0/2] Epoch: [ 14/350] Progress: [0:00:19/1:39:33] Time: 19.085 (19.085) Data: 16.666 (16.666) Loss: 1.5485 (1.5485)
[INFO][2021-08-29 15:52:51]	Batch: [ 30/313] Head: [0/2] Epoch: [ 14/350] Progress: [0:04:24/0:44:29] Time: 14.038 (8.530) Data: 11.638 (6.165) Loss: 1.6051 (1.5784)
[INFO][2021-08-29 15:56:57]	Batch: [ 60/313] Head: [0/2] Epoch: [ 14/350] Progress: [0:08:29/0:43:35] Time: 14.001 (8.355) Data: 11.711 (5.992) Loss: 1.6105 (1.5828)
[INFO][2021-08-29 16:01:02]	Batch: [ 90/313] Head: [0/2] Epoch: [ 14/350] Progress: [0:12:35/0:43:17] Time: 13.922 (8.298) Data: 11.629 (5.943) Loss: 1.5717 (1.5795)
[INFO][2021-08-29 16:05:08]	Batch: [120/313] Head: [0/2] Epoch: [ 14/350] Progress: [0:16:40/0:43:08] Time: 14.110 (8.270) Data: 11.706 (5.913) Loss: 1.5706 (1.5800)
[INFO][2021-08-29 16:09:13]	Batch: [150/313] Head: [0/2] Epoch: [ 14/350] Progress: [0:20:46/0:43:03] Time: 14.055 (8.253) Data: 11.765 (5.898) Loss: 1.5975 (1.5807)
[INFO][2021-08-29 16:13:19]	Batch: [180/313] Head: [0/2] Epoch: [ 14/350] Progress: [0:24:51/0:42:59] Time: 14.105 (8.243) Data: 11.703 (5.888) Loss: 1.5777 (1.5807)
[INFO][2021-08-29 16:17:24]	Batch: [210/313] Head: [0/2] Epoch: [ 14/350] Progress: [0:28:57/0:42:57] Time: 14.047 (8.233) Data: 11.758 (5.883) Loss: 1.5350 (1.5792)
[INFO][2021-08-29 16:21:30]	Batch: [240/313] Head: [0/2] Epoch: [ 14/350] Progress: [0:33:02/0:42:55] Time: 13.965 (8.228) Data: 11.672 (5.880) Loss: 1.6171 (1.5781)
[INFO][2021-08-29 16:25:36]	Batch: [270/313] Head: [0/2] Epoch: [ 14/350] Progress: [0:37:08/0:42:54] Time: 14.122 (8.224) Data: 11.724 (5.876) Loss: 1.5778 (1.5777)
[INFO][2021-08-29 16:29:41]	Batch: [300/313] Head: [0/2] Epoch: [ 14/350] Progress: [0:41:14/0:42:52] Time: 14.042 (8.220) Data: 11.752 (5.870) Loss: 1.5602 (1.5767)
[INFO][2021-08-29 16:31:11]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-29 16:31:29]	Batch: [  0/313] Head: [1/2] Epoch: [ 14/350] Progress: [0:00:18/1:38:49] Time: 18.944 (18.944) Data: 16.523 (16.523) Loss: 1.5383 (1.5383)
[INFO][2021-08-29 16:35:34]	Batch: [ 30/313] Head: [1/2] Epoch: [ 14/350] Progress: [0:04:23/0:44:18] Time: 14.014 (8.492) Data: 11.613 (6.108) Loss: 1.5735 (1.5836)
[INFO][2021-08-29 16:39:38]	Batch: [ 60/313] Head: [1/2] Epoch: [ 14/350] Progress: [0:08:27/0:43:25] Time: 13.892 (8.323) Data: 11.602 (5.942) Loss: 1.6019 (1.5783)
[INFO][2021-08-29 16:43:43]	Batch: [ 90/313] Head: [1/2] Epoch: [ 14/350] Progress: [0:12:32/0:43:07] Time: 13.064 (8.267) Data: 10.662 (5.896) Loss: 1.5557 (1.5760)
[INFO][2021-08-29 16:47:47]	Batch: [120/313] Head: [1/2] Epoch: [ 14/350] Progress: [0:16:36/0:42:57] Time: 11.766 (8.235) Data: 9.472 (5.867) Loss: 1.5961 (1.5757)
[INFO][2021-08-29 16:51:51]	Batch: [150/313] Head: [1/2] Epoch: [ 14/350] Progress: [0:20:40/0:42:51] Time: 10.299 (8.217) Data: 8.009 (5.854) Loss: 1.6196 (1.5760)
[INFO][2021-08-29 16:55:56]	Batch: [180/313] Head: [1/2] Epoch: [ 14/350] Progress: [0:24:45/0:42:48] Time: 8.888 (8.205) Data: 6.596 (5.841) Loss: 1.6187 (1.5741)
[INFO][2021-08-29 17:00:00]	Batch: [210/313] Head: [1/2] Epoch: [ 14/350] Progress: [0:28:49/0:42:45] Time: 7.303 (8.197) Data: 5.012 (5.836) Loss: 1.5957 (1.5742)
[INFO][2021-08-29 17:04:04]	Batch: [240/313] Head: [1/2] Epoch: [ 14/350] Progress: [0:32:53/0:42:43] Time: 6.096 (8.191) Data: 3.805 (5.835) Loss: 1.5798 (1.5745)
[INFO][2021-08-29 17:08:09]	Batch: [270/313] Head: [1/2] Epoch: [ 14/350] Progress: [0:36:58/0:42:42] Time: 4.583 (8.186) Data: 2.181 (5.831) Loss: 1.5769 (1.5760)
[INFO][2021-08-29 17:12:13]	Batch: [300/313] Head: [1/2] Epoch: [ 14/350] Progress: [0:41:02/0:42:40] Time: 3.185 (8.181) Data: 0.787 (5.827) Loss: 1.6091 (1.5762)
[INFO][2021-08-29 17:13:49]	Start to evaluate after 14 epoch of training
[INFO][2021-08-29 17:13:49]	len(loader.dataset)
[INFO][2021-08-29 17:13:49]	5000
[INFO][2021-08-29 17:16:52]	num_classes
[INFO][2021-08-29 17:16:52]	10
[INFO][2021-08-29 17:16:52]	[[   0 1908    0    0    0    0    0    0    0    0]
 [   0    0    4    0    0    0    0    0    0    0]
 [ 731    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0  489    0    0    0    0    0    0    0]
 [ 241    0   99    0    0    0    0    0    0    0]
 [   0   92    0    0    0    0    0    0    0    0]
 [   0    0  405    0    0    0    0    0    0    0]
 [1007    0    3    0    0    0    0    0    0    0]
 [  21    0    0    0    0    0    0    0    0    0]]
[INFO][2021-08-29 17:16:52]	Evaluation results at epoch 14 are: ACC: 0.681, NMI: 0.757, ARI: 0.681
[INFO][2021-08-29 17:16:53]	Start to train at 15 epoch with learning rate 0.000010
[INFO][2021-08-29 17:16:53]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-29 17:16:53]	hidx, head: 0, 10
[INFO][2021-08-29 17:16:53]	hidx, head: 1, 10
[INFO][2021-08-29 17:16:53]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-29 17:17:12]	Batch: [  0/313] Head: [0/2] Epoch: [ 15/350] Progress: [0:00:19/1:40:02] Time: 19.178 (19.178) Data: 16.758 (16.758) Loss: 1.5746 (1.5746)
[INFO][2021-08-29 17:21:17]	Batch: [ 30/313] Head: [0/2] Epoch: [ 15/350] Progress: [0:04:24/0:44:30] Time: 14.139 (8.533) Data: 11.740 (6.167) Loss: 1.5758 (1.5753)
[INFO][2021-08-29 17:25:23]	Batch: [ 60/313] Head: [0/2] Epoch: [ 15/350] Progress: [0:08:29/0:43:36] Time: 13.937 (8.359) Data: 11.536 (6.002) Loss: 1.5745 (1.5717)
[INFO][2021-08-29 17:29:28]	Batch: [ 90/313] Head: [0/2] Epoch: [ 15/350] Progress: [0:12:35/0:43:18] Time: 13.935 (8.302) Data: 11.644 (5.952) Loss: 1.5641 (1.5737)
[INFO][2021-08-29 17:33:34]	Batch: [120/313] Head: [0/2] Epoch: [ 15/350] Progress: [0:16:40/0:43:09] Time: 13.993 (8.273) Data: 11.702 (5.927) Loss: 1.5923 (1.5743)
[INFO][2021-08-29 17:37:39]	Batch: [150/313] Head: [0/2] Epoch: [ 15/350] Progress: [0:20:46/0:43:02] Time: 14.020 (8.252) Data: 11.731 (5.909) Loss: 1.5865 (1.5746)
[INFO][2021-08-29 17:41:43]	Batch: [180/313] Head: [0/2] Epoch: [ 15/350] Progress: [0:24:50/0:42:57] Time: 13.911 (8.235) Data: 11.511 (5.888) Loss: 1.5873 (1.5750)
[INFO][2021-08-29 17:45:48]	Batch: [210/313] Head: [0/2] Epoch: [ 15/350] Progress: [0:28:55/0:42:54] Time: 13.947 (8.225) Data: 11.540 (5.870) Loss: 1.5912 (1.5754)
[INFO][2021-08-29 17:49:53]	Batch: [240/313] Head: [0/2] Epoch: [ 15/350] Progress: [0:33:00/0:42:52] Time: 13.944 (8.217) Data: 11.651 (5.862) Loss: 1.5499 (1.5751)
[INFO][2021-08-29 17:53:58]	Batch: [270/313] Head: [0/2] Epoch: [ 15/350] Progress: [0:37:05/0:42:50] Time: 13.910 (8.211) Data: 11.511 (5.853) Loss: 1.5704 (1.5748)
[INFO][2021-08-29 17:58:03]	Batch: [300/313] Head: [0/2] Epoch: [ 15/350] Progress: [0:41:10/0:42:48] Time: 13.944 (8.208) Data: 11.537 (5.848) Loss: 1.6000 (1.5748)
[INFO][2021-08-29 17:59:32]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-29 17:59:51]	Batch: [  0/313] Head: [1/2] Epoch: [ 15/350] Progress: [0:00:19/1:39:45] Time: 19.123 (19.123) Data: 16.813 (16.813) Loss: 1.5620 (1.5620)
[INFO][2021-08-29 18:03:57]	Batch: [ 30/313] Head: [1/2] Epoch: [ 15/350] Progress: [0:04:25/0:44:37] Time: 14.201 (8.555) Data: 11.805 (6.210) Loss: 1.5480 (1.5644)
[INFO][2021-08-29 18:08:03]	Batch: [ 60/313] Head: [1/2] Epoch: [ 15/350] Progress: [0:08:31/0:43:43] Time: 13.877 (8.383) Data: 11.477 (6.030) Loss: 1.5927 (1.5657)
[INFO][2021-08-29 18:12:08]	Batch: [ 90/313] Head: [1/2] Epoch: [ 15/350] Progress: [0:12:35/0:43:18] Time: 13.898 (8.303) Data: 11.609 (5.944) Loss: 1.5430 (1.5667)
[INFO][2021-08-29 18:16:12]	Batch: [120/313] Head: [1/2] Epoch: [ 15/350] Progress: [0:16:39/0:43:05] Time: 13.793 (8.262) Data: 11.500 (5.904) Loss: 1.5429 (1.5686)
[INFO][2021-08-29 18:20:16]	Batch: [150/313] Head: [1/2] Epoch: [ 15/350] Progress: [0:20:43/0:42:58] Time: 13.916 (8.238) Data: 11.625 (5.887) Loss: 1.5748 (1.5686)
[INFO][2021-08-29 18:24:20]	Batch: [180/313] Head: [1/2] Epoch: [ 15/350] Progress: [0:24:48/0:42:53] Time: 14.046 (8.222) Data: 11.644 (5.875) Loss: 1.5766 (1.5698)
[INFO][2021-08-29 18:28:24]	Batch: [210/313] Head: [1/2] Epoch: [ 15/350] Progress: [0:28:52/0:42:49] Time: 14.065 (8.209) Data: 11.667 (5.858) Loss: 1.5680 (1.5704)
[INFO][2021-08-29 18:32:28]	Batch: [240/313] Head: [1/2] Epoch: [ 15/350] Progress: [0:32:55/0:42:46] Time: 13.888 (8.199) Data: 11.595 (5.846) Loss: 1.5849 (1.5702)
[INFO][2021-08-29 18:36:32]	Batch: [270/313] Head: [1/2] Epoch: [ 15/350] Progress: [0:37:00/0:42:44] Time: 13.825 (8.192) Data: 11.424 (5.838) Loss: 1.5450 (1.5698)
[INFO][2021-08-29 18:40:36]	Batch: [300/313] Head: [1/2] Epoch: [ 15/350] Progress: [0:41:03/0:42:42] Time: 14.050 (8.186) Data: 11.648 (5.829) Loss: 1.5546 (1.5704)
[INFO][2021-08-29 18:42:05]	Start to evaluate after 15 epoch of training
[INFO][2021-08-29 18:42:05]	len(loader.dataset)
[INFO][2021-08-29 18:42:05]	5000
[INFO][2021-08-29 18:45:09]	num_classes
[INFO][2021-08-29 18:45:09]	10
[INFO][2021-08-29 18:45:09]	[[   0 1995    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [1025    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0  112    0    0    0    0    0    0    0]
 [  58    0  285    0    0    0    0    0    0    0]
 [   0    5    0    0    0    0    0    0    0    0]
 [   0    0  592    0    0    0    0    0    0    0]
 [ 886    0   11    0    0    0    0    0    0    0]
 [  31    0    0    0    0    0    0    0    0    0]]
[INFO][2021-08-29 18:45:09]	Evaluation results at epoch 15 are: ACC: 0.722, NMI: 0.789, ARI: 0.741
[INFO][2021-08-29 18:45:09]	Start to train at 16 epoch with learning rate 0.000010
[INFO][2021-08-29 18:45:09]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-29 18:45:09]	hidx, head: 0, 10
[INFO][2021-08-29 18:45:09]	hidx, head: 1, 10
[INFO][2021-08-29 18:45:09]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-29 18:45:28]	Batch: [  0/313] Head: [0/2] Epoch: [ 16/350] Progress: [0:00:18/1:38:24] Time: 18.864 (18.864) Data: 16.554 (16.554) Loss: 1.5694 (1.5694)
[INFO][2021-08-29 18:49:32]	Batch: [ 30/313] Head: [0/2] Epoch: [ 16/350] Progress: [0:04:22/0:44:12] Time: 13.874 (8.474) Data: 11.585 (6.133) Loss: 1.5661 (1.5662)
[INFO][2021-08-29 18:53:36]	Batch: [ 60/313] Head: [0/2] Epoch: [ 16/350] Progress: [0:08:26/0:43:20] Time: 13.859 (8.308) Data: 11.569 (5.955) Loss: 1.6024 (1.5662)
[INFO][2021-08-29 18:57:40]	Batch: [ 90/313] Head: [0/2] Epoch: [ 16/350] Progress: [0:12:31/0:43:03] Time: 13.575 (8.256) Data: 11.281 (5.917) Loss: 1.5523 (1.5738)
[INFO][2021-08-29 19:01:44]	Batch: [120/313] Head: [0/2] Epoch: [ 16/350] Progress: [0:16:35/0:42:54] Time: 12.393 (8.225) Data: 10.099 (5.887) Loss: 1.5630 (1.5731)
[INFO][2021-08-29 19:05:48]	Batch: [150/313] Head: [0/2] Epoch: [ 16/350] Progress: [0:20:39/0:42:48] Time: 11.692 (8.206) Data: 9.399 (5.873) Loss: 1.6007 (1.5727)
[INFO][2021-08-29 19:09:52]	Batch: [180/313] Head: [0/2] Epoch: [ 16/350] Progress: [0:24:43/0:42:44] Time: 10.821 (8.195) Data: 8.419 (5.856) Loss: 1.5705 (1.5723)
[INFO][2021-08-29 19:13:57]	Batch: [210/313] Head: [0/2] Epoch: [ 16/350] Progress: [0:28:47/0:42:42] Time: 9.814 (8.188) Data: 7.412 (5.845) Loss: 1.6047 (1.5730)
[INFO][2021-08-29 19:18:01]	Batch: [240/313] Head: [0/2] Epoch: [ 16/350] Progress: [0:32:51/0:42:40] Time: 8.554 (8.181) Data: 6.265 (5.842) Loss: 1.6015 (1.5737)
[INFO][2021-08-29 19:22:05]	Batch: [270/313] Head: [0/2] Epoch: [ 16/350] Progress: [0:36:55/0:42:39] Time: 7.041 (8.176) Data: 4.638 (5.838) Loss: 1.5654 (1.5738)
[INFO][2021-08-29 19:26:09]	Batch: [300/313] Head: [0/2] Epoch: [ 16/350] Progress: [0:40:59/0:42:37] Time: 5.548 (8.172) Data: 3.150 (5.833) Loss: 1.5508 (1.5741)
[INFO][2021-08-29 19:27:43]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-29 19:28:02]	Batch: [  0/313] Head: [1/2] Epoch: [ 16/350] Progress: [0:00:18/1:39:04] Time: 18.992 (18.992) Data: 16.686 (16.686) Loss: 1.5725 (1.5725)
[INFO][2021-08-29 19:32:06]	Batch: [ 30/313] Head: [1/2] Epoch: [ 16/350] Progress: [0:04:23/0:44:19] Time: 13.859 (8.495) Data: 11.566 (6.150) Loss: 1.5793 (1.5779)
[INFO][2021-08-29 19:36:11]	Batch: [ 60/313] Head: [1/2] Epoch: [ 16/350] Progress: [0:08:27/0:43:25] Time: 13.892 (8.323) Data: 11.491 (5.967) Loss: 1.5741 (1.5697)
[INFO][2021-08-29 19:40:15]	Batch: [ 90/313] Head: [1/2] Epoch: [ 16/350] Progress: [0:12:32/0:43:06] Time: 13.768 (8.264) Data: 11.364 (5.899) Loss: 1.5634 (1.5698)
[INFO][2021-08-29 19:44:19]	Batch: [120/313] Head: [1/2] Epoch: [ 16/350] Progress: [0:16:36/0:42:56] Time: 11.906 (8.233) Data: 9.506 (5.867) Loss: 1.5680 (1.5676)
[INFO][2021-08-29 19:48:23]	Batch: [150/313] Head: [1/2] Epoch: [ 16/350] Progress: [0:20:40/0:42:51] Time: 9.640 (8.215) Data: 7.236 (5.852) Loss: 1.5771 (1.5670)
[INFO][2021-08-29 19:52:27]	Batch: [180/313] Head: [1/2] Epoch: [ 16/350] Progress: [0:24:44/0:42:46] Time: 7.375 (8.201) Data: 4.975 (5.839) Loss: 1.5957 (1.5701)
[INFO][2021-08-29 19:56:31]	Batch: [210/313] Head: [1/2] Epoch: [ 16/350] Progress: [0:28:48/0:42:43] Time: 4.802 (8.190) Data: 2.515 (5.827) Loss: 1.5783 (1.5710)
[INFO][2021-08-29 20:00:35]	Batch: [240/313] Head: [1/2] Epoch: [ 16/350] Progress: [0:32:52/0:42:41] Time: 2.508 (8.185) Data: 0.109 (5.821) Loss: 1.5789 (1.5702)
[INFO][2021-08-29 20:04:42]	Batch: [270/313] Head: [1/2] Epoch: [ 16/350] Progress: [0:36:59/0:42:43] Time: 2.287 (8.189) Data: 0.001 (5.823) Loss: 1.5733 (1.5706)
[INFO][2021-08-29 20:08:49]	Batch: [300/313] Head: [1/2] Epoch: [ 16/350] Progress: [0:41:06/0:42:44] Time: 2.397 (8.193) Data: 0.001 (5.825) Loss: 1.5578 (1.5700)
[INFO][2021-08-29 20:10:26]	Start to evaluate after 16 epoch of training
[INFO][2021-08-29 20:10:26]	len(loader.dataset)
[INFO][2021-08-29 20:10:26]	5000
[INFO][2021-08-29 20:13:31]	num_classes
[INFO][2021-08-29 20:13:31]	10
[INFO][2021-08-29 20:13:31]	[[   0 1996    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [1272    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0  144    0    0    0    0    0    0    0]
 [   2    0  223    0    0    0    0    0    0    0]
 [   0    4    0    0    0    0    0    0    0    0]
 [   0    0  603    0    0    0    0    0    0    0]
 [ 686    0   30    0    0    0    0    0    0    0]
 [  40    0    0    0    0    0    0    0    0    0]]
[INFO][2021-08-29 20:13:31]	Evaluation results at epoch 16 are: ACC: 0.774, NMI: 0.808, ARI: 0.766
[INFO][2021-08-29 20:13:32]	Start to train at 17 epoch with learning rate 0.000010
[INFO][2021-08-29 20:13:32]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-29 20:13:32]	hidx, head: 0, 10
[INFO][2021-08-29 20:13:32]	hidx, head: 1, 10
[INFO][2021-08-29 20:13:32]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-29 20:13:51]	Batch: [  0/313] Head: [0/2] Epoch: [ 17/350] Progress: [0:00:19/1:39:30] Time: 19.076 (19.076) Data: 16.766 (16.766) Loss: 1.5305 (1.5305)
[INFO][2021-08-29 20:17:56]	Batch: [ 30/313] Head: [0/2] Epoch: [ 17/350] Progress: [0:04:24/0:44:30] Time: 13.898 (8.530) Data: 11.606 (6.183) Loss: 1.5859 (1.5725)
[INFO][2021-08-29 20:22:01]	Batch: [ 60/313] Head: [0/2] Epoch: [ 17/350] Progress: [0:08:29/0:43:33] Time: 14.115 (8.349) Data: 11.716 (6.006) Loss: 1.5513 (1.5716)
[INFO][2021-08-29 20:26:05]	Batch: [ 90/313] Head: [0/2] Epoch: [ 17/350] Progress: [0:12:33/0:43:11] Time: 13.890 (8.280) Data: 11.594 (5.939) Loss: 1.6164 (1.5726)
[INFO][2021-08-29 20:30:09]	Batch: [120/313] Head: [0/2] Epoch: [ 17/350] Progress: [0:16:37/0:43:00] Time: 13.762 (8.245) Data: 11.474 (5.908) Loss: 1.5936 (1.5721)
[INFO][2021-08-29 20:34:13]	Batch: [150/313] Head: [0/2] Epoch: [ 17/350] Progress: [0:20:41/0:42:53] Time: 13.774 (8.222) Data: 11.485 (5.879) Loss: 1.5654 (1.5711)
[INFO][2021-08-29 20:38:18]	Batch: [180/313] Head: [0/2] Epoch: [ 17/350] Progress: [0:24:45/0:42:49] Time: 14.009 (8.209) Data: 11.608 (5.865) Loss: 1.5750 (1.5710)
[INFO][2021-08-29 20:42:22]	Batch: [210/313] Head: [0/2] Epoch: [ 17/350] Progress: [0:28:50/0:42:46] Time: 13.997 (8.200) Data: 11.592 (5.852) Loss: 1.5592 (1.5704)
[DEBUG][2021-08-30 03:20:26]	Provided arguments will be stored in sessions/pickle10/config.yaml
[INFO][2021-08-30 03:20:26]	Start to declare training variable
[INFO][2021-08-30 03:20:26]	Session will be ran in device: [cuda]
[INFO][2021-08-30 03:20:26]	Start to prepare data
[INFO][2021-08-30 03:20:27]	otrainset----------------------: length 20000
[INFO][2021-08-30 03:20:28]	ptrainset----------------------: length 20000
[INFO][2021-08-30 03:20:28]	testset-------------: length 5000
[INFO][2021-08-30 03:20:28]	Start to build model
[DEBUG][2021-08-30 03:20:28]	Backbone [resnet34] is declared with cin [1] and cout [1000] [with] sobel
[DEBUG][2021-08-30 03:20:28]	Backbone will be created wit the following heads: [10, 10]
[DEBUG][2021-08-30 03:20:28]	Number of trainable parameters is [112]
[DEBUG][2021-08-30 03:20:28]	Number of frozen parameters is [2]
[DEBUG][2021-08-30 03:20:28]	Name of frozen parameters are: dict_keys(['sobel.0.weight', 'sobel.0.bias'])
[DEBUG][2021-08-30 03:20:28]	Going to use [Adam] optimizer for training with betas (0.9, 0.999), eps 0.000000, weight decay 0.000000 without amsgrad
[DEBUG][2021-08-30 03:20:28]	Going to use [fixed] learning policy for optimization with base learning rate [0.00001]
[INFO][2021-08-30 03:20:29]	Start to resume session for file: [sessions/pickle10/checkpoint/latest.ckpt]
[DEBUG][2021-08-30 03:20:29]	Totally loaded [222] parameters
[INFO][2021-08-30 03:20:29]	Data parallel will be used for acceleration purpose
[INFO][2021-08-30 03:20:29]	Start to train at 17 epoch with learning rate 0.000010
[INFO][2021-08-30 03:20:29]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-30 03:20:29]	hidx, head: 0, 10
[INFO][2021-08-30 03:20:29]	hidx, head: 1, 10
[INFO][2021-08-30 03:20:29]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-30 03:21:07]	Batch: [  0/313] Head: [0/2] Epoch: [ 17/350] Progress: [0:00:38/3:21:16] Time: 38.583 (38.583) Data: 28.175 (28.175) Loss: 1.6084 (1.6084)
[INFO][2021-08-30 03:25:16]	Batch: [ 30/313] Head: [0/2] Epoch: [ 17/350] Progress: [0:04:46/0:48:15] Time: 14.249 (9.252) Data: 11.836 (6.612) Loss: 1.5679 (1.5679)
[INFO][2021-08-30 03:29:33]	Batch: [ 60/313] Head: [0/2] Epoch: [ 17/350] Progress: [0:09:04/0:46:33] Time: 14.466 (8.926) Data: 12.163 (6.427) Loss: 1.5594 (1.5682)
[INFO][2021-08-30 03:33:50]	Batch: [ 90/313] Head: [0/2] Epoch: [ 17/350] Progress: [0:13:21/0:45:55] Time: 14.876 (8.804) Data: 12.572 (6.363) Loss: 1.5864 (1.5659)
[INFO][2021-08-30 03:38:06]	Batch: [120/313] Head: [0/2] Epoch: [ 17/350] Progress: [0:17:37/0:45:34] Time: 13.174 (8.737) Data: 10.759 (6.322) Loss: 1.5959 (1.5691)
[INFO][2021-08-30 03:42:23]	Batch: [150/313] Head: [0/2] Epoch: [ 17/350] Progress: [0:21:53/0:45:23] Time: 12.775 (8.701) Data: 10.365 (6.289) Loss: 1.5611 (1.5692)
[INFO][2021-08-30 03:46:40]	Batch: [180/313] Head: [0/2] Epoch: [ 17/350] Progress: [0:26:11/0:45:17] Time: 11.749 (8.681) Data: 9.338 (6.275) Loss: 1.5520 (1.5686)
[INFO][2021-08-30 03:50:56]	Batch: [210/313] Head: [0/2] Epoch: [ 17/350] Progress: [0:30:27/0:45:11] Time: 10.582 (8.662) Data: 8.174 (6.259) Loss: 1.5594 (1.5682)
[INFO][2021-08-30 03:55:12]	Batch: [240/313] Head: [0/2] Epoch: [ 17/350] Progress: [0:34:43/0:45:06] Time: 9.255 (8.646) Data: 6.950 (6.246) Loss: 1.5800 (1.5677)
[INFO][2021-08-30 03:59:28]	Batch: [270/313] Head: [0/2] Epoch: [ 17/350] Progress: [0:38:59/0:45:01] Time: 6.415 (8.632) Data: 4.000 (6.234) Loss: 1.5646 (1.5684)
[INFO][2021-08-30 04:03:45]	Batch: [300/313] Head: [0/2] Epoch: [ 17/350] Progress: [0:43:15/0:44:59] Time: 6.052 (8.624) Data: 3.748 (6.231) Loss: 1.5451 (1.5681)
[INFO][2021-08-30 04:05:23]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-30 04:05:43]	Batch: [  0/313] Head: [1/2] Epoch: [ 17/350] Progress: [0:00:19/1:42:01] Time: 19.557 (19.557) Data: 17.144 (17.144) Loss: 1.5537 (1.5537)
[INFO][2021-08-30 04:09:58]	Batch: [ 30/313] Head: [1/2] Epoch: [ 17/350] Progress: [0:04:34/0:46:12] Time: 14.801 (8.858) Data: 12.429 (6.527) Loss: 1.5440 (1.5704)
[INFO][2021-08-30 04:14:11]	Batch: [ 60/313] Head: [1/2] Epoch: [ 17/350] Progress: [0:08:48/0:45:09] Time: 14.445 (8.656) Data: 12.069 (6.314) Loss: 1.5398 (1.5666)
[INFO][2021-08-30 04:18:26]	Batch: [ 90/313] Head: [1/2] Epoch: [ 17/350] Progress: [0:13:02/0:44:52] Time: 14.610 (8.603) Data: 12.321 (6.263) Loss: 1.5611 (1.5679)
[INFO][2021-08-30 04:22:42]	Batch: [120/313] Head: [1/2] Epoch: [ 17/350] Progress: [0:17:18/0:44:47] Time: 14.672 (8.585) Data: 12.296 (6.248) Loss: 1.5576 (1.5670)
[INFO][2021-08-30 04:26:58]	Batch: [150/313] Head: [1/2] Epoch: [ 17/350] Progress: [0:21:34/0:44:42] Time: 14.526 (8.570) Data: 12.236 (6.237) Loss: 1.5594 (1.5662)
[INFO][2021-08-30 04:31:11]	Batch: [180/313] Head: [1/2] Epoch: [ 17/350] Progress: [0:25:47/0:44:35] Time: 14.800 (8.548) Data: 12.512 (6.215) Loss: 1.5650 (1.5658)
[INFO][2021-08-30 04:35:23]	Batch: [210/313] Head: [1/2] Epoch: [ 17/350] Progress: [0:29:59/0:44:29] Time: 14.378 (8.529) Data: 12.086 (6.195) Loss: 1.5507 (1.5664)
[INFO][2021-08-30 04:39:37]	Batch: [240/313] Head: [1/2] Epoch: [ 17/350] Progress: [0:34:13/0:44:26] Time: 14.492 (8.520) Data: 12.200 (6.187) Loss: 1.5666 (1.5661)
[INFO][2021-08-30 04:43:50]	Batch: [270/313] Head: [1/2] Epoch: [ 17/350] Progress: [0:38:26/0:44:24] Time: 14.838 (8.512) Data: 12.466 (6.180) Loss: 1.5774 (1.5656)
[INFO][2021-08-30 04:48:03]	Batch: [300/313] Head: [1/2] Epoch: [ 17/350] Progress: [0:42:39/0:44:21] Time: 14.950 (8.503) Data: 12.659 (6.171) Loss: 1.5607 (1.5655)
[INFO][2021-08-30 04:49:35]	Start to evaluate after 17 epoch of training
[INFO][2021-08-30 04:49:35]	len(loader.dataset)
[INFO][2021-08-30 04:49:35]	5000
[INFO][2021-08-30 04:52:43]	num_classes
[INFO][2021-08-30 04:52:43]	10
[INFO][2021-08-30 04:52:43]	[[   0 1985    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [1269    0    0    0    0    0    0    0    0    0]
 [   0    3    0    0    0    0    0    0    0    0]
 [   0    0  227    0    0    0    0    0    0    0]
 [   3    0  220    0    0    0    0    0    0    0]
 [   0   12    0    0    0    0    0    0    0    0]
 [   0    0  525    0    0    0    0    0    0    0]
 [ 643    0   28    0    0    0    0    0    0    0]
 [  85    0    0    0    0    0    0    0    0    0]]
[INFO][2021-08-30 04:52:43]	Evaluation results at epoch 17 are: ACC: 0.756, NMI: 0.795, ARI: 0.751
[INFO][2021-08-30 04:52:44]	Start to train at 18 epoch with learning rate 0.000010
[INFO][2021-08-30 04:52:44]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-30 04:52:44]	hidx, head: 0, 10
[INFO][2021-08-30 04:52:44]	hidx, head: 1, 10
[INFO][2021-08-30 04:52:44]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-30 04:53:04]	Batch: [  0/313] Head: [0/2] Epoch: [ 18/350] Progress: [0:00:19/1:43:36] Time: 19.861 (19.861) Data: 17.436 (17.436) Loss: 1.5517 (1.5517)
[INFO][2021-08-30 04:57:17]	Batch: [ 30/313] Head: [0/2] Epoch: [ 18/350] Progress: [0:04:33/0:46:01] Time: 14.551 (8.822) Data: 12.248 (6.485) Loss: 1.5526 (1.5686)
[INFO][2021-08-30 05:01:30]	Batch: [ 60/313] Head: [0/2] Epoch: [ 18/350] Progress: [0:08:45/0:44:56] Time: 14.342 (8.616) Data: 12.042 (6.259) Loss: 1.5802 (1.5650)
[INFO][2021-08-30 05:05:43]	Batch: [ 90/313] Head: [0/2] Epoch: [ 18/350] Progress: [0:12:58/0:44:39] Time: 14.652 (8.560) Data: 12.240 (6.206) Loss: 1.5308 (1.5654)
[INFO][2021-08-30 05:09:55]	Batch: [120/313] Head: [0/2] Epoch: [ 18/350] Progress: [0:17:11/0:44:28] Time: 14.445 (8.525) Data: 12.146 (6.166) Loss: 1.5615 (1.5648)
[INFO][2021-08-30 05:14:09]	Batch: [150/313] Head: [0/2] Epoch: [ 18/350] Progress: [0:21:25/0:44:24] Time: 14.876 (8.511) Data: 12.579 (6.155) Loss: 1.5633 (1.5660)
[INFO][2021-08-30 05:18:23]	Batch: [180/313] Head: [0/2] Epoch: [ 18/350] Progress: [0:25:39/0:44:21] Time: 14.340 (8.503) Data: 12.036 (6.144) Loss: 1.5411 (1.5657)
[INFO][2021-08-30 05:22:37]	Batch: [210/313] Head: [0/2] Epoch: [ 18/350] Progress: [0:29:52/0:44:19] Time: 14.869 (8.497) Data: 12.457 (6.141) Loss: 1.5720 (1.5661)
[INFO][2021-08-30 05:26:53]	Batch: [240/313] Head: [0/2] Epoch: [ 18/350] Progress: [0:34:09/0:44:21] Time: 14.602 (8.502) Data: 12.303 (6.148) Loss: 1.5438 (1.5653)
[INFO][2021-08-30 05:31:07]	Batch: [270/313] Head: [0/2] Epoch: [ 18/350] Progress: [0:38:23/0:44:19] Time: 14.760 (8.498) Data: 12.347 (6.142) Loss: 1.5521 (1.5653)
[INFO][2021-08-30 05:35:21]	Batch: [300/313] Head: [0/2] Epoch: [ 18/350] Progress: [0:42:36/0:44:18] Time: 14.492 (8.495) Data: 12.082 (6.136) Loss: 1.5585 (1.5648)
[INFO][2021-08-30 05:36:53]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-30 05:37:13]	Batch: [  0/313] Head: [1/2] Epoch: [ 18/350] Progress: [0:00:19/1:42:16] Time: 19.607 (19.607) Data: 17.302 (17.302) Loss: 1.5540 (1.5540)
[INFO][2021-08-30 05:41:28]	Batch: [ 30/313] Head: [1/2] Epoch: [ 18/350] Progress: [0:04:34/0:46:10] Time: 14.875 (8.851) Data: 12.575 (6.486) Loss: 1.5776 (1.5596)
[INFO][2021-08-30 05:45:40]	Batch: [ 60/313] Head: [1/2] Epoch: [ 18/350] Progress: [0:08:47/0:45:04] Time: 10.909 (8.642) Data: 8.608 (6.283) Loss: 1.5564 (1.5635)
[INFO][2021-08-30 05:49:53]	Batch: [ 90/313] Head: [1/2] Epoch: [ 18/350] Progress: [0:12:59/0:44:41] Time: 5.213 (8.567) Data: 2.914 (6.211) Loss: 1.5513 (1.5630)
[INFO][2021-08-30 05:54:07]	Batch: [120/313] Head: [1/2] Epoch: [ 18/350] Progress: [0:17:13/0:44:33] Time: 2.413 (8.541) Data: 0.001 (6.192) Loss: 1.5468 (1.5619)
[INFO][2021-08-30 05:58:24]	Batch: [150/313] Head: [1/2] Epoch: [ 18/350] Progress: [0:21:31/0:44:36] Time: 2.299 (8.550) Data: 0.001 (6.200) Loss: 1.5765 (1.5630)
[INFO][2021-08-30 06:02:40]	Batch: [180/313] Head: [1/2] Epoch: [ 18/350] Progress: [0:25:46/0:44:34] Time: 2.411 (8.545) Data: 0.001 (6.192) Loss: 1.5604 (1.5640)
[INFO][2021-08-30 06:06:58]	Batch: [210/313] Head: [1/2] Epoch: [ 18/350] Progress: [0:30:04/0:44:36] Time: 2.296 (8.552) Data: 0.001 (6.199) Loss: 1.5613 (1.5637)
[INFO][2021-08-30 06:11:14]	Batch: [240/313] Head: [1/2] Epoch: [ 18/350] Progress: [0:34:20/0:44:36] Time: 2.407 (8.550) Data: 0.001 (6.193) Loss: 1.5809 (1.5653)
[INFO][2021-08-30 06:15:26]	Batch: [270/313] Head: [1/2] Epoch: [ 18/350] Progress: [0:38:33/0:44:31] Time: 2.412 (8.536) Data: 0.001 (6.179) Loss: 1.5404 (1.5646)
[INFO][2021-08-30 06:19:40]	Batch: [300/313] Head: [1/2] Epoch: [ 18/350] Progress: [0:42:46/0:44:28] Time: 2.413 (8.527) Data: 0.001 (6.168) Loss: 1.5805 (1.5645)
[INFO][2021-08-30 06:21:21]	Start to evaluate after 18 epoch of training
[INFO][2021-08-30 06:21:21]	len(loader.dataset)
[INFO][2021-08-30 06:21:21]	5000
[INFO][2021-08-30 06:24:36]	num_classes
[INFO][2021-08-30 06:24:36]	10
[INFO][2021-08-30 06:24:36]	[[   0 1977    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [1242    0    0    0    0    0    0    0    0    0]
 [   0    7    0    0    0    0    0    0    0    0]
 [   0    0   22    0    0    0    0    0    0    0]
 [  22    0  172    0    0    0    0    0    0    0]
 [   0   16    0    0    0    0    0    0    0    0]
 [   0    0  794    0    0    0    0    0    0    0]
 [ 679    0   12    0    0    0    0    0    0    0]
 [  57    0    0    0    0    0    0    0    0    0]]
[INFO][2021-08-30 06:24:36]	Evaluation results at epoch 18 are: ACC: 0.803, NMI: 0.816, ARI: 0.774
[INFO][2021-08-30 06:24:37]	Start to train at 19 epoch with learning rate 0.000010
[INFO][2021-08-30 06:24:37]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-30 06:24:37]	hidx, head: 0, 10
[INFO][2021-08-30 06:24:37]	hidx, head: 1, 10
[INFO][2021-08-30 06:24:37]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-30 06:24:57]	Batch: [  0/313] Head: [0/2] Epoch: [ 19/350] Progress: [0:00:19/1:43:48] Time: 19.900 (19.900) Data: 17.478 (17.478) Loss: 1.5660 (1.5660)
[INFO][2021-08-30 06:29:13]	Batch: [ 30/313] Head: [0/2] Epoch: [ 19/350] Progress: [0:04:36/0:46:31] Time: 14.965 (8.917) Data: 12.666 (6.568) Loss: 1.5519 (1.5661)
[INFO][2021-08-30 06:33:31]	Batch: [ 60/313] Head: [0/2] Epoch: [ 19/350] Progress: [0:08:54/0:45:40] Time: 14.918 (8.755) Data: 12.619 (6.411) Loss: 1.5485 (1.5617)
[INFO][2021-08-30 06:37:48]	Batch: [ 90/313] Head: [0/2] Epoch: [ 19/350] Progress: [0:13:11/0:45:21] Time: 14.537 (8.695) Data: 12.125 (6.353) Loss: 1.5649 (1.5641)
[INFO][2021-08-30 06:42:04]	Batch: [120/313] Head: [0/2] Epoch: [ 19/350] Progress: [0:17:27/0:45:08] Time: 14.771 (8.654) Data: 12.355 (6.311) Loss: 1.5375 (1.5639)
[INFO][2021-08-30 06:46:21]	Batch: [150/313] Head: [0/2] Epoch: [ 19/350] Progress: [0:21:44/0:45:04] Time: 14.671 (8.640) Data: 12.259 (6.298) Loss: 1.5849 (1.5640)
[INFO][2021-08-30 06:50:37]	Batch: [180/313] Head: [0/2] Epoch: [ 19/350] Progress: [0:26:00/0:44:57] Time: 15.202 (8.620) Data: 12.899 (6.281) Loss: 1.5289 (1.5647)
[INFO][2021-08-30 06:54:51]	Batch: [210/313] Head: [0/2] Epoch: [ 19/350] Progress: [0:30:14/0:44:51] Time: 14.653 (8.598) Data: 12.353 (6.260) Loss: 1.5533 (1.5656)
[INFO][2021-08-30 06:59:06]	Batch: [240/313] Head: [0/2] Epoch: [ 19/350] Progress: [0:34:29/0:44:47] Time: 14.705 (8.588) Data: 12.404 (6.250) Loss: 1.5476 (1.5642)
[INFO][2021-08-30 07:03:22]	Batch: [270/313] Head: [0/2] Epoch: [ 19/350] Progress: [0:38:45/0:44:45] Time: 14.379 (8.580) Data: 12.082 (6.242) Loss: 1.5520 (1.5640)
[INFO][2021-08-30 07:07:38]	Batch: [300/313] Head: [0/2] Epoch: [ 19/350] Progress: [0:43:01/0:44:44] Time: 15.006 (8.577) Data: 12.704 (6.241) Loss: 1.5577 (1.5641)
[INFO][2021-08-30 07:09:12]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-30 07:09:31]	Batch: [  0/313] Head: [1/2] Epoch: [ 19/350] Progress: [0:00:19/1:43:29] Time: 19.839 (19.839) Data: 17.419 (17.419) Loss: 1.5252 (1.5252)
[INFO][2021-08-30 07:13:48]	Batch: [ 30/313] Head: [1/2] Epoch: [ 19/350] Progress: [0:04:36/0:46:29] Time: 14.671 (8.912) Data: 12.260 (6.515) Loss: 1.5474 (1.5618)
[INFO][2021-08-30 07:18:01]	Batch: [ 60/313] Head: [1/2] Epoch: [ 19/350] Progress: [0:08:49/0:45:15] Time: 15.011 (8.674) Data: 12.714 (6.295) Loss: 1.5261 (1.5588)
[INFO][2021-08-30 07:22:13]	Batch: [ 90/313] Head: [1/2] Epoch: [ 19/350] Progress: [0:13:01/0:44:49] Time: 13.727 (8.591) Data: 11.315 (6.208) Loss: 1.5719 (1.5591)
[INFO][2021-08-30 07:26:27]	Batch: [120/313] Head: [1/2] Epoch: [ 19/350] Progress: [0:17:15/0:44:37] Time: 11.768 (8.554) Data: 9.464 (6.174) Loss: 1.5594 (1.5616)
[INFO][2021-08-30 07:30:41]	Batch: [150/313] Head: [1/2] Epoch: [ 19/350] Progress: [0:21:29/0:44:31] Time: 11.097 (8.537) Data: 8.796 (6.169) Loss: 1.5703 (1.5607)
[INFO][2021-08-30 07:34:55]	Batch: [180/313] Head: [1/2] Epoch: [ 19/350] Progress: [0:25:43/0:44:28] Time: 10.150 (8.526) Data: 7.741 (6.166) Loss: 1.5675 (1.5612)
[INFO][2021-08-30 07:39:08]	Batch: [210/313] Head: [1/2] Epoch: [ 19/350] Progress: [0:29:56/0:44:24] Time: 7.364 (8.514) Data: 5.066 (6.162) Loss: 1.5852 (1.5614)
[INFO][2021-08-30 07:43:20]	Batch: [240/313] Head: [1/2] Epoch: [ 19/350] Progress: [0:34:08/0:44:20] Time: 4.691 (8.501) Data: 2.283 (6.153) Loss: 1.5498 (1.5610)
[INFO][2021-08-30 07:47:33]	Batch: [270/313] Head: [1/2] Epoch: [ 19/350] Progress: [0:38:21/0:44:17] Time: 3.633 (8.491) Data: 1.223 (6.144) Loss: 1.5820 (1.5615)
[INFO][2021-08-30 07:51:48]	Batch: [300/313] Head: [1/2] Epoch: [ 19/350] Progress: [0:42:36/0:44:18] Time: 2.409 (8.495) Data: 0.001 (6.145) Loss: 1.5441 (1.5611)
[INFO][2021-08-30 07:53:29]	Start to evaluate after 19 epoch of training
[INFO][2021-08-30 07:53:29]	len(loader.dataset)
[INFO][2021-08-30 07:53:29]	5000
[INFO][2021-08-30 07:56:44]	num_classes
[INFO][2021-08-30 07:56:44]	10
[INFO][2021-08-30 07:56:44]	[[   0 2000    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [1114    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0    3    0    0    0    0    0    0    0]
 [  23    0  246    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0  743    0    0    0    0    0    0    0]
 [ 826    0    8    0    0    0    0    0    0    0]
 [  37    0    0    0    0    0    0    0    0    0]]
[INFO][2021-08-30 07:56:44]	Evaluation results at epoch 19 are: ACC: 0.771, NMI: 0.824, ARI: 0.770
[INFO][2021-08-30 07:56:44]	Start to train at 20 epoch with learning rate 0.000010
[INFO][2021-08-30 07:56:44]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-30 07:56:44]	hidx, head: 0, 10
[INFO][2021-08-30 07:56:44]	hidx, head: 1, 10
[INFO][2021-08-30 07:56:44]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-30 07:57:04]	Batch: [  0/313] Head: [0/2] Epoch: [ 20/350] Progress: [0:00:19/1:42:08] Time: 19.578 (19.578) Data: 17.262 (17.262) Loss: 1.5307 (1.5307)
[INFO][2021-08-30 08:01:18]	Batch: [ 30/313] Head: [0/2] Epoch: [ 20/350] Progress: [0:04:33/0:46:06] Time: 14.476 (8.837) Data: 12.055 (6.440) Loss: 1.5538 (1.5506)
[INFO][2021-08-30 08:05:32]	Batch: [ 60/313] Head: [0/2] Epoch: [ 20/350] Progress: [0:08:47/0:45:05] Time: 14.683 (8.644) Data: 12.268 (6.256) Loss: 1.5828 (1.5531)
[INFO][2021-08-30 08:09:44]	Batch: [ 90/313] Head: [0/2] Epoch: [ 20/350] Progress: [0:13:00/0:44:43] Time: 12.879 (8.573) Data: 10.465 (6.183) Loss: 1.5881 (1.5558)
[INFO][2021-08-30 08:13:56]	Batch: [120/313] Head: [0/2] Epoch: [ 20/350] Progress: [0:17:12/0:44:29] Time: 7.286 (8.530) Data: 4.876 (6.152) Loss: 1.5552 (1.5572)
[INFO][2021-08-30 08:18:10]	Batch: [150/313] Head: [0/2] Epoch: [ 20/350] Progress: [0:21:25/0:44:25] Time: 4.617 (8.516) Data: 2.200 (6.133) Loss: 1.5505 (1.5580)
[INFO][2021-08-30 08:22:25]	Batch: [180/313] Head: [0/2] Epoch: [ 20/350] Progress: [0:25:40/0:44:23] Time: 5.166 (8.511) Data: 2.870 (6.137) Loss: 1.5990 (1.5592)
[INFO][2021-08-30 08:26:38]	Batch: [210/313] Head: [0/2] Epoch: [ 20/350] Progress: [0:29:53/0:44:21] Time: 3.970 (8.502) Data: 1.673 (6.129) Loss: 1.5407 (1.5596)
[INFO][2021-08-30 08:30:53]	Batch: [240/313] Head: [0/2] Epoch: [ 20/350] Progress: [0:34:08/0:44:20] Time: 3.258 (8.501) Data: 0.958 (6.135) Loss: 1.5541 (1.5591)
[INFO][2021-08-30 08:35:08]	Batch: [270/313] Head: [0/2] Epoch: [ 20/350] Progress: [0:38:23/0:44:20] Time: 2.416 (8.499) Data: 0.001 (6.132) Loss: 1.5364 (1.5590)
[INFO][2021-08-30 08:39:22]	Batch: [300/313] Head: [0/2] Epoch: [ 20/350] Progress: [0:42:38/0:44:20] Time: 2.410 (8.498) Data: 0.001 (6.132) Loss: 1.5601 (1.5589)
[INFO][2021-08-30 08:41:03]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-30 08:41:23]	Batch: [  0/313] Head: [1/2] Epoch: [ 20/350] Progress: [0:00:19/1:43:10] Time: 19.778 (19.778) Data: 17.465 (17.465) Loss: 1.5766 (1.5766)
[INFO][2021-08-30 08:45:39]	Batch: [ 30/313] Head: [1/2] Epoch: [ 20/350] Progress: [0:04:35/0:46:20] Time: 14.380 (8.882) Data: 12.079 (6.501) Loss: 1.5820 (1.5585)
[INFO][2021-08-30 08:49:53]	Batch: [ 60/313] Head: [1/2] Epoch: [ 20/350] Progress: [0:08:49/0:45:18] Time: 14.746 (8.685) Data: 12.332 (6.319) Loss: 1.5761 (1.5568)
[INFO][2021-08-30 08:54:06]	Batch: [ 90/313] Head: [1/2] Epoch: [ 20/350] Progress: [0:13:02/0:44:51] Time: 14.970 (8.600) Data: 12.559 (6.237) Loss: 1.5610 (1.5568)
[INFO][2021-08-30 08:58:20]	Batch: [120/313] Head: [1/2] Epoch: [ 20/350] Progress: [0:17:16/0:44:40] Time: 14.351 (8.565) Data: 12.049 (6.204) Loss: 1.5556 (1.5583)
[INFO][2021-08-30 09:02:34]	Batch: [150/313] Head: [1/2] Epoch: [ 20/350] Progress: [0:21:30/0:44:34] Time: 13.918 (8.544) Data: 11.506 (6.184) Loss: 1.5822 (1.5592)
[INFO][2021-08-30 09:06:49]	Batch: [180/313] Head: [1/2] Epoch: [ 20/350] Progress: [0:25:45/0:44:32] Time: 12.444 (8.538) Data: 10.036 (6.174) Loss: 1.5366 (1.5575)
[INFO][2021-08-30 09:11:02]	Batch: [210/313] Head: [1/2] Epoch: [ 20/350] Progress: [0:29:58/0:44:28] Time: 12.313 (8.525) Data: 9.901 (6.159) Loss: 1.5486 (1.5568)
[INFO][2021-08-30 09:15:15]	Batch: [240/313] Head: [1/2] Epoch: [ 20/350] Progress: [0:34:11/0:44:24] Time: 9.113 (8.512) Data: 6.706 (6.141) Loss: 1.5342 (1.5567)
[INFO][2021-08-30 09:19:28]	Batch: [270/313] Head: [1/2] Epoch: [ 20/350] Progress: [0:38:25/0:44:22] Time: 7.557 (8.506) Data: 5.149 (6.131) Loss: 1.5238 (1.5577)
[INFO][2021-08-30 09:23:41]	Batch: [300/313] Head: [1/2] Epoch: [ 20/350] Progress: [0:42:37/0:44:19] Time: 7.879 (8.498) Data: 5.471 (6.119) Loss: 1.6125 (1.5579)
[INFO][2021-08-30 09:25:17]	Start to evaluate after 20 epoch of training
[INFO][2021-08-30 09:25:17]	len(loader.dataset)
[INFO][2021-08-30 09:25:17]	5000
[INFO][2021-08-30 09:28:32]	num_classes
[INFO][2021-08-30 09:28:32]	10
[INFO][2021-08-30 09:28:32]	[[   0 1988    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [1306    0    0    0    0    0    0    0    0    0]
 [   0   12    0    0    0    0    0    0    0    0]
 [   0    0    4    0    0    0    0    0    0    0]
 [   6    0  265    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0  722    0    0    0    0    0    0    0]
 [ 646    0    9    0    0    0    0    0    0    0]
 [  42    0    0    0    0    0    0    0    0    0]]
[INFO][2021-08-30 09:28:32]	Evaluation results at epoch 20 are: ACC: 0.803, NMI: 0.832, ARI: 0.784
[INFO][2021-08-30 09:28:33]	Start to train at 21 epoch with learning rate 0.000010
[INFO][2021-08-30 09:28:33]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-30 09:28:33]	hidx, head: 0, 10
[INFO][2021-08-30 09:28:33]	hidx, head: 1, 10
[INFO][2021-08-30 09:28:33]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-30 09:28:53]	Batch: [  0/313] Head: [0/2] Epoch: [ 21/350] Progress: [0:00:19/1:43:30] Time: 19.841 (19.841) Data: 17.514 (17.514) Loss: 1.5389 (1.5389)
[INFO][2021-08-30 09:33:10]	Batch: [ 30/313] Head: [0/2] Epoch: [ 21/350] Progress: [0:04:36/0:46:31] Time: 14.149 (8.918) Data: 11.744 (6.517) Loss: 1.6257 (1.5673)
[INFO][2021-08-30 09:37:27]	Batch: [ 60/313] Head: [0/2] Epoch: [ 21/350] Progress: [0:08:53/0:45:38] Time: 13.191 (8.750) Data: 10.889 (6.351) Loss: 1.5216 (1.5614)
[INFO][2021-08-30 09:41:45]	Batch: [ 90/313] Head: [0/2] Epoch: [ 21/350] Progress: [0:13:11/0:45:22] Time: 13.029 (8.698) Data: 10.618 (6.305) Loss: 1.5788 (1.5607)
[INFO][2021-08-30 09:45:59]	Batch: [120/313] Head: [0/2] Epoch: [ 21/350] Progress: [0:17:26/0:45:06] Time: 9.839 (8.647) Data: 7.537 (6.252) Loss: 1.5504 (1.5589)
[INFO][2021-08-30 09:50:13]	Batch: [150/313] Head: [0/2] Epoch: [ 21/350] Progress: [0:21:39/0:44:54] Time: 6.163 (8.607) Data: 3.752 (6.217) Loss: 1.5755 (1.5585)
[INFO][2021-08-30 09:54:28]	Batch: [180/313] Head: [0/2] Epoch: [ 21/350] Progress: [0:25:54/0:44:48] Time: 2.410 (8.589) Data: 0.001 (6.197) Loss: 1.5547 (1.5590)
[INFO][2021-08-30 09:58:45]	Batch: [210/313] Head: [0/2] Epoch: [ 21/350] Progress: [0:30:12/0:44:48] Time: 2.412 (8.589) Data: 0.001 (6.198) Loss: 1.5431 (1.5598)
[INFO][2021-08-30 10:03:05]	Batch: [240/313] Head: [0/2] Epoch: [ 21/350] Progress: [0:34:31/0:44:50] Time: 2.407 (8.596) Data: 0.001 (6.206) Loss: 1.5442 (1.5594)
[INFO][2021-08-30 10:07:21]	Batch: [270/313] Head: [0/2] Epoch: [ 21/350] Progress: [0:38:47/0:44:48] Time: 2.408 (8.588) Data: 0.001 (6.199) Loss: 1.5389 (1.5591)
[INFO][2021-08-30 10:11:36]	Batch: [300/313] Head: [0/2] Epoch: [ 21/350] Progress: [0:43:02/0:44:45] Time: 2.411 (8.580) Data: 0.001 (6.189) Loss: 1.5452 (1.5589)
[INFO][2021-08-30 10:13:18]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-30 10:13:38]	Batch: [  0/313] Head: [1/2] Epoch: [ 21/350] Progress: [0:00:19/1:44:16] Time: 19.987 (19.987) Data: 17.557 (17.557) Loss: 1.5679 (1.5679)
[INFO][2021-08-30 10:17:57]	Batch: [ 30/313] Head: [1/2] Epoch: [ 21/350] Progress: [0:04:38/0:46:56] Time: 15.029 (8.998) Data: 12.602 (6.606) Loss: 1.5750 (1.5669)
[INFO][2021-08-30 10:22:15]	Batch: [ 60/313] Head: [1/2] Epoch: [ 21/350] Progress: [0:08:56/0:45:54] Time: 14.467 (8.799) Data: 12.051 (6.421) Loss: 1.5481 (1.5676)
[INFO][2021-08-30 10:26:31]	Batch: [ 90/313] Head: [1/2] Epoch: [ 21/350] Progress: [0:13:13/0:45:27] Time: 14.582 (8.714) Data: 12.170 (6.332) Loss: 1.5405 (1.5637)
[INFO][2021-08-30 10:30:48]	Batch: [120/313] Head: [1/2] Epoch: [ 21/350] Progress: [0:17:29/0:45:16] Time: 14.459 (8.678) Data: 12.045 (6.296) Loss: 1.5605 (1.5603)
[INFO][2021-08-30 10:35:06]	Batch: [150/313] Head: [1/2] Epoch: [ 21/350] Progress: [0:21:48/0:45:11] Time: 14.952 (8.664) Data: 12.538 (6.282) Loss: 1.5426 (1.5620)
[INFO][2021-08-30 10:39:23]	Batch: [180/313] Head: [1/2] Epoch: [ 21/350] Progress: [0:26:05/0:45:06] Time: 14.482 (8.647) Data: 12.071 (6.260) Loss: 1.5576 (1.5632)
[INFO][2021-08-30 10:43:41]	Batch: [210/313] Head: [1/2] Epoch: [ 21/350] Progress: [0:30:22/0:45:04] Time: 14.506 (8.640) Data: 12.205 (6.250) Loss: 1.5796 (1.5624)
[INFO][2021-08-30 10:48:00]	Batch: [240/313] Head: [1/2] Epoch: [ 21/350] Progress: [0:34:42/0:45:04] Time: 14.574 (8.641) Data: 12.161 (6.250) Loss: 1.5361 (1.5627)
[INFO][2021-08-30 10:52:17]	Batch: [270/313] Head: [1/2] Epoch: [ 21/350] Progress: [0:38:59/0:45:01] Time: 15.073 (8.632) Data: 12.659 (6.241) Loss: 1.5646 (1.5617)
[INFO][2021-08-30 10:56:33]	Batch: [300/313] Head: [1/2] Epoch: [ 21/350] Progress: [0:43:15/0:44:58] Time: 14.690 (8.622) Data: 12.387 (6.235) Loss: 1.5618 (1.5616)
[INFO][2021-08-30 10:58:07]	Start to evaluate after 21 epoch of training
[INFO][2021-08-30 10:58:07]	len(loader.dataset)
[INFO][2021-08-30 10:58:07]	5000
[INFO][2021-08-30 11:01:21]	num_classes
[INFO][2021-08-30 11:01:21]	10
[INFO][2021-08-30 11:01:21]	[[   0 1982    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [1272    0    0    0    0    0    0    0    0    0]
 [   0   18    0    0    0    0    0    0    0    0]
 [   0    0   15    0    0    0    0    0    0    0]
 [   1    0  298    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0  672    0    0    0    0    0    0    0]
 [ 684    0   15    0    0    0    0    0    0    0]
 [  43    0    0    0    0    0    0    0    0    0]]
[INFO][2021-08-30 11:01:21]	Evaluation results at epoch 21 are: ACC: 0.785, NMI: 0.824, ARI: 0.773
[INFO][2021-08-30 11:01:22]	Start to train at 22 epoch with learning rate 0.000010
[INFO][2021-08-30 11:01:22]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-30 11:01:22]	hidx, head: 0, 10
[INFO][2021-08-30 11:01:22]	hidx, head: 1, 10
[INFO][2021-08-30 11:01:22]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-30 11:01:41]	Batch: [  0/313] Head: [0/2] Epoch: [ 22/350] Progress: [0:00:19/1:41:43] Time: 19.501 (19.501) Data: 17.181 (17.181) Loss: 1.5248 (1.5248)
[INFO][2021-08-30 11:05:56]	Batch: [ 30/313] Head: [0/2] Epoch: [ 22/350] Progress: [0:04:34/0:46:08] Time: 14.552 (8.845) Data: 12.142 (6.483) Loss: 1.5982 (1.5510)
[INFO][2021-08-30 11:10:09]	Batch: [ 60/313] Head: [0/2] Epoch: [ 22/350] Progress: [0:08:47/0:45:05] Time: 14.309 (8.644) Data: 11.896 (6.264) Loss: 1.5204 (1.5546)
[INFO][2021-08-30 11:14:26]	Batch: [ 90/313] Head: [0/2] Epoch: [ 22/350] Progress: [0:13:04/0:44:57] Time: 14.919 (8.619) Data: 12.507 (6.236) Loss: 1.5123 (1.5520)
[INFO][2021-08-30 11:18:40]	Batch: [120/313] Head: [0/2] Epoch: [ 22/350] Progress: [0:17:17/0:44:44] Time: 14.749 (8.577) Data: 12.343 (6.191) Loss: 1.5539 (1.5527)
[INFO][2021-08-30 11:22:54]	Batch: [150/313] Head: [0/2] Epoch: [ 22/350] Progress: [0:21:32/0:44:39] Time: 14.567 (8.560) Data: 12.157 (6.180) Loss: 1.5736 (1.5542)
[INFO][2021-08-30 11:27:09]	Batch: [180/313] Head: [0/2] Epoch: [ 22/350] Progress: [0:25:47/0:44:35] Time: 14.598 (8.549) Data: 12.184 (6.168) Loss: 1.5536 (1.5538)
[INFO][2021-08-30 11:31:27]	Batch: [210/313] Head: [0/2] Epoch: [ 22/350] Progress: [0:30:04/0:44:37] Time: 14.567 (8.553) Data: 12.154 (6.172) Loss: 1.5282 (1.5543)
[INFO][2021-08-30 11:35:43]	Batch: [240/313] Head: [0/2] Epoch: [ 22/350] Progress: [0:34:21/0:44:37] Time: 14.967 (8.554) Data: 12.552 (6.174) Loss: 1.5667 (1.5540)
[INFO][2021-08-30 11:40:00]	Batch: [270/313] Head: [0/2] Epoch: [ 22/350] Progress: [0:38:37/0:44:37] Time: 14.402 (8.553) Data: 12.103 (6.174) Loss: 1.5507 (1.5547)
[INFO][2021-08-30 11:44:11]	Batch: [300/313] Head: [0/2] Epoch: [ 22/350] Progress: [0:42:49/0:44:31] Time: 14.082 (8.536) Data: 11.786 (6.158) Loss: 1.5430 (1.5553)
[INFO][2021-08-30 11:45:43]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-30 11:46:02]	Batch: [  0/313] Head: [1/2] Epoch: [ 22/350] Progress: [0:00:19/1:43:21] Time: 19.814 (19.814) Data: 17.389 (17.389) Loss: 1.5721 (1.5721)
[INFO][2021-08-30 11:50:16]	Batch: [ 30/313] Head: [1/2] Epoch: [ 22/350] Progress: [0:04:33/0:45:57] Time: 14.319 (8.811) Data: 11.910 (6.423) Loss: 1.5618 (1.5519)
[INFO][2021-08-30 11:54:28]	Batch: [ 60/313] Head: [1/2] Epoch: [ 22/350] Progress: [0:08:45/0:44:54] Time: 12.596 (8.609) Data: 10.187 (6.238) Loss: 1.5570 (1.5516)
[INFO][2021-08-30 11:58:43]	Batch: [ 90/313] Head: [1/2] Epoch: [ 22/350] Progress: [0:13:00/0:44:43] Time: 12.416 (8.573) Data: 10.007 (6.201) Loss: 1.5442 (1.5527)
[INFO][2021-08-30 12:02:58]	Batch: [120/313] Head: [1/2] Epoch: [ 22/350] Progress: [0:17:15/0:44:38] Time: 12.192 (8.559) Data: 9.779 (6.181) Loss: 1.5980 (1.5531)
[INFO][2021-08-30 12:07:15]	Batch: [150/313] Head: [1/2] Epoch: [ 22/350] Progress: [0:21:32/0:44:38] Time: 11.819 (8.557) Data: 9.408 (6.173) Loss: 1.5574 (1.5528)
[INFO][2021-08-30 12:11:34]	Batch: [180/313] Head: [1/2] Epoch: [ 22/350] Progress: [0:25:51/0:44:43] Time: 14.765 (8.573) Data: 12.354 (6.186) Loss: 1.5590 (1.5537)
[INFO][2021-08-30 12:15:54]	Batch: [210/313] Head: [1/2] Epoch: [ 22/350] Progress: [0:30:11/0:44:46] Time: 14.800 (8.584) Data: 12.496 (6.196) Loss: 1.5313 (1.5529)
[INFO][2021-08-30 12:20:12]	Batch: [240/313] Head: [1/2] Epoch: [ 22/350] Progress: [0:34:29/0:44:47] Time: 14.567 (8.586) Data: 12.266 (6.197) Loss: 1.5674 (1.5530)
[INFO][2021-08-30 12:24:26]	Batch: [270/313] Head: [1/2] Epoch: [ 22/350] Progress: [0:38:43/0:44:43] Time: 14.453 (8.572) Data: 12.039 (6.186) Loss: 1.5385 (1.5530)
[INFO][2021-08-30 12:28:39]	Batch: [300/313] Head: [1/2] Epoch: [ 22/350] Progress: [0:42:56/0:44:39] Time: 14.872 (8.561) Data: 12.458 (6.176) Loss: 1.5517 (1.5531)
[INFO][2021-08-30 12:30:11]	Start to evaluate after 22 epoch of training
[INFO][2021-08-30 12:30:11]	len(loader.dataset)
[INFO][2021-08-30 12:30:11]	5000
[INFO][2021-08-30 12:33:25]	num_classes
[INFO][2021-08-30 12:33:25]	10
[INFO][2021-08-30 12:33:25]	[[   0 1990    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [1328    0    0    0    0    0    0    0    0    0]
 [   0    4    0    0    0    0    0    0    0    0]
 [   0    0    5    0    0    0    0    0    0    0]
 [   0    0  347    0    0    0    0    0    0    0]
 [   0    6    0    0    0    0    0    0    0    0]
 [   0    0  603    0    0    0    0    0    0    0]
 [ 666    0   45    0    0    0    0    0    0    0]
 [   6    0    0    0    0    0    0    0    0    0]]
[INFO][2021-08-30 12:33:25]	Evaluation results at epoch 22 are: ACC: 0.784, NMI: 0.822, ARI: 0.779
[INFO][2021-08-30 12:33:26]	Start to train at 23 epoch with learning rate 0.000010
[INFO][2021-08-30 12:33:26]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-30 12:33:26]	hidx, head: 0, 10
[INFO][2021-08-30 12:33:26]	hidx, head: 1, 10
[INFO][2021-08-30 12:33:26]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-30 12:33:45]	Batch: [  0/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:00:19/1:41:47] Time: 19.513 (19.513) Data: 17.198 (17.198) Loss: 1.5820 (1.5820)
[INFO][2021-08-30 12:38:00]	Batch: [ 30/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:04:34/0:46:09] Time: 14.160 (8.847) Data: 11.748 (6.484) Loss: 1.5473 (1.5567)
[INFO][2021-08-30 12:42:14]	Batch: [ 60/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:08:48/0:45:10] Time: 11.487 (8.658) Data: 9.072 (6.286) Loss: 1.5049 (1.5580)
[INFO][2021-08-30 12:46:27]	Batch: [ 90/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:13:01/0:44:49] Time: 7.667 (8.591) Data: 5.366 (6.222) Loss: 1.5248 (1.5549)
[INFO][2021-08-30 12:50:41]	Batch: [120/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:17:15/0:44:37] Time: 6.869 (8.555) Data: 4.457 (6.185) Loss: 1.5427 (1.5543)
[INFO][2021-08-30 12:54:56]	Batch: [150/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:21:30/0:44:34] Time: 9.153 (8.545) Data: 6.739 (6.173) Loss: 1.5989 (1.5547)
[INFO][2021-08-30 12:59:12]	Batch: [180/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:25:46/0:44:33] Time: 12.350 (8.542) Data: 10.051 (6.170) Loss: 1.5424 (1.5549)
[INFO][2021-08-30 13:03:27]	Batch: [210/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:30:01/0:44:32] Time: 14.586 (8.538) Data: 12.138 (6.162) Loss: 1.5578 (1.5539)
[INFO][2021-08-30 13:07:42]	Batch: [240/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:34:16/0:44:31] Time: 15.112 (8.534) Data: 12.696 (6.158) Loss: 1.5505 (1.5552)
[INFO][2021-08-30 13:11:58]	Batch: [270/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:38:32/0:44:30] Time: 14.962 (8.533) Data: 12.547 (6.159) Loss: 1.5396 (1.5544)
[INFO][2021-08-30 13:16:12]	Batch: [300/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:42:46/0:44:28] Time: 14.402 (8.526) Data: 12.096 (6.153) Loss: 1.5692 (1.5538)
[INFO][2021-08-30 13:17:44]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-30 13:18:03]	Batch: [  0/313] Head: [1/2] Epoch: [ 23/350] Progress: [0:00:19/1:43:51] Time: 19.908 (19.908) Data: 17.477 (17.477) Loss: 1.5399 (1.5399)
[INFO][2021-08-30 13:22:18]	Batch: [ 30/313] Head: [1/2] Epoch: [ 23/350] Progress: [0:04:34/0:46:12] Time: 14.592 (8.859) Data: 12.178 (6.492) Loss: 1.5149 (1.5463)
[INFO][2021-08-30 13:26:34]	Batch: [ 60/313] Head: [1/2] Epoch: [ 23/350] Progress: [0:08:50/0:45:22] Time: 14.871 (8.699) Data: 12.573 (6.337) Loss: 1.5490 (1.5494)
[INFO][2021-08-30 13:30:46]	Batch: [ 90/313] Head: [1/2] Epoch: [ 23/350] Progress: [0:13:02/0:44:52] Time: 14.363 (8.603) Data: 12.060 (6.238) Loss: 1.5309 (1.5522)
[INFO][2021-08-30 13:34:58]	Batch: [120/313] Head: [1/2] Epoch: [ 23/350] Progress: [0:17:14/0:44:35] Time: 12.494 (8.548) Data: 10.192 (6.187) Loss: 1.5425 (1.5524)
[INFO][2021-08-30 13:39:09]	Batch: [150/313] Head: [1/2] Epoch: [ 23/350] Progress: [0:21:25/0:44:23] Time: 9.167 (8.510) Data: 6.753 (6.148) Loss: 1.5630 (1.5525)
[INFO][2021-08-30 13:43:20]	Batch: [180/313] Head: [1/2] Epoch: [ 23/350] Progress: [0:25:36/0:44:17] Time: 7.447 (8.491) Data: 5.141 (6.131) Loss: 1.5427 (1.5530)
[INFO][2021-08-30 13:47:33]	Batch: [210/313] Head: [1/2] Epoch: [ 23/350] Progress: [0:29:49/0:44:14] Time: 5.472 (8.481) Data: 3.056 (6.119) Loss: 1.5710 (1.5534)
[INFO][2021-08-30 13:51:45]	Batch: [240/313] Head: [1/2] Epoch: [ 23/350] Progress: [0:34:01/0:44:10] Time: 2.409 (8.469) Data: 0.001 (6.102) Loss: 1.5306 (1.5536)
[DEBUG][2021-08-30 14:04:22]	Provided arguments will be stored in sessions/pickle10/config.yaml
[INFO][2021-08-30 14:04:22]	Start to declare training variable
[INFO][2021-08-30 14:04:22]	Session will be ran in device: [cuda]
[INFO][2021-08-30 14:04:22]	Start to prepare data
[INFO][2021-08-30 14:04:24]	otrainset----------------------: length 20000
[INFO][2021-08-30 14:04:25]	ptrainset----------------------: length 20000
[INFO][2021-08-30 14:04:25]	testset-------------: length 5000
[INFO][2021-08-30 14:04:25]	Start to build model
[DEBUG][2021-08-30 14:04:25]	Backbone [resnet34] is declared with cin [1] and cout [1000] [with] sobel
[DEBUG][2021-08-30 14:04:25]	Backbone will be created wit the following heads: [10, 10]
[DEBUG][2021-08-30 14:04:25]	Number of trainable parameters is [112]
[DEBUG][2021-08-30 14:04:25]	Number of frozen parameters is [2]
[DEBUG][2021-08-30 14:04:25]	Name of frozen parameters are: dict_keys(['sobel.0.weight', 'sobel.0.bias'])
[DEBUG][2021-08-30 14:04:25]	Going to use [Adam] optimizer for training with betas (0.9, 0.999), eps 0.000000, weight decay 0.000000 without amsgrad
[DEBUG][2021-08-30 14:04:25]	Going to use [fixed] learning policy for optimization with base learning rate [0.00001]
[INFO][2021-08-30 14:04:26]	Start to resume session for file: [sessions/pickle10/checkpoint/latest.ckpt]
[DEBUG][2021-08-30 14:04:26]	Totally loaded [222] parameters
[INFO][2021-08-30 14:04:26]	Data parallel will be used for acceleration purpose
[INFO][2021-08-30 14:04:26]	Start to train at 23 epoch with learning rate 0.000010
[INFO][2021-08-30 14:04:26]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-30 14:04:26]	hidx, head: 0, 10
[INFO][2021-08-30 14:04:26]	hidx, head: 1, 10
[INFO][2021-08-30 14:04:26]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-30 14:05:09]	Batch: [  0/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:00:43/3:44:42] Time: 43.075 (43.075) Data: 31.974 (31.974) Loss: 1.5911 (1.5911)
[INFO][2021-08-30 14:09:18]	Batch: [ 30/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:04:52/0:49:12] Time: 15.052 (9.434) Data: 12.757 (6.813) Loss: 1.5665 (1.5599)
[INFO][2021-08-30 14:13:37]	Batch: [ 60/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:09:11/0:47:10] Time: 14.868 (9.043) Data: 12.472 (6.570) Loss: 1.5517 (1.5594)
[INFO][2021-08-30 14:17:53]	Batch: [ 90/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:13:27/0:46:17] Time: 14.611 (8.874) Data: 12.311 (6.442) Loss: 1.5678 (1.5571)
[INFO][2021-08-30 14:22:10]	Batch: [120/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:17:43/0:45:52] Time: 11.797 (8.793) Data: 9.505 (6.388) Loss: 1.5394 (1.5549)
[INFO][2021-08-30 14:26:27]	Batch: [150/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:22:01/0:45:38] Time: 10.245 (8.750) Data: 7.954 (6.362) Loss: 1.5526 (1.5549)
[INFO][2021-08-30 14:30:45]	Batch: [180/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:26:19/0:45:30] Time: 9.918 (8.724) Data: 7.513 (6.346) Loss: 1.6001 (1.5552)
[INFO][2021-08-30 14:35:02]	Batch: [210/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:30:36/0:45:23] Time: 9.884 (8.703) Data: 7.591 (6.329) Loss: 1.5566 (1.5549)
[DEBUG][2021-08-30 19:53:46]	Provided arguments will be stored in sessions/pickle10/config.yaml
[INFO][2021-08-30 19:53:46]	Start to declare training variable
[INFO][2021-08-30 19:53:46]	Session will be ran in device: [cuda]
[INFO][2021-08-30 19:53:46]	Start to prepare data
[INFO][2021-08-30 19:53:47]	otrainset----------------------: length 20000
[INFO][2021-08-30 19:53:48]	ptrainset----------------------: length 20000
[INFO][2021-08-30 19:53:48]	testset-------------: length 5000
[INFO][2021-08-30 19:53:48]	Start to build model
[DEBUG][2021-08-30 19:53:48]	Backbone [resnet34] is declared with cin [1] and cout [1000] [with] sobel
[DEBUG][2021-08-30 19:53:48]	Backbone will be created wit the following heads: [10, 10]
[DEBUG][2021-08-30 19:53:49]	Number of trainable parameters is [112]
[DEBUG][2021-08-30 19:53:49]	Number of frozen parameters is [2]
[DEBUG][2021-08-30 19:53:49]	Name of frozen parameters are: dict_keys(['sobel.0.weight', 'sobel.0.bias'])
[DEBUG][2021-08-30 19:53:49]	Going to use [Adam] optimizer for training with betas (0.9, 0.999), eps 0.000000, weight decay 0.000000 without amsgrad
[DEBUG][2021-08-30 19:53:49]	Going to use [fixed] learning policy for optimization with base learning rate [0.00001]
[INFO][2021-08-30 19:53:49]	Start to resume session for file: [sessions/pickle10/checkpoint/latest.ckpt]
[DEBUG][2021-08-30 19:53:49]	Totally loaded [222] parameters
[INFO][2021-08-30 19:53:49]	Data parallel will be used for acceleration purpose
[INFO][2021-08-30 19:53:49]	Start to train at 23 epoch with learning rate 0.000010
[INFO][2021-08-30 19:53:49]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-30 19:53:49]	hidx, head: 0, 10
[INFO][2021-08-30 19:53:49]	hidx, head: 1, 10
[INFO][2021-08-30 19:53:49]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-30 19:54:17]	Batch: [  0/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:00:27/2:25:17] Time: 27.853 (27.853) Data: 16.651 (16.651) Loss: 1.5512 (1.5512)
[INFO][2021-08-30 19:58:13]	Batch: [ 30/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:04:24/0:44:25] Time: 13.955 (8.517) Data: 11.666 (5.869) Loss: 1.5592 (1.5637)
[INFO][2021-08-30 20:02:18]	Batch: [ 60/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:08:29/0:43:35] Time: 14.080 (8.355) Data: 11.789 (5.862) Loss: 1.5532 (1.5565)
[INFO][2021-08-30 20:06:24]	Batch: [ 90/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:12:34/0:43:16] Time: 14.025 (8.296) Data: 11.612 (5.836) Loss: 1.5913 (1.5569)
[INFO][2021-08-30 20:10:30]	Batch: [120/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:16:40/0:43:08] Time: 14.019 (8.270) Data: 11.617 (5.827) Loss: 1.5314 (1.5552)
[INFO][2021-08-30 20:14:34]	Batch: [150/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:20:45/0:43:01] Time: 14.028 (8.249) Data: 11.624 (5.819) Loss: 1.5431 (1.5551)
[INFO][2021-08-30 20:18:39]	Batch: [180/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:24:50/0:42:57] Time: 13.864 (8.234) Data: 11.463 (5.813) Loss: 1.5213 (1.5541)
[INFO][2021-08-30 20:22:44]	Batch: [210/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:28:54/0:42:53] Time: 14.000 (8.222) Data: 11.710 (5.808) Loss: 1.5664 (1.5535)
[DEBUG][2021-08-31 00:48:20]	Provided arguments will be stored in sessions/pickle10/config.yaml
[INFO][2021-08-31 00:48:20]	Start to declare training variable
[INFO][2021-08-31 00:48:20]	Session will be ran in device: [cuda]
[INFO][2021-08-31 00:48:20]	Start to prepare data
[INFO][2021-08-31 00:48:21]	otrainset----------------------: length 20000
[INFO][2021-08-31 00:48:22]	ptrainset----------------------: length 20000
[INFO][2021-08-31 00:48:22]	testset-------------: length 5000
[INFO][2021-08-31 00:48:22]	Start to build model
[DEBUG][2021-08-31 00:48:22]	Backbone [resnet34] is declared with cin [1] and cout [1000] [with] sobel
[DEBUG][2021-08-31 00:48:22]	Backbone will be created wit the following heads: [10, 10]
[DEBUG][2021-08-31 00:48:22]	Number of trainable parameters is [112]
[DEBUG][2021-08-31 00:48:22]	Number of frozen parameters is [2]
[DEBUG][2021-08-31 00:48:22]	Name of frozen parameters are: dict_keys(['sobel.0.weight', 'sobel.0.bias'])
[DEBUG][2021-08-31 00:48:23]	Going to use [Adam] optimizer for training with betas (0.9, 0.999), eps 0.000000, weight decay 0.000000 without amsgrad
[DEBUG][2021-08-31 00:48:23]	Going to use [fixed] learning policy for optimization with base learning rate [0.00001]
[INFO][2021-08-31 00:48:23]	Start to resume session for file: [sessions/pickle10/checkpoint/latest.ckpt]
[DEBUG][2021-08-31 00:48:23]	Totally loaded [222] parameters
[INFO][2021-08-31 00:48:23]	Data parallel will be used for acceleration purpose
[INFO][2021-08-31 00:48:23]	Start to train at 23 epoch with learning rate 0.000010
[INFO][2021-08-31 00:48:23]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-31 00:48:23]	hidx, head: 0, 10
[INFO][2021-08-31 00:48:23]	hidx, head: 1, 10
[INFO][2021-08-31 00:48:23]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-31 00:49:56]	Batch: [  0/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:01:33/8:07:31] Time: 93.457 (93.457) Data: 64.513 (64.513) Loss: 1.5479 (1.5479)
[INFO][2021-08-31 00:55:24]	Batch: [ 30/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:07:01/1:10:54] Time: 14.360 (13.592) Data: 11.962 (10.357) Loss: 1.6213 (1.5582)
[INFO][2021-08-31 00:59:35]	Batch: [ 60/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:11:12/0:57:30] Time: 13.931 (11.023) Data: 11.638 (8.228) Loss: 1.5218 (1.5594)
[INFO][2021-08-31 01:03:46]	Batch: [ 90/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:15:23/0:52:55] Time: 14.115 (10.145) Data: 11.703 (7.499) Loss: 1.5710 (1.5564)
[INFO][2021-08-31 01:07:57]	Batch: [120/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:19:34/0:50:38] Time: 14.674 (9.708) Data: 12.382 (7.140) Loss: 1.5530 (1.5554)
[INFO][2021-08-31 01:12:09]	Batch: [150/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:23:46/0:49:17] Time: 14.378 (9.447) Data: 11.975 (6.926) Loss: 1.5417 (1.5542)
[INFO][2021-08-31 01:16:21]	Batch: [180/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:27:57/0:48:21] Time: 14.353 (9.270) Data: 12.056 (6.777) Loss: 1.5458 (1.5543)
[INFO][2021-08-31 01:20:31]	Batch: [210/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:32:08/0:47:41] Time: 14.365 (9.141) Data: 11.963 (6.670) Loss: 1.5730 (1.5542)
[INFO][2021-08-31 01:24:42]	Batch: [240/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:36:19/0:47:10] Time: 14.281 (9.045) Data: 11.877 (6.590) Loss: 1.6006 (1.5537)
[INFO][2021-08-31 01:28:54]	Batch: [270/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:40:31/0:46:47] Time: 14.676 (8.971) Data: 12.270 (6.528) Loss: 1.5753 (1.5530)
[INFO][2021-08-31 01:33:04]	Batch: [300/313] Head: [0/2] Epoch: [ 23/350] Progress: [0:44:41/0:46:28] Time: 14.351 (8.908) Data: 12.061 (6.476) Loss: 1.5613 (1.5531)
[INFO][2021-08-31 01:34:36]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-31 01:34:55]	Batch: [  0/313] Head: [1/2] Epoch: [ 23/350] Progress: [0:00:19/1:41:01] Time: 19.365 (19.365) Data: 17.055 (17.055) Loss: 1.5125 (1.5125)
[INFO][2021-08-31 01:39:06]	Batch: [ 30/313] Head: [1/2] Epoch: [ 23/350] Progress: [0:04:29/0:45:21] Time: 14.401 (8.696) Data: 12.111 (6.381) Loss: 1.5549 (1.5521)
[INFO][2021-08-31 01:43:16]	Batch: [ 60/313] Head: [1/2] Epoch: [ 23/350] Progress: [0:08:39/0:44:27] Time: 12.752 (8.523) Data: 10.463 (6.213) Loss: 1.5475 (1.5548)
[INFO][2021-08-31 01:47:28]	Batch: [ 90/313] Head: [1/2] Epoch: [ 23/350] Progress: [0:12:51/0:44:13] Time: 12.229 (8.479) Data: 9.940 (6.173) Loss: 1.5363 (1.5541)
[INFO][2021-08-31 01:51:38]	Batch: [120/313] Head: [1/2] Epoch: [ 23/350] Progress: [0:17:01/0:44:03] Time: 10.500 (8.445) Data: 8.206 (6.136) Loss: 1.5534 (1.5540)
[INFO][2021-08-31 01:55:46]	Batch: [150/313] Head: [1/2] Epoch: [ 23/350] Progress: [0:21:10/0:43:53] Time: 8.774 (8.413) Data: 6.479 (6.104) Loss: 1.5594 (1.5541)
[INFO][2021-08-31 01:59:58]	Batch: [180/313] Head: [1/2] Epoch: [ 23/350] Progress: [0:25:22/0:43:52] Time: 9.429 (8.409) Data: 7.137 (6.102) Loss: 1.5938 (1.5537)
[INFO][2021-08-31 02:04:09]	Batch: [210/313] Head: [1/2] Epoch: [ 23/350] Progress: [0:29:32/0:43:49] Time: 9.051 (8.402) Data: 6.650 (6.095) Loss: 1.5237 (1.5540)
[INFO][2021-08-31 02:08:20]	Batch: [240/313] Head: [1/2] Epoch: [ 23/350] Progress: [0:33:43/0:43:48] Time: 9.160 (8.398) Data: 6.756 (6.086) Loss: 1.5161 (1.5540)
[INFO][2021-08-31 02:12:32]	Batch: [270/313] Head: [1/2] Epoch: [ 23/350] Progress: [0:37:56/0:43:49] Time: 10.384 (8.399) Data: 8.089 (6.081) Loss: 1.5689 (1.5542)
[INFO][2021-08-31 02:16:46]	Batch: [300/313] Head: [1/2] Epoch: [ 23/350] Progress: [0:42:10/0:43:50] Time: 12.674 (8.405) Data: 10.271 (6.081) Loss: 1.5144 (1.5540)
[INFO][2021-08-31 02:18:17]	Start to evaluate after 23 epoch of training
[INFO][2021-08-31 02:18:17]	len(loader.dataset)
[INFO][2021-08-31 02:18:17]	5000
[INFO][2021-08-31 02:21:24]	num_classes
[INFO][2021-08-31 02:21:24]	10
[INFO][2021-08-31 02:21:24]	[[   0 1987    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [1333    0    0    0    0    0    0    0    0    0]
 [   0   13    0    0    0    0    0    0    0    0]
 [   0    0    8    0    0    0    0    0    0    0]
 [   0    0  421    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0  535    0    0    0    0    0    0    0]
 [ 615    0   36    0    0    0    0    0    0    0]
 [  52    0    0    0    0    0    0    0    0    0]]
[INFO][2021-08-31 02:21:24]	Evaluation results at epoch 23 are: ACC: 0.771, NMI: 0.815, ARI: 0.772
[INFO][2021-08-31 02:21:25]	Start to train at 24 epoch with learning rate 0.000010
[INFO][2021-08-31 02:21:25]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-31 02:21:25]	hidx, head: 0, 10
[INFO][2021-08-31 02:21:25]	hidx, head: 1, 10
[INFO][2021-08-31 02:21:25]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-31 02:21:44]	Batch: [  0/313] Head: [0/2] Epoch: [ 24/350] Progress: [0:00:19/1:41:59] Time: 19.550 (19.550) Data: 17.242 (17.242) Loss: 1.5440 (1.5440)
[INFO][2021-08-31 02:25:56]	Batch: [ 30/313] Head: [0/2] Epoch: [ 24/350] Progress: [0:04:31/0:45:42] Time: 14.482 (8.761) Data: 12.083 (6.376) Loss: 1.5360 (1.5534)
[INFO][2021-08-31 02:30:09]	Batch: [ 60/313] Head: [0/2] Epoch: [ 24/350] Progress: [0:08:44/0:44:52] Time: 14.528 (8.601) Data: 12.124 (6.222) Loss: 1.5336 (1.5533)
[INFO][2021-08-31 02:34:22]	Batch: [ 90/313] Head: [0/2] Epoch: [ 24/350] Progress: [0:12:57/0:44:33] Time: 14.186 (8.541) Data: 11.891 (6.171) Loss: 1.5282 (1.5538)
[INFO][2021-08-31 02:38:35]	Batch: [120/313] Head: [0/2] Epoch: [ 24/350] Progress: [0:17:10/0:44:24] Time: 14.109 (8.513) Data: 11.817 (6.148) Loss: 1.5320 (1.5536)
[INFO][2021-08-31 02:42:48]	Batch: [150/313] Head: [0/2] Epoch: [ 24/350] Progress: [0:21:23/0:44:20] Time: 14.447 (8.499) Data: 12.044 (6.137) Loss: 1.5497 (1.5530)
[INFO][2021-08-31 02:46:58]	Batch: [180/313] Head: [0/2] Epoch: [ 24/350] Progress: [0:25:33/0:44:12] Time: 13.624 (8.474) Data: 11.336 (6.117) Loss: 1.5787 (1.5523)
[INFO][2021-08-31 02:51:11]	Batch: [210/313] Head: [0/2] Epoch: [ 24/350] Progress: [0:29:46/0:44:09] Time: 14.301 (8.465) Data: 12.007 (6.105) Loss: 1.5448 (1.5508)
[INFO][2021-08-31 02:55:21]	Batch: [240/313] Head: [0/2] Epoch: [ 24/350] Progress: [0:33:56/0:44:05] Time: 14.369 (8.452) Data: 11.967 (6.094) Loss: 1.5634 (1.5503)
[INFO][2021-08-31 02:59:32]	Batch: [270/313] Head: [0/2] Epoch: [ 24/350] Progress: [0:38:07/0:44:01] Time: 12.838 (8.439) Data: 10.436 (6.084) Loss: 1.5501 (1.5501)
[INFO][2021-08-31 03:03:42]	Batch: [300/313] Head: [0/2] Epoch: [ 24/350] Progress: [0:42:17/0:43:58] Time: 11.481 (8.430) Data: 9.188 (6.075) Loss: 1.6033 (1.5503)
[INFO][2021-08-31 03:05:13]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-31 03:05:33]	Batch: [  0/313] Head: [1/2] Epoch: [ 24/350] Progress: [0:00:19/1:42:04] Time: 19.568 (19.568) Data: 17.258 (17.258) Loss: 1.5196 (1.5196)
[INFO][2021-08-31 03:09:47]	Batch: [ 30/313] Head: [1/2] Epoch: [ 24/350] Progress: [0:04:33/0:46:00] Time: 14.548 (8.818) Data: 12.144 (6.436) Loss: 1.5673 (1.5526)
[INFO][2021-08-31 03:13:59]	Batch: [ 60/313] Head: [1/2] Epoch: [ 24/350] Progress: [0:08:45/0:44:55] Time: 14.293 (8.611) Data: 11.893 (6.238) Loss: 1.5619 (1.5530)
[INFO][2021-08-31 03:18:09]	Batch: [ 90/313] Head: [1/2] Epoch: [ 24/350] Progress: [0:12:55/0:44:27] Time: 14.377 (8.524) Data: 11.975 (6.156) Loss: 1.5329 (1.5529)
[INFO][2021-08-31 03:22:19]	Batch: [120/313] Head: [1/2] Epoch: [ 24/350] Progress: [0:17:05/0:44:13] Time: 14.258 (8.479) Data: 11.860 (6.106) Loss: 1.5485 (1.5534)
[INFO][2021-08-31 03:26:29]	Batch: [150/313] Head: [1/2] Epoch: [ 24/350] Progress: [0:21:15/0:44:04] Time: 14.253 (8.449) Data: 11.851 (6.073) Loss: 1.5172 (1.5528)
[INFO][2021-08-31 03:30:39]	Batch: [180/313] Head: [1/2] Epoch: [ 24/350] Progress: [0:25:25/0:43:58] Time: 14.286 (8.429) Data: 11.880 (6.056) Loss: 1.5810 (1.5524)
[INFO][2021-08-31 03:34:49]	Batch: [210/313] Head: [1/2] Epoch: [ 24/350] Progress: [0:29:35/0:43:53] Time: 14.135 (8.414) Data: 11.842 (6.044) Loss: 1.5724 (1.5517)
[INFO][2021-08-31 03:39:00]	Batch: [240/313] Head: [1/2] Epoch: [ 24/350] Progress: [0:33:46/0:43:52] Time: 14.399 (8.409) Data: 12.106 (6.040) Loss: 1.5502 (1.5515)
[INFO][2021-08-31 03:43:11]	Batch: [270/313] Head: [1/2] Epoch: [ 24/350] Progress: [0:37:57/0:43:50] Time: 14.164 (8.403) Data: 11.870 (6.034) Loss: 1.5691 (1.5515)
[INFO][2021-08-31 03:47:21]	Batch: [300/313] Head: [1/2] Epoch: [ 24/350] Progress: [0:42:07/0:43:48] Time: 14.263 (8.397) Data: 11.865 (6.028) Loss: 1.5420 (1.5515)
[INFO][2021-08-31 03:48:52]	Start to evaluate after 24 epoch of training
[INFO][2021-08-31 03:48:52]	len(loader.dataset)
[INFO][2021-08-31 03:48:52]	5000
[DEBUG][2021-08-31 04:34:08]	Provided arguments will be stored in sessions/pickle10/config.yaml
[INFO][2021-08-31 04:34:08]	Start to declare training variable
[INFO][2021-08-31 04:34:08]	Session will be ran in device: [cuda]
[INFO][2021-08-31 04:34:08]	Start to prepare data
[INFO][2021-08-31 04:34:09]	otrainset----------------------: length 20000
[INFO][2021-08-31 04:34:10]	ptrainset----------------------: length 20000
[INFO][2021-08-31 04:34:11]	testset-------------: length 5000
[INFO][2021-08-31 04:34:11]	Start to build model
[DEBUG][2021-08-31 04:34:11]	Backbone [resnet34] is declared with cin [1] and cout [1000] [with] sobel
[DEBUG][2021-08-31 04:34:11]	Backbone will be created wit the following heads: [10, 10]
[DEBUG][2021-08-31 04:34:11]	Number of trainable parameters is [112]
[DEBUG][2021-08-31 04:34:11]	Number of frozen parameters is [2]
[DEBUG][2021-08-31 04:34:11]	Name of frozen parameters are: dict_keys(['sobel.0.weight', 'sobel.0.bias'])
[DEBUG][2021-08-31 04:34:11]	Going to use [Adam] optimizer for training with betas (0.9, 0.999), eps 0.000000, weight decay 0.000000 without amsgrad
[DEBUG][2021-08-31 04:34:11]	Going to use [fixed] learning policy for optimization with base learning rate [0.00001]
[INFO][2021-08-31 04:34:11]	Start to resume session for file: [sessions/pickle10/checkpoint/latest.ckpt]
[DEBUG][2021-08-31 04:34:11]	Totally loaded [222] parameters
[INFO][2021-08-31 04:34:11]	Data parallel will be used for acceleration purpose
[INFO][2021-08-31 04:34:11]	Start to train at 24 epoch with learning rate 0.000010
[INFO][2021-08-31 04:34:11]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-31 04:34:11]	hidx, head: 0, 10
[INFO][2021-08-31 04:34:11]	hidx, head: 1, 10
[INFO][2021-08-31 04:34:11]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-31 04:35:44]	Batch: [  0/313] Head: [0/2] Epoch: [ 24/350] Progress: [0:01:32/8:02:06] Time: 92.416 (92.416) Data: 62.766 (62.766) Loss: 1.5126 (1.5126)
[INFO][2021-08-31 04:40:34]	Batch: [ 30/313] Head: [0/2] Epoch: [ 24/350] Progress: [0:06:23/1:04:27] Time: 13.851 (12.355) Data: 11.451 (9.082) Loss: 1.5593 (1.5480)
[INFO][2021-08-31 04:44:38]	Batch: [ 60/313] Head: [0/2] Epoch: [ 24/350] Progress: [0:10:26/0:53:36] Time: 13.756 (10.276) Data: 11.466 (7.454) Loss: 1.5687 (1.5503)
[INFO][2021-08-31 04:48:42]	Batch: [ 90/313] Head: [0/2] Epoch: [ 24/350] Progress: [0:14:30/0:49:54] Time: 13.746 (9.567) Data: 11.455 (6.890) Loss: 1.5435 (1.5499)
[INFO][2021-08-31 04:52:46]	Batch: [120/313] Head: [0/2] Epoch: [ 24/350] Progress: [0:18:34/0:48:03] Time: 13.992 (9.212) Data: 11.594 (6.608) Loss: 1.5339 (1.5498)
[INFO][2021-08-31 04:56:50]	Batch: [150/313] Head: [0/2] Epoch: [ 24/350] Progress: [0:22:38/0:46:55] Time: 13.571 (8.995) Data: 11.279 (6.439) Loss: 1.5704 (1.5501)
[INFO][2021-08-31 05:00:53]	Batch: [180/313] Head: [0/2] Epoch: [ 24/350] Progress: [0:26:42/0:46:10] Time: 13.008 (8.851) Data: 10.715 (6.330) Loss: 1.5491 (1.5515)
[INFO][2021-08-31 05:04:57]	Batch: [210/313] Head: [0/2] Epoch: [ 24/350] Progress: [0:30:45/0:45:38] Time: 11.675 (8.748) Data: 9.376 (6.253) Loss: 1.5475 (1.5519)
[INFO][2021-08-31 05:09:01]	Batch: [240/313] Head: [0/2] Epoch: [ 24/350] Progress: [0:34:49/0:45:13] Time: 10.575 (8.671) Data: 8.282 (6.195) Loss: 1.5742 (1.5516)
[INFO][2021-08-31 05:13:05]	Batch: [270/313] Head: [0/2] Epoch: [ 24/350] Progress: [0:38:53/0:44:55] Time: 10.415 (8.612) Data: 8.015 (6.147) Loss: 1.5228 (1.5512)
[INFO][2021-08-31 05:17:09]	Batch: [300/313] Head: [0/2] Epoch: [ 24/350] Progress: [0:42:57/0:44:40] Time: 9.653 (8.565) Data: 7.358 (6.109) Loss: 1.5355 (1.5513)
[INFO][2021-08-31 05:18:39]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-31 05:18:59]	Batch: [  0/313] Head: [1/2] Epoch: [ 24/350] Progress: [0:00:19/1:39:21] Time: 19.046 (19.046) Data: 16.740 (16.740) Loss: 1.5660 (1.5660)
[INFO][2021-08-31 05:23:03]	Batch: [ 30/313] Head: [1/2] Epoch: [ 24/350] Progress: [0:04:23/0:44:25] Time: 14.015 (8.515) Data: 11.622 (6.159) Loss: 1.5539 (1.5527)
[INFO][2021-08-31 05:27:07]	Batch: [ 60/313] Head: [1/2] Epoch: [ 24/350] Progress: [0:08:27/0:43:26] Time: 13.889 (8.326) Data: 11.498 (5.966) Loss: 1.6037 (1.5514)
[INFO][2021-08-31 05:31:11]	Batch: [ 90/313] Head: [1/2] Epoch: [ 24/350] Progress: [0:12:31/0:43:05] Time: 13.975 (8.262) Data: 11.583 (5.902) Loss: 1.5948 (1.5501)
[INFO][2021-08-31 05:35:15]	Batch: [120/313] Head: [1/2] Epoch: [ 24/350] Progress: [0:16:35/0:42:55] Time: 13.842 (8.229) Data: 11.451 (5.864) Loss: 1.5553 (1.5499)
[INFO][2021-08-31 05:39:19]	Batch: [150/313] Head: [1/2] Epoch: [ 24/350] Progress: [0:20:39/0:42:49] Time: 13.411 (8.208) Data: 11.018 (5.839) Loss: 1.5588 (1.5507)
[INFO][2021-08-31 05:43:23]	Batch: [180/313] Head: [1/2] Epoch: [ 24/350] Progress: [0:24:43/0:42:44] Time: 10.712 (8.194) Data: 8.319 (5.827) Loss: 1.5556 (1.5517)
[INFO][2021-08-31 05:47:26]	Batch: [210/313] Head: [1/2] Epoch: [ 24/350] Progress: [0:28:46/0:42:41] Time: 8.196 (8.185) Data: 5.805 (5.815) Loss: 1.5586 (1.5517)
[INFO][2021-08-31 05:51:30]	Batch: [240/313] Head: [1/2] Epoch: [ 24/350] Progress: [0:32:50/0:42:39] Time: 5.654 (8.177) Data: 3.363 (5.807) Loss: 1.5882 (1.5517)
[INFO][2021-08-31 05:55:34]	Batch: [270/313] Head: [1/2] Epoch: [ 24/350] Progress: [0:36:54/0:42:37] Time: 3.497 (8.172) Data: 1.106 (5.803) Loss: 1.5427 (1.5522)
[INFO][2021-08-31 05:59:38]	Batch: [300/313] Head: [1/2] Epoch: [ 24/350] Progress: [0:40:58/0:42:36] Time: 2.291 (8.169) Data: 0.001 (5.801) Loss: 1.5288 (1.5523)
[INFO][2021-08-31 06:01:15]	Start to evaluate after 24 epoch of training
[INFO][2021-08-31 06:01:15]	len(loader.dataset)
[INFO][2021-08-31 06:01:15]	5000
[INFO][2021-08-31 06:04:19]	num_classes
[INFO][2021-08-31 06:04:19]	10
[INFO][2021-08-31 06:04:19]	[[   0 1995    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [1529    0    1    0    0    0    0    0    0    0]
 [   0    1    0    0    0    0    0    0    0    0]
 [   0    0    4    0    0    0    0    0    0    0]
 [   0    0  350    0    0    0    0    0    0    0]
 [   0    4    0    0    0    0    0    0    0    0]
 [   0    0  594    0    0    0    0    0    0    0]
 [ 404    0   51    0    0    0    0    0    0    0]
 [  67    0    0    0    0    0    0    0    0    0]]
[INFO][2021-08-31 06:04:19]	Evaluation results at epoch 24 are: ACC: 0.824, NMI: 0.824, ARI: 0.810
[INFO][2021-08-31 06:04:20]	Start to train at 25 epoch with learning rate 0.000010
[INFO][2021-08-31 06:04:20]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-31 06:04:20]	hidx, head: 0, 10
[INFO][2021-08-31 06:04:20]	hidx, head: 1, 10
[INFO][2021-08-31 06:04:20]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-31 06:04:39]	Batch: [  0/313] Head: [0/2] Epoch: [ 25/350] Progress: [0:00:18/1:38:22] Time: 18.857 (18.857) Data: 16.538 (16.538) Loss: 1.5832 (1.5832)
[INFO][2021-08-31 06:08:43]	Batch: [ 30/313] Head: [0/2] Epoch: [ 25/350] Progress: [0:04:23/0:44:16] Time: 13.863 (8.487) Data: 11.569 (6.147) Loss: 1.5438 (1.5539)
[INFO][2021-08-31 06:12:47]	Batch: [ 60/313] Head: [0/2] Epoch: [ 25/350] Progress: [0:08:27/0:43:22] Time: 13.519 (8.315) Data: 11.227 (5.981) Loss: 1.5580 (1.5498)
[INFO][2021-08-31 06:16:51]	Batch: [ 90/313] Head: [0/2] Epoch: [ 25/350] Progress: [0:12:31/0:43:04] Time: 12.597 (8.258) Data: 10.192 (5.922) Loss: 1.5287 (1.5525)
[INFO][2021-08-31 06:20:56]	Batch: [120/313] Head: [0/2] Epoch: [ 25/350] Progress: [0:16:35/0:42:55] Time: 11.642 (8.228) Data: 9.238 (5.884) Loss: 1.5472 (1.5525)
[INFO][2021-08-31 06:25:00]	Batch: [150/313] Head: [0/2] Epoch: [ 25/350] Progress: [0:20:39/0:42:49] Time: 10.567 (8.210) Data: 8.274 (5.861) Loss: 1.6189 (1.5523)
[INFO][2021-08-31 06:29:04]	Batch: [180/313] Head: [0/2] Epoch: [ 25/350] Progress: [0:24:43/0:42:45] Time: 9.598 (8.198) Data: 7.303 (5.852) Loss: 1.5413 (1.5514)
[INFO][2021-08-31 06:33:08]	Batch: [210/313] Head: [0/2] Epoch: [ 25/350] Progress: [0:28:47/0:42:43] Time: 8.659 (8.189) Data: 6.361 (5.845) Loss: 1.5429 (1.5504)
[INFO][2021-08-31 06:37:12]	Batch: [240/313] Head: [0/2] Epoch: [ 25/350] Progress: [0:32:51/0:42:41] Time: 7.552 (8.182) Data: 5.256 (5.843) Loss: 1.5428 (1.5510)
[INFO][2021-08-31 06:41:16]	Batch: [270/313] Head: [0/2] Epoch: [ 25/350] Progress: [0:36:56/0:42:39] Time: 6.575 (8.178) Data: 4.173 (5.837) Loss: 1.5110 (1.5508)
[INFO][2021-08-31 06:45:20]	Batch: [300/313] Head: [0/2] Epoch: [ 25/350] Progress: [0:41:00/0:42:38] Time: 5.533 (8.175) Data: 3.241 (5.834) Loss: 1.5639 (1.5516)
[INFO][2021-08-31 06:46:55]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-31 06:47:14]	Batch: [  0/313] Head: [1/2] Epoch: [ 25/350] Progress: [0:00:19/1:39:18] Time: 19.037 (19.037) Data: 16.726 (16.726) Loss: 1.5810 (1.5810)
[INFO][2021-08-31 06:51:19]	Batch: [ 30/313] Head: [1/2] Epoch: [ 25/350] Progress: [0:04:24/0:44:30] Time: 13.980 (8.533) Data: 11.573 (6.143) Loss: 1.5265 (1.5563)
[INFO][2021-08-31 06:55:25]	Batch: [ 60/313] Head: [1/2] Epoch: [ 25/350] Progress: [0:08:29/0:43:36] Time: 14.155 (8.359) Data: 11.752 (5.981) Loss: 1.5323 (1.5568)
[INFO][2021-08-31 06:59:30]	Batch: [ 90/313] Head: [1/2] Epoch: [ 25/350] Progress: [0:12:35/0:43:18] Time: 14.204 (8.303) Data: 11.800 (5.932) Loss: 1.5620 (1.5573)
[INFO][2021-08-31 07:03:36]	Batch: [120/313] Head: [1/2] Epoch: [ 25/350] Progress: [0:16:41/0:43:09] Time: 13.856 (8.273) Data: 11.451 (5.914) Loss: 1.5470 (1.5553)
[INFO][2021-08-31 07:07:41]	Batch: [150/313] Head: [1/2] Epoch: [ 25/350] Progress: [0:20:46/0:43:03] Time: 13.920 (8.254) Data: 11.627 (5.896) Loss: 1.5476 (1.5531)
[INFO][2021-08-31 07:11:47]	Batch: [180/313] Head: [1/2] Epoch: [ 25/350] Progress: [0:24:52/0:43:00] Time: 14.018 (8.244) Data: 11.617 (5.888) Loss: 1.5281 (1.5518)
[INFO][2021-08-31 07:15:51]	Batch: [210/313] Head: [1/2] Epoch: [ 25/350] Progress: [0:28:56/0:42:56] Time: 12.390 (8.230) Data: 10.099 (5.875) Loss: 1.6434 (1.5515)
[INFO][2021-08-31 07:19:55]	Batch: [240/313] Head: [1/2] Epoch: [ 25/350] Progress: [0:33:00/0:42:52] Time: 10.927 (8.219) Data: 8.526 (5.864) Loss: 1.5621 (1.5514)
[INFO][2021-08-31 07:23:59]	Batch: [270/313] Head: [1/2] Epoch: [ 25/350] Progress: [0:37:04/0:42:49] Time: 8.988 (8.210) Data: 6.696 (5.855) Loss: 1.5423 (1.5511)
[INFO][2021-08-31 07:28:04]	Batch: [300/313] Head: [1/2] Epoch: [ 25/350] Progress: [0:41:09/0:42:47] Time: 7.522 (8.203) Data: 5.228 (5.850) Loss: 1.5256 (1.5521)
[INFO][2021-08-31 07:29:36]	Start to evaluate after 25 epoch of training
[INFO][2021-08-31 07:29:36]	len(loader.dataset)
[INFO][2021-08-31 07:29:36]	5000
[INFO][2021-08-31 07:32:41]	num_classes
[INFO][2021-08-31 07:32:41]	10
[INFO][2021-08-31 07:32:41]	[[   0 1982    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [1255    0    0    0    0    0    0    0    0    0]
 [   0   17    0    0    0    0    0    0    0    0]
 [   0    0    3    0    0    0    0    0    0    0]
 [   0    0  362    0    0    0    0    0    0    0]
 [   0    1    0    0    0    0    0    0    0    0]
 [   0    0  603    0    0    0    0    0    0    0]
 [ 639    0   32    0    0    0    0    0    0    0]
 [ 106    0    0    0    0    0    0    0    0    0]]
[INFO][2021-08-31 07:32:41]	Evaluation results at epoch 25 are: ACC: 0.768, NMI: 0.809, ARI: 0.757
[INFO][2021-08-31 07:32:42]	Start to train at 26 epoch with learning rate 0.000010
[INFO][2021-08-31 07:32:42]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-31 07:32:42]	hidx, head: 0, 10
[INFO][2021-08-31 07:32:42]	hidx, head: 1, 10
[INFO][2021-08-31 07:32:42]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-31 07:33:01]	Batch: [  0/313] Head: [0/2] Epoch: [ 26/350] Progress: [0:00:19/1:39:20] Time: 19.042 (19.042) Data: 16.621 (16.621) Loss: 1.5687 (1.5687)
[INFO][2021-08-31 07:37:06]	Batch: [ 30/313] Head: [0/2] Epoch: [ 26/350] Progress: [0:04:23/0:44:22] Time: 14.024 (8.508) Data: 11.622 (6.165) Loss: 1.5162 (1.5492)
[INFO][2021-08-31 07:41:10]	Batch: [ 60/313] Head: [0/2] Epoch: [ 26/350] Progress: [0:08:28/0:43:27] Time: 13.879 (8.330) Data: 11.474 (5.977) Loss: 1.5157 (1.5519)
[INFO][2021-08-31 07:45:14]	Batch: [ 90/313] Head: [0/2] Epoch: [ 26/350] Progress: [0:12:32/0:43:07] Time: 14.048 (8.266) Data: 11.646 (5.919) Loss: 1.5460 (1.5513)
[INFO][2021-08-31 07:49:18]	Batch: [120/313] Head: [0/2] Epoch: [ 26/350] Progress: [0:16:36/0:42:57] Time: 13.985 (8.234) Data: 11.579 (5.892) Loss: 1.5484 (1.5513)
[INFO][2021-08-31 07:53:22]	Batch: [150/313] Head: [0/2] Epoch: [ 26/350] Progress: [0:20:40/0:42:50] Time: 13.963 (8.214) Data: 11.562 (5.870) Loss: 1.6017 (1.5514)
[INFO][2021-08-31 07:57:26]	Batch: [180/313] Head: [0/2] Epoch: [ 26/350] Progress: [0:24:44/0:42:46] Time: 13.870 (8.201) Data: 11.578 (5.859) Loss: 1.5343 (1.5504)
[INFO][2021-08-31 08:01:30]	Batch: [210/313] Head: [0/2] Epoch: [ 26/350] Progress: [0:28:48/0:42:44] Time: 13.868 (8.192) Data: 11.466 (5.848) Loss: 1.5189 (1.5505)
[INFO][2021-08-31 08:05:35]	Batch: [240/313] Head: [0/2] Epoch: [ 26/350] Progress: [0:32:53/0:42:42] Time: 13.576 (8.187) Data: 11.173 (5.842) Loss: 1.5641 (1.5510)
[INFO][2021-08-31 08:09:40]	Batch: [270/313] Head: [0/2] Epoch: [ 26/350] Progress: [0:36:58/0:42:42] Time: 13.538 (8.186) Data: 11.248 (5.839) Loss: 1.5205 (1.5508)
[INFO][2021-08-31 08:13:46]	Batch: [300/313] Head: [0/2] Epoch: [ 26/350] Progress: [0:41:04/0:42:42] Time: 13.634 (8.187) Data: 11.184 (5.840) Loss: 1.5320 (1.5508)
[INFO][2021-08-31 08:15:15]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-31 08:15:34]	Batch: [  0/313] Head: [1/2] Epoch: [ 26/350] Progress: [0:00:18/1:38:43] Time: 18.923 (18.923) Data: 16.610 (16.610) Loss: 1.5392 (1.5392)
[INFO][2021-08-31 08:19:38]	Batch: [ 30/313] Head: [1/2] Epoch: [ 26/350] Progress: [0:04:22/0:44:14] Time: 13.884 (8.481) Data: 11.591 (6.123) Loss: 1.5181 (1.5511)
[INFO][2021-08-31 08:23:42]	Batch: [ 60/313] Head: [1/2] Epoch: [ 26/350] Progress: [0:08:26/0:43:21] Time: 12.481 (8.310) Data: 10.081 (5.955) Loss: 1.5318 (1.5476)
[INFO][2021-08-31 08:27:46]	Batch: [ 90/313] Head: [1/2] Epoch: [ 26/350] Progress: [0:12:30/0:43:02] Time: 10.487 (8.252) Data: 8.087 (5.893) Loss: 1.5496 (1.5490)
[INFO][2021-08-31 08:31:50]	Batch: [120/313] Head: [1/2] Epoch: [ 26/350] Progress: [0:16:35/0:42:53] Time: 8.926 (8.224) Data: 6.525 (5.860) Loss: 1.5133 (1.5485)
[INFO][2021-08-31 08:35:55]	Batch: [150/313] Head: [1/2] Epoch: [ 26/350] Progress: [0:20:39/0:42:48] Time: 8.645 (8.206) Data: 6.245 (5.843) Loss: 1.5534 (1.5488)
[INFO][2021-08-31 08:39:59]	Batch: [180/313] Head: [1/2] Epoch: [ 26/350] Progress: [0:24:43/0:42:45] Time: 8.437 (8.196) Data: 6.033 (5.829) Loss: 1.5232 (1.5485)
[INFO][2021-08-31 08:44:03]	Batch: [210/313] Head: [1/2] Epoch: [ 26/350] Progress: [0:28:47/0:42:42] Time: 8.347 (8.187) Data: 6.052 (5.822) Loss: 1.6144 (1.5494)
[INFO][2021-08-31 08:48:07]	Batch: [240/313] Head: [1/2] Epoch: [ 26/350] Progress: [0:32:51/0:42:40] Time: 8.271 (8.180) Data: 5.977 (5.816) Loss: 1.5467 (1.5504)
[INFO][2021-08-31 08:52:11]	Batch: [270/313] Head: [1/2] Epoch: [ 26/350] Progress: [0:36:55/0:42:38] Time: 8.367 (8.175) Data: 5.966 (5.814) Loss: 1.5127 (1.5491)
[INFO][2021-08-31 08:56:15]	Batch: [300/313] Head: [1/2] Epoch: [ 26/350] Progress: [0:40:59/0:42:37] Time: 8.350 (8.171) Data: 5.950 (5.807) Loss: 1.5677 (1.5491)
[INFO][2021-08-31 08:57:46]	Start to evaluate after 26 epoch of training
[INFO][2021-08-31 08:57:46]	len(loader.dataset)
[INFO][2021-08-31 08:57:46]	5000
[INFO][2021-08-31 09:00:50]	num_classes
[INFO][2021-08-31 09:00:50]	10
[INFO][2021-08-31 09:00:50]	[[   0 1988    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [1477    0    0    0    0    0    0    0    0    0]
 [   0   11    0    0    0    0    0    0    0    0]
 [   0    0    5    0    0    0    0    0    0    0]
 [   0    0  397    0    0    0    0    0    0    0]
 [   0    1    0    0    0    0    0    0    0    0]
 [   0    0  561    0    0    0    0    0    0    0]
 [ 426    0   37    0    0    0    0    0    0    0]
 [  97    0    0    0    0    0    0    0    0    0]]
[INFO][2021-08-31 09:00:50]	Evaluation results at epoch 26 are: ACC: 0.805, NMI: 0.820, ARI: 0.795
[INFO][2021-08-31 09:00:50]	Start to train at 27 epoch with learning rate 0.000010
[INFO][2021-08-31 09:00:50]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-31 09:00:50]	hidx, head: 0, 10
[INFO][2021-08-31 09:00:50]	hidx, head: 1, 10
[INFO][2021-08-31 09:00:50]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-31 09:01:09]	Batch: [  0/313] Head: [0/2] Epoch: [ 27/350] Progress: [0:00:18/1:38:44] Time: 18.929 (18.929) Data: 16.620 (16.620) Loss: 1.5269 (1.5269)
[INFO][2021-08-31 09:05:13]	Batch: [ 30/313] Head: [0/2] Epoch: [ 27/350] Progress: [0:04:23/0:44:15] Time: 13.839 (8.484) Data: 11.433 (6.121) Loss: 1.5415 (1.5538)
[INFO][2021-08-31 09:09:17]	Batch: [ 60/313] Head: [0/2] Epoch: [ 27/350] Progress: [0:08:26/0:43:19] Time: 13.865 (8.304) Data: 11.570 (5.943) Loss: 1.5445 (1.5528)
[INFO][2021-08-31 09:13:21]	Batch: [ 90/313] Head: [0/2] Epoch: [ 27/350] Progress: [0:12:30/0:43:01] Time: 13.965 (8.248) Data: 11.561 (5.890) Loss: 1.5206 (1.5516)
[INFO][2021-08-31 09:17:24]	Batch: [120/313] Head: [0/2] Epoch: [ 27/350] Progress: [0:16:34/0:42:52] Time: 13.837 (8.218) Data: 11.493 (5.859) Loss: 1.5634 (1.5493)
[INFO][2021-08-31 09:21:28]	Batch: [150/313] Head: [0/2] Epoch: [ 27/350] Progress: [0:20:38/0:42:46] Time: 13.849 (8.201) Data: 11.447 (5.840) Loss: 1.5717 (1.5495)
[INFO][2021-08-31 09:25:32]	Batch: [180/313] Head: [0/2] Epoch: [ 27/350] Progress: [0:24:42/0:42:43] Time: 13.894 (8.189) Data: 11.598 (5.830) Loss: 1.5573 (1.5495)
[INFO][2021-08-31 09:29:36]	Batch: [210/313] Head: [0/2] Epoch: [ 27/350] Progress: [0:28:46/0:42:40] Time: 13.975 (8.181) Data: 11.575 (5.825) Loss: 1.5522 (1.5499)
[INFO][2021-08-31 09:33:40]	Batch: [240/313] Head: [0/2] Epoch: [ 27/350] Progress: [0:32:50/0:42:38] Time: 13.994 (8.176) Data: 11.595 (5.821) Loss: 1.5454 (1.5497)
[INFO][2021-08-31 09:37:45]	Batch: [270/313] Head: [0/2] Epoch: [ 27/350] Progress: [0:36:54/0:42:37] Time: 13.879 (8.171) Data: 11.479 (5.814) Loss: 1.5497 (1.5492)
[INFO][2021-08-31 09:41:49]	Batch: [300/313] Head: [0/2] Epoch: [ 27/350] Progress: [0:40:58/0:42:36] Time: 14.027 (8.169) Data: 11.622 (5.809) Loss: 1.5244 (1.5489)
[INFO][2021-08-31 09:43:18]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-31 09:43:37]	Batch: [  0/313] Head: [1/2] Epoch: [ 27/350] Progress: [0:00:18/1:39:04] Time: 18.991 (18.991) Data: 16.681 (16.681) Loss: 1.5192 (1.5192)
[INFO][2021-08-31 09:47:41]	Batch: [ 30/313] Head: [1/2] Epoch: [ 27/350] Progress: [0:04:23/0:44:16] Time: 13.860 (8.488) Data: 11.567 (6.141) Loss: 1.5249 (1.5509)
[INFO][2021-08-31 09:51:45]	Batch: [ 60/313] Head: [1/2] Epoch: [ 27/350] Progress: [0:08:27/0:43:22] Time: 13.544 (8.313) Data: 11.251 (5.954) Loss: 1.5496 (1.5517)
[INFO][2021-08-31 09:55:49]	Batch: [ 90/313] Head: [1/2] Epoch: [ 27/350] Progress: [0:12:30/0:43:03] Time: 13.364 (8.253) Data: 11.069 (5.897) Loss: 1.5593 (1.5494)
[INFO][2021-08-31 09:59:53]	Batch: [120/313] Head: [1/2] Epoch: [ 27/350] Progress: [0:16:34/0:42:53] Time: 13.498 (8.223) Data: 11.205 (5.876) Loss: 1.5531 (1.5518)
[INFO][2021-08-31 10:03:57]	Batch: [150/313] Head: [1/2] Epoch: [ 27/350] Progress: [0:20:39/0:42:48] Time: 13.561 (8.205) Data: 11.158 (5.854) Loss: 1.5697 (1.5516)
[INFO][2021-08-31 10:08:01]	Batch: [180/313] Head: [1/2] Epoch: [ 27/350] Progress: [0:24:43/0:42:44] Time: 13.749 (8.194) Data: 11.345 (5.836) Loss: 1.5269 (1.5516)
[INFO][2021-08-31 10:12:05]	Batch: [210/313] Head: [1/2] Epoch: [ 27/350] Progress: [0:28:47/0:42:42] Time: 13.681 (8.186) Data: 11.276 (5.823) Loss: 1.5296 (1.5524)
[INFO][2021-08-31 10:16:09]	Batch: [240/313] Head: [1/2] Epoch: [ 27/350] Progress: [0:32:51/0:42:40] Time: 13.983 (8.181) Data: 11.577 (5.817) Loss: 1.5630 (1.5527)
[INFO][2021-08-31 10:20:13]	Batch: [270/313] Head: [1/2] Epoch: [ 27/350] Progress: [0:36:55/0:42:39] Time: 13.779 (8.176) Data: 11.484 (5.810) Loss: 1.5658 (1.5527)
[INFO][2021-08-31 10:24:18]	Batch: [300/313] Head: [1/2] Epoch: [ 27/350] Progress: [0:41:00/0:42:38] Time: 13.900 (8.174) Data: 11.495 (5.805) Loss: 1.5693 (1.5523)
[INFO][2021-08-31 10:25:46]	Start to evaluate after 27 epoch of training
[INFO][2021-08-31 10:25:46]	len(loader.dataset)
[INFO][2021-08-31 10:25:46]	5000
[INFO][2021-08-31 10:28:50]	num_classes
[INFO][2021-08-31 10:28:50]	10
[INFO][2021-08-31 10:28:50]	[[   0 1996    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [1328    0    0    0    0    0    0    0    0    0]
 [   0    1    0    0    0    0    0    0    0    0]
 [   0    0   19    0    0    0    0    0    0    0]
 [   0    0  294    0    0    0    0    0    0    0]
 [   0    3    0    0    0    0    0    0    0    0]
 [   0    0  635    0    0    0    0    0    0    0]
 [ 643    0   52    0    0    0    0    0    0    0]
 [  29    0    0    0    0    0    0    0    0    0]]
[INFO][2021-08-31 10:28:50]	Evaluation results at epoch 27 are: ACC: 0.792, NMI: 0.815, ARI: 0.778
[INFO][2021-08-31 10:28:51]	Start to train at 28 epoch with learning rate 0.000010
[INFO][2021-08-31 10:28:51]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-31 10:28:51]	hidx, head: 0, 10
[INFO][2021-08-31 10:28:51]	hidx, head: 1, 10
[INFO][2021-08-31 10:28:51]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-31 10:29:10]	Batch: [  0/313] Head: [0/2] Epoch: [ 28/350] Progress: [0:00:18/1:38:48] Time: 18.941 (18.941) Data: 16.622 (16.622) Loss: 1.5885 (1.5885)
[INFO][2021-08-31 10:33:14]	Batch: [ 30/313] Head: [0/2] Epoch: [ 28/350] Progress: [0:04:22/0:44:14] Time: 13.882 (8.482) Data: 11.477 (6.097) Loss: 1.5593 (1.5521)
[INFO][2021-08-31 10:37:18]	Batch: [ 60/313] Head: [0/2] Epoch: [ 28/350] Progress: [0:08:26/0:43:21] Time: 13.863 (8.311) Data: 11.460 (5.920) Loss: 1.6206 (1.5525)
[INFO][2021-08-31 10:41:21]	Batch: [ 90/313] Head: [0/2] Epoch: [ 28/350] Progress: [0:12:30/0:43:01] Time: 13.971 (8.248) Data: 11.679 (5.862) Loss: 1.5394 (1.5503)
[INFO][2021-08-31 10:45:25]	Batch: [120/313] Head: [0/2] Epoch: [ 28/350] Progress: [0:16:34/0:42:53] Time: 14.167 (8.222) Data: 11.761 (5.855) Loss: 1.5550 (1.5490)
[INFO][2021-08-31 10:49:29]	Batch: [150/313] Head: [0/2] Epoch: [ 28/350] Progress: [0:20:38/0:42:47] Time: 13.752 (8.203) Data: 11.458 (5.835) Loss: 1.5266 (1.5482)
[INFO][2021-08-31 10:53:34]	Batch: [180/313] Head: [0/2] Epoch: [ 28/350] Progress: [0:24:43/0:42:45] Time: 13.829 (8.195) Data: 11.537 (5.826) Loss: 1.5738 (1.5495)
[INFO][2021-08-31 10:57:40]	Batch: [210/313] Head: [0/2] Epoch: [ 28/350] Progress: [0:28:49/0:42:45] Time: 13.989 (8.196) Data: 11.589 (5.826) Loss: 1.5195 (1.5488)
[INFO][2021-08-31 11:01:47]	Batch: [240/313] Head: [0/2] Epoch: [ 28/350] Progress: [0:32:56/0:42:46] Time: 14.103 (8.199) Data: 11.810 (5.830) Loss: 1.5402 (1.5488)
[INFO][2021-08-31 11:05:53]	Batch: [270/313] Head: [0/2] Epoch: [ 28/350] Progress: [0:37:02/0:42:47] Time: 13.935 (8.202) Data: 11.531 (5.832) Loss: 1.5598 (1.5479)
[INFO][2021-08-31 11:10:00]	Batch: [300/313] Head: [0/2] Epoch: [ 28/350] Progress: [0:41:09/0:42:47] Time: 14.225 (8.204) Data: 11.821 (5.834) Loss: 1.5580 (1.5487)
[INFO][2021-08-31 11:11:29]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-31 11:11:48]	Batch: [  0/313] Head: [1/2] Epoch: [ 28/350] Progress: [0:00:18/1:38:43] Time: 18.925 (18.925) Data: 16.613 (16.613) Loss: 1.5638 (1.5638)
[INFO][2021-08-31 11:15:53]	Batch: [ 30/313] Head: [1/2] Epoch: [ 28/350] Progress: [0:04:23/0:44:21] Time: 13.735 (8.503) Data: 11.443 (6.147) Loss: 1.5448 (1.5553)
[INFO][2021-08-31 11:19:57]	Batch: [ 60/313] Head: [1/2] Epoch: [ 28/350] Progress: [0:08:28/0:43:26] Time: 14.000 (8.328) Data: 11.708 (5.974) Loss: 1.5260 (1.5489)
[INFO][2021-08-31 11:24:02]	Batch: [ 90/313] Head: [1/2] Epoch: [ 28/350] Progress: [0:12:32/0:43:08] Time: 12.968 (8.270) Data: 10.671 (5.911) Loss: 1.5241 (1.5505)
[INFO][2021-08-31 11:28:06]	Batch: [120/313] Head: [1/2] Epoch: [ 28/350] Progress: [0:16:37/0:42:59] Time: 12.135 (8.241) Data: 9.844 (5.875) Loss: 1.5353 (1.5499)
[INFO][2021-08-31 11:32:11]	Batch: [150/313] Head: [1/2] Epoch: [ 28/350] Progress: [0:20:41/0:42:54] Time: 11.363 (8.224) Data: 8.960 (5.854) Loss: 1.5505 (1.5492)
[INFO][2021-08-31 11:36:16]	Batch: [180/313] Head: [1/2] Epoch: [ 28/350] Progress: [0:24:46/0:42:50] Time: 10.647 (8.213) Data: 8.246 (5.838) Loss: 1.5402 (1.5504)
[INFO][2021-08-31 11:40:21]	Batch: [210/313] Head: [1/2] Epoch: [ 28/350] Progress: [0:28:51/0:42:48] Time: 9.953 (8.206) Data: 7.662 (5.829) Loss: 1.5533 (1.5498)
[INFO][2021-08-31 11:44:27]	Batch: [240/313] Head: [1/2] Epoch: [ 28/350] Progress: [0:32:57/0:42:48] Time: 10.776 (8.207) Data: 8.373 (5.835) Loss: 1.5455 (1.5490)
[INFO][2021-08-31 11:48:33]	Batch: [270/313] Head: [1/2] Epoch: [ 28/350] Progress: [0:37:04/0:42:49] Time: 11.701 (8.208) Data: 9.298 (5.840) Loss: 1.5705 (1.5483)
[INFO][2021-08-31 11:52:40]	Batch: [300/313] Head: [1/2] Epoch: [ 28/350] Progress: [0:41:10/0:42:49] Time: 12.381 (8.208) Data: 10.086 (5.841) Loss: 1.5748 (1.5483)
[INFO][2021-08-31 11:54:10]	Start to evaluate after 28 epoch of training
[INFO][2021-08-31 11:54:10]	len(loader.dataset)
[INFO][2021-08-31 11:54:10]	5000
[INFO][2021-08-31 11:57:13]	num_classes
[INFO][2021-08-31 11:57:13]	10
[INFO][2021-08-31 11:57:13]	[[   0 2000    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [1292    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0   25    0    0    0    0    0    0    0]
 [   0    0  312    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0  635    0    0    0    0    0    0    0]
 [ 693    0   28    0    0    0    0    0    0    0]
 [  15    0    0    0    0    0    0    0    0    0]]
[INFO][2021-08-31 11:57:13]	Evaluation results at epoch 28 are: ACC: 0.785, NMI: 0.827, ARI: 0.780
[INFO][2021-08-31 11:57:14]	Start to train at 29 epoch with learning rate 0.000010
[INFO][2021-08-31 11:57:14]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-31 11:57:14]	hidx, head: 0, 10
[INFO][2021-08-31 11:57:14]	hidx, head: 1, 10
[INFO][2021-08-31 11:57:14]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-31 11:57:33]	Batch: [  0/313] Head: [0/2] Epoch: [ 29/350] Progress: [0:00:18/1:38:23] Time: 18.861 (18.861) Data: 16.543 (16.543) Loss: 1.5753 (1.5753)
[INFO][2021-08-31 12:01:36]	Batch: [ 30/313] Head: [0/2] Epoch: [ 29/350] Progress: [0:04:22/0:44:10] Time: 13.934 (8.469) Data: 11.530 (6.121) Loss: 1.5269 (1.5526)
[INFO][2021-08-31 12:05:40]	Batch: [ 60/313] Head: [0/2] Epoch: [ 29/350] Progress: [0:08:26/0:43:17] Time: 13.365 (8.299) Data: 10.962 (5.955) Loss: 1.5540 (1.5536)
[INFO][2021-08-31 12:09:44]	Batch: [ 90/313] Head: [0/2] Epoch: [ 29/350] Progress: [0:12:29/0:42:59] Time: 11.509 (8.240) Data: 9.106 (5.878) Loss: 1.5683 (1.5527)
[INFO][2021-08-31 12:13:47]	Batch: [120/313] Head: [0/2] Epoch: [ 29/350] Progress: [0:16:33/0:42:49] Time: 9.855 (8.210) Data: 7.452 (5.838) Loss: 1.5280 (1.5504)
[INFO][2021-08-31 12:17:51]	Batch: [150/313] Head: [0/2] Epoch: [ 29/350] Progress: [0:20:36/0:42:44] Time: 8.335 (8.192) Data: 5.937 (5.815) Loss: 1.5089 (1.5482)
[INFO][2021-08-31 12:21:54]	Batch: [180/313] Head: [0/2] Epoch: [ 29/350] Progress: [0:24:40/0:42:40] Time: 6.606 (8.180) Data: 4.206 (5.799) Loss: 1.5059 (1.5484)
[INFO][2021-08-31 12:25:58]	Batch: [210/313] Head: [0/2] Epoch: [ 29/350] Progress: [0:28:44/0:42:37] Time: 5.244 (8.172) Data: 2.841 (5.788) Loss: 1.5159 (1.5484)
[INFO][2021-08-31 12:30:02]	Batch: [240/313] Head: [0/2] Epoch: [ 29/350] Progress: [0:32:47/0:42:35] Time: 3.815 (8.166) Data: 1.521 (5.786) Loss: 1.5476 (1.5480)
[INFO][2021-08-31 12:34:06]	Batch: [270/313] Head: [0/2] Epoch: [ 29/350] Progress: [0:36:51/0:42:34] Time: 2.721 (8.162) Data: 0.318 (5.787) Loss: 1.5110 (1.5472)
[INFO][2021-08-31 12:38:11]	Batch: [300/313] Head: [0/2] Epoch: [ 29/350] Progress: [0:40:56/0:42:34] Time: 2.295 (8.163) Data: 0.001 (5.791) Loss: 1.5187 (1.5477)
[INFO][2021-08-31 12:39:48]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-31 12:40:07]	Batch: [  0/313] Head: [1/2] Epoch: [ 29/350] Progress: [0:00:19/1:39:29] Time: 19.073 (19.073) Data: 16.647 (16.647) Loss: 1.5738 (1.5738)
[INFO][2021-08-31 12:44:11]	Batch: [ 30/313] Head: [1/2] Epoch: [ 29/350] Progress: [0:04:23/0:44:19] Time: 13.942 (8.497) Data: 11.540 (6.111) Loss: 1.5390 (1.5485)
[INFO][2021-08-31 12:48:15]	Batch: [ 60/313] Head: [1/2] Epoch: [ 29/350] Progress: [0:08:27/0:43:23] Time: 12.324 (8.318) Data: 9.923 (5.937) Loss: 1.5553 (1.5472)
[INFO][2021-08-31 12:52:19]	Batch: [ 90/313] Head: [1/2] Epoch: [ 29/350] Progress: [0:12:31/0:43:04] Time: 9.613 (8.256) Data: 7.316 (5.879) Loss: 1.5803 (1.5475)
[INFO][2021-08-31 12:56:23]	Batch: [120/313] Head: [1/2] Epoch: [ 29/350] Progress: [0:16:35/0:42:54] Time: 7.427 (8.224) Data: 5.136 (5.862) Loss: 1.5286 (1.5468)
[INFO][2021-08-31 13:00:27]	Batch: [150/313] Head: [1/2] Epoch: [ 29/350] Progress: [0:20:39/0:42:48] Time: 5.460 (8.205) Data: 3.056 (5.838) Loss: 1.5479 (1.5469)
[INFO][2021-08-31 13:04:31]	Batch: [180/313] Head: [1/2] Epoch: [ 29/350] Progress: [0:24:42/0:42:43] Time: 2.990 (8.191) Data: 0.699 (5.823) Loss: 1.5362 (1.5466)
[INFO][2021-08-31 13:08:36]	Batch: [210/313] Head: [1/2] Epoch: [ 29/350] Progress: [0:28:47/0:42:42] Time: 2.293 (8.188) Data: 0.001 (5.818) Loss: 1.5635 (1.5465)
[INFO][2021-08-31 13:12:41]	Batch: [240/313] Head: [1/2] Epoch: [ 29/350] Progress: [0:32:53/0:42:43] Time: 2.293 (8.189) Data: 0.001 (5.823) Loss: 1.5326 (1.5463)
[INFO][2021-08-31 13:16:47]	Batch: [270/313] Head: [1/2] Epoch: [ 29/350] Progress: [0:36:59/0:42:43] Time: 2.291 (8.189) Data: 0.001 (5.828) Loss: 1.5442 (1.5468)
[INFO][2021-08-31 13:20:53]	Batch: [300/313] Head: [1/2] Epoch: [ 29/350] Progress: [0:41:05/0:42:43] Time: 2.400 (8.191) Data: 0.001 (5.829) Loss: 1.5512 (1.5472)
[INFO][2021-08-31 13:22:31]	Start to evaluate after 29 epoch of training
[INFO][2021-08-31 13:22:31]	len(loader.dataset)
[INFO][2021-08-31 13:22:31]	5000
[INFO][2021-08-31 13:25:35]	num_classes
[INFO][2021-08-31 13:25:35]	10
[INFO][2021-08-31 13:25:35]	[[   0 2000    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [1292    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0    7    0    0    0    0    0    0    0]
 [   0    0  290    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0  677    0    0    0    0    0    0    0]
 [ 655    0   26    0    0    0    0    0    0    0]
 [  53    0    0    0    0    0    0    0    0    0]]
[INFO][2021-08-31 13:25:35]	Evaluation results at epoch 29 are: ACC: 0.794, NMI: 0.826, ARI: 0.780
[INFO][2021-08-31 13:25:35]	Start to train at 30 epoch with learning rate 0.000010
[INFO][2021-08-31 13:25:35]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-31 13:25:35]	hidx, head: 0, 10
[INFO][2021-08-31 13:25:35]	hidx, head: 1, 10
[INFO][2021-08-31 13:25:35]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-31 13:25:54]	Batch: [  0/313] Head: [0/2] Epoch: [ 30/350] Progress: [0:00:18/1:38:46] Time: 18.933 (18.933) Data: 16.605 (16.605) Loss: 1.5372 (1.5372)
[INFO][2021-08-31 13:29:58]	Batch: [ 30/313] Head: [0/2] Epoch: [ 30/350] Progress: [0:04:22/0:44:12] Time: 13.822 (8.474) Data: 11.418 (6.096) Loss: 1.5409 (1.5478)
[INFO][2021-08-31 13:34:02]	Batch: [ 60/313] Head: [0/2] Epoch: [ 30/350] Progress: [0:08:26/0:43:19] Time: 11.508 (8.305) Data: 9.216 (5.926) Loss: 1.5516 (1.5467)
[INFO][2021-08-31 13:38:06]	Batch: [ 90/313] Head: [0/2] Epoch: [ 30/350] Progress: [0:12:30/0:43:02] Time: 9.165 (8.250) Data: 6.763 (5.873) Loss: 1.5557 (1.5483)
[INFO][2021-08-31 13:42:10]	Batch: [120/313] Head: [0/2] Epoch: [ 30/350] Progress: [0:16:34/0:42:52] Time: 7.035 (8.219) Data: 4.741 (5.846) Loss: 1.5444 (1.5488)
[INFO][2021-08-31 13:46:14]	Batch: [150/313] Head: [0/2] Epoch: [ 30/350] Progress: [0:20:38/0:42:47] Time: 4.017 (8.202) Data: 1.615 (5.830) Loss: 1.5345 (1.5477)
[INFO][2021-08-31 13:50:19]	Batch: [180/313] Head: [0/2] Epoch: [ 30/350] Progress: [0:24:43/0:42:45] Time: 2.290 (8.195) Data: 0.001 (5.830) Loss: 1.5210 (1.5471)
[INFO][2021-08-31 13:54:25]	Batch: [210/313] Head: [0/2] Epoch: [ 30/350] Progress: [0:28:50/0:42:46] Time: 2.293 (8.199) Data: 0.001 (5.837) Loss: 1.5455 (1.5471)
[INFO][2021-08-31 13:58:31]	Batch: [240/313] Head: [0/2] Epoch: [ 30/350] Progress: [0:32:55/0:42:45] Time: 2.292 (8.198) Data: 0.001 (5.835) Loss: 1.5408 (1.5470)
[INFO][2021-08-31 14:02:37]	Batch: [270/313] Head: [0/2] Epoch: [ 30/350] Progress: [0:37:01/0:42:45] Time: 2.292 (8.197) Data: 0.001 (5.837) Loss: 1.5489 (1.5475)
[INFO][2021-08-31 14:06:41]	Batch: [300/313] Head: [0/2] Epoch: [ 30/350] Progress: [0:41:05/0:42:43] Time: 2.292 (8.191) Data: 0.001 (5.831) Loss: 1.5337 (1.5474)
[INFO][2021-08-31 14:08:18]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-31 14:08:37]	Batch: [  0/313] Head: [1/2] Epoch: [ 30/350] Progress: [0:00:18/1:38:49] Time: 18.944 (18.944) Data: 16.630 (16.630) Loss: 1.5426 (1.5426)
[DEBUG][2021-08-31 14:13:33]	Provided arguments will be stored in sessions/pickle10/config.yaml
[INFO][2021-08-31 14:13:33]	Start to declare training variable
[INFO][2021-08-31 14:13:33]	Session will be ran in device: [cuda]
[INFO][2021-08-31 14:13:33]	Start to prepare data
[INFO][2021-08-31 14:13:34]	otrainset----------------------: length 20000
[INFO][2021-08-31 14:13:35]	ptrainset----------------------: length 20000
[INFO][2021-08-31 14:13:35]	testset-------------: length 5000
[INFO][2021-08-31 14:13:35]	Start to build model
[DEBUG][2021-08-31 14:13:35]	Backbone [resnet34] is declared with cin [1] and cout [1000] [with] sobel
[DEBUG][2021-08-31 14:13:35]	Backbone will be created wit the following heads: [10, 10]
[DEBUG][2021-08-31 14:13:36]	Number of trainable parameters is [112]
[DEBUG][2021-08-31 14:13:36]	Number of frozen parameters is [2]
[DEBUG][2021-08-31 14:13:36]	Name of frozen parameters are: dict_keys(['sobel.0.weight', 'sobel.0.bias'])
[DEBUG][2021-08-31 14:13:36]	Going to use [Adam] optimizer for training with betas (0.9, 0.999), eps 0.000000, weight decay 0.000000 without amsgrad
[DEBUG][2021-08-31 14:13:36]	Going to use [fixed] learning policy for optimization with base learning rate [0.00001]
[INFO][2021-08-31 14:13:36]	Start to resume session for file: [sessions/pickle10/checkpoint/latest.ckpt]
[DEBUG][2021-08-31 14:13:36]	Totally loaded [222] parameters
[INFO][2021-08-31 14:13:36]	Data parallel will be used for acceleration purpose
[INFO][2021-08-31 14:13:36]	Start to train at 30 epoch with learning rate 0.000010
[INFO][2021-08-31 14:13:36]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-31 14:13:36]	hidx, head: 0, 10
[INFO][2021-08-31 14:13:36]	hidx, head: 1, 10
[INFO][2021-08-31 14:13:36]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-31 14:15:09]	Batch: [  0/313] Head: [0/2] Epoch: [ 30/350] Progress: [0:01:33/8:05:13] Time: 93.014 (93.014) Data: 66.586 (66.586) Loss: 1.5297 (1.5297)
[INFO][2021-08-31 14:20:10]	Batch: [ 30/313] Head: [0/2] Epoch: [ 30/350] Progress: [0:06:34/1:06:19] Time: 15.018 (12.713) Data: 12.615 (9.548) Loss: 1.5349 (1.5553)
[INFO][2021-08-31 14:24:30]	Batch: [ 60/313] Head: [0/2] Epoch: [ 30/350] Progress: [0:10:53/0:55:55] Time: 14.743 (10.720) Data: 12.345 (7.939) Loss: 1.5386 (1.5527)
[INFO][2021-08-31 14:28:48]	Batch: [ 90/313] Head: [0/2] Epoch: [ 30/350] Progress: [0:15:11/0:52:16] Time: 14.947 (10.020) Data: 12.651 (7.379) Loss: 1.5647 (1.5510)
[INFO][2021-08-31 14:33:06]	Batch: [120/313] Head: [0/2] Epoch: [ 30/350] Progress: [0:19:30/0:50:27] Time: 15.041 (9.672) Data: 12.751 (7.105) Loss: 1.5771 (1.5498)
[INFO][2021-08-31 14:37:25]	Batch: [150/313] Head: [0/2] Epoch: [ 30/350] Progress: [0:23:49/0:49:22] Time: 15.089 (9.466) Data: 12.685 (6.947) Loss: 1.5477 (1.5489)
[INFO][2021-08-31 14:41:44]	Batch: [180/313] Head: [0/2] Epoch: [ 30/350] Progress: [0:28:08/0:48:39] Time: 13.987 (9.327) Data: 11.584 (6.839) Loss: 1.5453 (1.5485)
[INFO][2021-08-31 14:46:03]	Batch: [210/313] Head: [0/2] Epoch: [ 30/350] Progress: [0:32:26/0:48:07] Time: 9.868 (9.226) Data: 7.575 (6.764) Loss: 1.5393 (1.5480)
[INFO][2021-08-31 14:50:21]	Batch: [240/313] Head: [0/2] Epoch: [ 30/350] Progress: [0:36:45/0:47:44] Time: 10.468 (9.151) Data: 8.176 (6.708) Loss: 1.5777 (1.5478)
[INFO][2021-08-31 14:54:38]	Batch: [270/313] Head: [0/2] Epoch: [ 30/350] Progress: [0:41:02/0:47:23] Time: 8.166 (9.086) Data: 5.871 (6.659) Loss: 1.5890 (1.5475)
[INFO][2021-08-31 14:58:54]	Batch: [300/313] Head: [0/2] Epoch: [ 30/350] Progress: [0:45:18/0:47:06] Time: 6.036 (9.032) Data: 3.746 (6.617) Loss: 1.5148 (1.5477)
[INFO][2021-08-31 15:00:36]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-31 15:00:56]	Batch: [  0/313] Head: [1/2] Epoch: [ 30/350] Progress: [0:00:20/1:45:01] Time: 20.132 (20.132) Data: 17.830 (17.830) Loss: 1.5882 (1.5882)
[INFO][2021-08-31 15:05:15]	Batch: [ 30/313] Head: [1/2] Epoch: [ 30/350] Progress: [0:04:39/0:47:00] Time: 15.053 (9.011) Data: 12.760 (6.681) Loss: 1.5897 (1.5549)
[INFO][2021-08-31 15:09:33]	Batch: [ 60/313] Head: [1/2] Epoch: [ 30/350] Progress: [0:08:57/0:45:58] Time: 14.475 (8.812) Data: 12.185 (6.482) Loss: 1.5529 (1.5526)
[INFO][2021-08-31 15:13:53]	Batch: [ 90/313] Head: [1/2] Epoch: [ 30/350] Progress: [0:13:17/0:45:43] Time: 15.094 (8.767) Data: 12.799 (6.444) Loss: 1.5306 (1.5511)
[INFO][2021-08-31 15:18:14]	Batch: [120/313] Head: [1/2] Epoch: [ 30/350] Progress: [0:17:38/0:45:38] Time: 15.097 (8.748) Data: 12.808 (6.428) Loss: 1.5489 (1.5491)
[INFO][2021-08-31 15:22:34]	Batch: [150/313] Head: [1/2] Epoch: [ 30/350] Progress: [0:21:57/0:45:31] Time: 13.148 (8.728) Data: 10.850 (6.409) Loss: 1.5197 (1.5487)
[INFO][2021-08-31 15:26:54]	Batch: [180/313] Head: [1/2] Epoch: [ 30/350] Progress: [0:26:18/0:45:29] Time: 12.461 (8.719) Data: 10.166 (6.405) Loss: 1.5429 (1.5480)
[INFO][2021-08-31 15:31:14]	Batch: [210/313] Head: [1/2] Epoch: [ 30/350] Progress: [0:30:38/0:45:26] Time: 9.786 (8.712) Data: 7.384 (6.394) Loss: 1.5452 (1.5475)
[INFO][2021-08-31 15:35:35]	Batch: [240/313] Head: [1/2] Epoch: [ 30/350] Progress: [0:34:59/0:45:26] Time: 8.140 (8.710) Data: 5.737 (6.382) Loss: 1.5537 (1.5481)
[INFO][2021-08-31 15:39:56]	Batch: [270/313] Head: [1/2] Epoch: [ 30/350] Progress: [0:39:20/0:45:26] Time: 6.207 (8.710) Data: 3.810 (6.379) Loss: 1.5298 (1.5477)
[INFO][2021-08-31 15:44:17]	Batch: [300/313] Head: [1/2] Epoch: [ 30/350] Progress: [0:43:41/0:45:25] Time: 5.116 (8.708) Data: 2.706 (6.372) Loss: 1.6000 (1.5473)
[INFO][2021-08-31 15:45:58]	Start to evaluate after 30 epoch of training
[INFO][2021-08-31 15:45:58]	len(loader.dataset)
[INFO][2021-08-31 15:45:58]	5000
[INFO][2021-08-31 15:49:10]	num_classes
[INFO][2021-08-31 15:49:10]	10
[INFO][2021-08-31 15:49:10]	[[   0 1972    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [1191    0    0    0    0    0    0    0    0    0]
 [   0   22    0    0    0    0    0    0    0    0]
 [   0    0   21    0    0    0    0    0    0    0]
 [   0    0  413    0    0    0    0    0    0    0]
 [   0    6    0    0    0    0    0    0    0    0]
 [   0    0  555    0    0    0    0    0    0    0]
 [ 781    0   11    0    0    0    0    0    0    0]
 [  28    0    0    0    0    0    0    0    0    0]]
[INFO][2021-08-31 15:49:10]	Evaluation results at epoch 30 are: ACC: 0.744, NMI: 0.820, ARI: 0.757
[INFO][2021-08-31 15:49:10]	Start to train at 31 epoch with learning rate 0.000010
[INFO][2021-08-31 15:49:10]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-08-31 15:49:10]	hidx, head: 0, 10
[INFO][2021-08-31 15:49:10]	hidx, head: 1, 10
[INFO][2021-08-31 15:49:10]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-31 15:49:30]	Batch: [  0/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:00:20/1:46:03] Time: 20.330 (20.330) Data: 18.031 (18.031) Loss: 1.5435 (1.5435)
[INFO][2021-08-31 15:53:53]	Batch: [ 30/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:04:42/0:47:35] Time: 15.015 (9.122) Data: 12.720 (6.753) Loss: 1.5784 (1.5552)
[INFO][2021-08-31 15:58:14]	Batch: [ 60/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:09:04/0:46:31] Time: 15.009 (8.918) Data: 12.715 (6.571) Loss: 1.6257 (1.5531)
[INFO][2021-08-31 16:02:37]	Batch: [ 90/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:13:26/0:46:14] Time: 15.228 (8.864) Data: 12.935 (6.509) Loss: 1.5425 (1.5514)
[INFO][2021-08-31 16:06:58]	Batch: [120/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:17:48/0:46:03] Time: 14.622 (8.830) Data: 12.331 (6.474) Loss: 1.5745 (1.5494)
[INFO][2021-08-31 16:11:21]	Batch: [150/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:22:10/0:45:58] Time: 15.065 (8.814) Data: 12.661 (6.458) Loss: 1.5524 (1.5486)
[INFO][2021-08-31 16:15:42]	Batch: [180/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:26:31/0:45:52] Time: 14.906 (8.795) Data: 12.502 (6.440) Loss: 1.5714 (1.5482)
[INFO][2021-08-31 16:20:04]	Batch: [210/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:30:53/0:45:50] Time: 15.000 (8.787) Data: 12.710 (6.433) Loss: 1.5460 (1.5471)
[INFO][2021-08-31 16:24:26]	Batch: [240/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:35:15/0:45:47] Time: 14.823 (8.779) Data: 12.529 (6.429) Loss: 1.5792 (1.5469)
[INFO][2021-08-31 16:28:48]	Batch: [270/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:39:38/0:45:47] Time: 15.261 (8.777) Data: 12.857 (6.427) Loss: 1.5473 (1.5471)
[INFO][2021-08-31 16:33:09]	Batch: [300/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:43:58/0:45:43] Time: 15.406 (8.767) Data: 13.002 (6.418) Loss: 1.5687 (1.5467)
[INFO][2021-08-31 16:34:43]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-08-31 16:35:03]	Batch: [  0/313] Head: [1/2] Epoch: [ 31/350] Progress: [0:00:19/1:43:55] Time: 19.921 (19.921) Data: 17.508 (17.508) Loss: 1.5457 (1.5457)
[INFO][2021-08-31 16:39:24]	Batch: [ 30/313] Head: [1/2] Epoch: [ 31/350] Progress: [0:04:41/0:47:19] Time: 14.993 (9.073) Data: 12.592 (6.694) Loss: 1.5221 (1.5406)
[INFO][2021-08-31 16:43:45]	Batch: [ 60/313] Head: [1/2] Epoch: [ 31/350] Progress: [0:09:01/0:46:19] Time: 14.650 (8.880) Data: 12.355 (6.506) Loss: 1.5338 (1.5425)
[INFO][2021-08-31 16:48:06]	Batch: [ 90/313] Head: [1/2] Epoch: [ 31/350] Progress: [0:13:22/0:46:00] Time: 14.935 (8.820) Data: 12.533 (6.452) Loss: 1.5480 (1.5442)
[INFO][2021-08-31 16:52:27]	Batch: [120/313] Head: [1/2] Epoch: [ 31/350] Progress: [0:17:44/0:45:52] Time: 15.091 (8.794) Data: 12.689 (6.429) Loss: 1.5466 (1.5460)
[INFO][2021-08-31 16:56:47]	Batch: [150/313] Head: [1/2] Epoch: [ 31/350] Progress: [0:22:03/0:45:44] Time: 14.128 (8.768) Data: 11.727 (6.407) Loss: 1.5425 (1.5450)
[INFO][2021-08-31 17:01:07]	Batch: [180/313] Head: [1/2] Epoch: [ 31/350] Progress: [0:26:24/0:45:39] Time: 13.248 (8.751) Data: 10.850 (6.391) Loss: 1.5183 (1.5459)
[INFO][2021-08-31 17:05:28]	Batch: [210/313] Head: [1/2] Epoch: [ 31/350] Progress: [0:30:44/0:45:36] Time: 12.821 (8.742) Data: 10.422 (6.386) Loss: 1.5540 (1.5460)
[INFO][2021-08-31 17:09:49]	Batch: [240/313] Head: [1/2] Epoch: [ 31/350] Progress: [0:35:05/0:45:34] Time: 13.481 (8.737) Data: 11.080 (6.379) Loss: 1.5603 (1.5453)
[DEBUG][2021-09-01 01:45:34]	Provided arguments will be stored in sessions/pickle10/config.yaml
[INFO][2021-09-01 01:45:34]	Start to declare training variable
[INFO][2021-09-01 01:45:34]	Session will be ran in device: [cuda]
[INFO][2021-09-01 01:45:34]	Start to prepare data
[INFO][2021-09-01 01:45:35]	otrainset----------------------: length 20000
[INFO][2021-09-01 01:45:35]	ptrainset----------------------: length 20000
[INFO][2021-09-01 01:45:36]	testset-------------: length 5000
[INFO][2021-09-01 01:45:36]	Start to build model
[DEBUG][2021-09-01 01:45:36]	Backbone [resnet34] is declared with cin [1] and cout [1000] [with] sobel
[DEBUG][2021-09-01 01:45:36]	Backbone will be created wit the following heads: [10, 10]
[DEBUG][2021-09-01 01:45:36]	Number of trainable parameters is [112]
[DEBUG][2021-09-01 01:45:36]	Number of frozen parameters is [2]
[DEBUG][2021-09-01 01:45:36]	Name of frozen parameters are: dict_keys(['sobel.0.weight', 'sobel.0.bias'])
[DEBUG][2021-09-01 01:45:36]	Going to use [Adam] optimizer for training with betas (0.9, 0.999), eps 0.000000, weight decay 0.000000 without amsgrad
[DEBUG][2021-09-01 01:45:36]	Going to use [fixed] learning policy for optimization with base learning rate [0.00001]
[INFO][2021-09-01 01:45:36]	Start to resume session for file: [sessions/pickle10/checkpoint/latest.ckpt]
[DEBUG][2021-09-01 01:45:36]	Totally loaded [222] parameters
[INFO][2021-09-01 01:45:36]	Data parallel will be used for acceleration purpose
[INFO][2021-09-01 01:45:36]	Start to train at 31 epoch with learning rate 0.000010
[INFO][2021-09-01 01:45:36]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-09-01 01:45:36]	hidx, head: 0, 10
[INFO][2021-09-01 01:45:36]	hidx, head: 1, 10
[INFO][2021-09-01 01:45:36]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-09-01 01:47:08]	Batch: [  0/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:01:31/7:58:59] Time: 91.818 (91.818) Data: 65.233 (65.233) Loss: 1.5590 (1.5590)
[INFO][2021-09-01 01:53:13]	Batch: [ 30/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:07:36/1:16:52] Time: 14.582 (14.736) Data: 12.178 (11.579) Loss: 1.5227 (1.5514)
[INFO][2021-09-01 01:57:26]	Batch: [ 60/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:11:49/1:00:41] Time: 14.186 (11.633) Data: 11.781 (8.869) Loss: 1.5453 (1.5488)
[INFO][2021-09-01 02:01:38]	Batch: [ 90/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:16:01/0:55:08] Time: 10.533 (10.571) Data: 8.113 (7.926) Loss: 1.5608 (1.5488)
[INFO][2021-09-01 02:05:51]	Batch: [120/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:20:15/0:52:23] Time: 9.606 (10.043) Data: 7.199 (7.458) Loss: 1.5548 (1.5469)
[INFO][2021-09-01 02:10:05]	Batch: [150/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:24:29/0:50:45] Time: 8.375 (9.729) Data: 5.967 (7.179) Loss: 1.5442 (1.5443)
[INFO][2021-09-01 02:14:19]	Batch: [180/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:28:43/0:49:39] Time: 6.942 (9.520) Data: 4.535 (6.998) Loss: 1.5615 (1.5457)
[INFO][2021-09-01 02:18:34]	Batch: [210/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:32:57/0:48:54] Time: 7.524 (9.374) Data: 5.231 (6.876) Loss: 1.5547 (1.5451)
[INFO][2021-09-01 02:22:49]	Batch: [240/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:37:13/0:48:20] Time: 9.439 (9.266) Data: 7.147 (6.782) Loss: 1.5720 (1.5458)
[INFO][2021-09-01 02:27:04]	Batch: [270/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:41:27/0:47:53] Time: 10.143 (9.181) Data: 7.737 (6.706) Loss: 1.5324 (1.5457)
[DEBUG][2021-09-01 14:12:44]	Provided arguments will be stored in sessions/pickle10/config.yaml
[INFO][2021-09-01 14:12:44]	Start to declare training variable
[INFO][2021-09-01 14:12:44]	Session will be ran in device: [cuda]
[INFO][2021-09-01 14:12:44]	Start to prepare data
[INFO][2021-09-01 14:12:45]	otrainset----------------------: length 20000
[INFO][2021-09-01 14:12:46]	ptrainset----------------------: length 20000
[INFO][2021-09-01 14:12:47]	testset-------------: length 5000
[INFO][2021-09-01 14:12:47]	Start to build model
[DEBUG][2021-09-01 14:12:47]	Backbone [resnet34] is declared with cin [1] and cout [1000] [with] sobel
[DEBUG][2021-09-01 14:12:47]	Backbone will be created wit the following heads: [10, 10]
[DEBUG][2021-09-01 14:12:47]	Number of trainable parameters is [112]
[DEBUG][2021-09-01 14:12:47]	Number of frozen parameters is [2]
[DEBUG][2021-09-01 14:12:47]	Name of frozen parameters are: dict_keys(['sobel.0.weight', 'sobel.0.bias'])
[DEBUG][2021-09-01 14:12:47]	Going to use [Adam] optimizer for training with betas (0.9, 0.999), eps 0.000000, weight decay 0.000000 without amsgrad
[DEBUG][2021-09-01 14:12:47]	Going to use [fixed] learning policy for optimization with base learning rate [0.00001]
[INFO][2021-09-01 14:12:47]	Start to resume session for file: [sessions/pickle10/checkpoint/latest.ckpt]
[DEBUG][2021-09-01 14:12:47]	Totally loaded [222] parameters
[INFO][2021-09-01 14:12:47]	Data parallel will be used for acceleration purpose
[INFO][2021-09-01 14:12:47]	Start to train at 31 epoch with learning rate 0.000010
[INFO][2021-09-01 14:12:47]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-09-01 14:12:47]	hidx, head: 0, 10
[INFO][2021-09-01 14:12:47]	hidx, head: 1, 10
[INFO][2021-09-01 14:12:47]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-09-01 14:14:13]	Batch: [  0/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:01:25/7:25:30] Time: 85.400 (85.400) Data: 62.249 (62.249) Loss: 1.5599 (1.5599)
[INFO][2021-09-01 14:18:10]	Batch: [ 30/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:05:22/0:54:19] Time: 14.023 (10.413) Data: 11.608 (7.359) Loss: 1.5510 (1.5496)
[INFO][2021-09-01 14:22:15]	Batch: [ 60/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:09:27/0:48:33] Time: 13.846 (9.308) Data: 11.432 (6.578) Loss: 1.5297 (1.5481)
[INFO][2021-09-01 14:26:19]	Batch: [ 90/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:13:32/0:46:33] Time: 13.885 (8.924) Data: 11.453 (6.302) Loss: 1.5467 (1.5473)
[INFO][2021-09-01 14:30:24]	Batch: [120/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:17:36/0:45:34] Time: 13.950 (8.735) Data: 11.643 (6.181) Loss: 1.5119 (1.5471)
[INFO][2021-09-01 14:34:29]	Batch: [150/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:21:41/0:44:58] Time: 13.907 (8.622) Data: 11.493 (6.104) Loss: 1.5394 (1.5454)
[INFO][2021-09-01 14:38:34]	Batch: [180/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:25:46/0:44:34] Time: 14.020 (8.545) Data: 11.716 (6.052) Loss: 1.5729 (1.5457)
[DEBUG][2021-09-01 17:28:07]	Provided arguments will be stored in sessions/pickle10/config.yaml
[INFO][2021-09-01 17:28:07]	Start to declare training variable
[INFO][2021-09-01 17:28:07]	Session will be ran in device: [cuda]
[INFO][2021-09-01 17:28:07]	Start to prepare data
[INFO][2021-09-01 17:28:08]	otrainset----------------------: length 20000
[INFO][2021-09-01 17:28:09]	ptrainset----------------------: length 20000
[INFO][2021-09-01 17:28:09]	testset-------------: length 5000
[INFO][2021-09-01 17:28:09]	Start to build model
[DEBUG][2021-09-01 17:28:09]	Backbone [resnet34] is declared with cin [1] and cout [1000] [with] sobel
[DEBUG][2021-09-01 17:28:09]	Backbone will be created wit the following heads: [10, 10]
[DEBUG][2021-09-01 17:28:09]	Number of trainable parameters is [112]
[DEBUG][2021-09-01 17:28:09]	Number of frozen parameters is [2]
[DEBUG][2021-09-01 17:28:09]	Name of frozen parameters are: dict_keys(['sobel.0.weight', 'sobel.0.bias'])
[DEBUG][2021-09-01 17:28:09]	Going to use [Adam] optimizer for training with betas (0.9, 0.999), eps 0.000000, weight decay 0.000000 without amsgrad
[DEBUG][2021-09-01 17:28:09]	Going to use [fixed] learning policy for optimization with base learning rate [0.00001]
[INFO][2021-09-01 17:28:10]	Start to resume session for file: [sessions/pickle10/checkpoint/latest.ckpt]
[DEBUG][2021-09-01 17:28:10]	Totally loaded [222] parameters
[INFO][2021-09-01 17:28:10]	Data parallel will be used for acceleration purpose
[INFO][2021-09-01 17:28:10]	Start to train at 31 epoch with learning rate 0.000010
[INFO][2021-09-01 17:28:10]	cfg.net_heads: {cfg.net_heads}
[INFO][2021-09-01 17:28:10]	hidx, head: 0, 10
[INFO][2021-09-01 17:28:10]	hidx, head: 1, 10
[INFO][2021-09-01 17:28:10]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-09-01 17:29:03]	Batch: [  0/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:00:53/4:36:55] Time: 53.084 (53.084) Data: 41.123 (41.123) Loss: 1.5259 (1.5259)
[INFO][2021-09-01 17:33:01]	Batch: [ 30/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:04:51/0:49:02] Time: 13.868 (9.401) Data: 11.578 (6.749) Loss: 1.5713 (1.5421)
[INFO][2021-09-01 17:37:06]	Batch: [ 60/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:08:56/0:45:54] Time: 14.053 (8.799) Data: 11.652 (6.291) Loss: 1.5305 (1.5431)
[INFO][2021-09-01 17:41:11]	Batch: [ 90/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:13:01/0:44:48] Time: 13.937 (8.588) Data: 11.526 (6.125) Loss: 1.5122 (1.5414)
[INFO][2021-09-01 17:45:16]	Batch: [120/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:17:06/0:44:15] Time: 13.948 (8.484) Data: 11.549 (6.041) Loss: 1.5672 (1.5417)
[INFO][2021-09-01 17:49:21]	Batch: [150/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:21:11/0:43:55] Time: 14.033 (8.420) Data: 11.633 (5.997) Loss: 1.5232 (1.5420)
[INFO][2021-09-01 17:53:26]	Batch: [180/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:25:16/0:43:41] Time: 13.923 (8.376) Data: 11.631 (5.964) Loss: 1.5292 (1.5430)
[INFO][2021-09-01 17:57:30]	Batch: [210/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:29:20/0:43:31] Time: 13.921 (8.344) Data: 11.633 (5.944) Loss: 1.5541 (1.5447)
[INFO][2021-09-01 18:01:35]	Batch: [240/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:33:25/0:43:24] Time: 14.021 (8.322) Data: 11.733 (5.931) Loss: 1.5232 (1.5451)
[INFO][2021-09-01 18:05:40]	Batch: [270/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:37:30/0:43:19] Time: 14.085 (8.304) Data: 11.684 (5.920) Loss: 1.5592 (1.5451)
[INFO][2021-09-01 18:09:45]	Batch: [300/313] Head: [0/2] Epoch: [ 31/350] Progress: [0:41:35/0:43:14] Time: 13.929 (8.290) Data: 11.639 (5.910) Loss: 1.5309 (1.5453)
[INFO][2021-09-01 18:11:15]	train_head-------------: otrainset=20000, ptrainset=20000
[INFO][2021-09-01 18:11:34]	Batch: [  0/313] Head: [1/2] Epoch: [ 31/350] Progress: [0:00:18/1:38:34] Time: 18.896 (18.896) Data: 16.583 (16.583) Loss: 1.5292 (1.5292)
[INFO][2021-09-01 18:15:39]	Batch: [ 30/313] Head: [1/2] Epoch: [ 31/350] Progress: [0:04:23/0:44:19] Time: 13.938 (8.498) Data: 11.652 (6.155) Loss: 1.5758 (1.5507)
[INFO][2021-09-01 18:19:44]	Batch: [ 60/313] Head: [1/2] Epoch: [ 31/350] Progress: [0:08:28/0:43:28] Time: 13.932 (8.335) Data: 11.643 (5.992) Loss: 1.5263 (1.5478)
[INFO][2021-09-01 18:23:49]	Batch: [ 90/313] Head: [1/2] Epoch: [ 31/350] Progress: [0:12:33/0:43:11] Time: 14.026 (8.280) Data: 11.627 (5.934) Loss: 1.5324 (1.5468)
[INFO][2021-09-01 18:27:54]	Batch: [120/313] Head: [1/2] Epoch: [ 31/350] Progress: [0:16:38/0:43:03] Time: 13.936 (8.253) Data: 11.640 (5.901) Loss: 1.5581 (1.5463)
[INFO][2021-09-01 18:31:59]	Batch: [150/313] Head: [1/2] Epoch: [ 31/350] Progress: [0:20:43/0:42:57] Time: 13.408 (8.236) Data: 11.008 (5.883) Loss: 1.5254 (1.5460)
