[DEBUG][2021-08-09 19:31:51]	TFboard files will be stored in sessions/20210809-193151/tfboard if applicable
[DEBUG][2021-08-09 19:31:51]	Provided arguments will be stored in sessions/20210809-193151/config.yaml
[INFO][2021-08-09 19:31:51]	Start to declare training variable
[INFO][2021-08-09 19:31:51]	Session will be ran in device: [cuda]
[INFO][2021-08-09 19:31:51]	Start to prepare data
[INFO][2021-08-09 19:31:51]	otrainset-------------
[INFO][2021-08-09 19:31:52]	5000
[INFO][2021-08-09 19:31:52]	ptrainset-------------
[INFO][2021-08-09 19:31:52]	5000
[INFO][2021-08-09 19:31:52]	testset-------------
[INFO][2021-08-09 19:31:52]	5000
[INFO][2021-08-09 19:31:52]	Start to build model
[DEBUG][2021-08-09 19:31:52]	Backbone [resnet34] is declared with cin [1] and cout [1000] [with] sobel
[DEBUG][2021-08-09 19:31:52]	Backbone will be created wit the following heads: [20, 6]
[DEBUG][2021-08-09 19:31:52]	Number of trainable parameters is [112]
[DEBUG][2021-08-09 19:31:52]	Number of frozen parameters is [2]
[DEBUG][2021-08-09 19:31:52]	Name of frozen parameters are: dict_keys(['sobel.0.weight', 'sobel.0.bias'])
[DEBUG][2021-08-09 19:31:52]	Going to use [Adam] optimizer for training with betas (0.9, 0.999), eps 0.000000, weight decay 0.000000 without amsgrad
[DEBUG][2021-08-09 19:31:52]	Going to use [fixed] learning policy for optimization with base learning rate [0.00001]
[INFO][2021-08-09 19:31:52]	Start to resume session for file: [sessions/0807binary/checkpoint/latest.ckpt]
[DEBUG][2021-08-09 19:31:52]	Totally loaded [222] parameters
[INFO][2021-08-09 19:31:52]	Data parallel will be used for acceleration purpose
[INFO][2021-08-09 19:31:52]	Start to evaluate after 350 epoch of training
[INFO][2021-08-09 19:31:52]	len(loader.dataset)
[INFO][2021-08-09 19:31:52]	5000
