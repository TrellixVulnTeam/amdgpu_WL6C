[DEBUG][2021-08-09 20:52:47]	TFboard files will be stored in sessions/20210809-205247/tfboard if applicable
[DEBUG][2021-08-09 20:52:47]	Provided arguments will be stored in sessions/20210809-205247/config.yaml
[INFO][2021-08-09 20:52:47]	Start to declare training variable
[INFO][2021-08-09 20:52:47]	Session will be ran in device: [cuda]
[INFO][2021-08-09 20:52:47]	Start to prepare data
[INFO][2021-08-09 20:52:47]	otrainset-------------
[INFO][2021-08-09 20:52:47]	5000
[INFO][2021-08-09 20:52:47]	ptrainset-------------
[INFO][2021-08-09 20:52:48]	5000
[INFO][2021-08-09 20:52:48]	testset-------------
[INFO][2021-08-09 20:52:48]	5000
[INFO][2021-08-09 20:52:48]	Start to build model
[DEBUG][2021-08-09 20:52:48]	Backbone [resnet34] is declared with cin [1] and cout [1000] [with] sobel
[DEBUG][2021-08-09 20:52:48]	Backbone will be created wit the following heads: [20, 6]
[DEBUG][2021-08-09 20:52:48]	Number of trainable parameters is [112]
[DEBUG][2021-08-09 20:52:48]	Number of frozen parameters is [2]
[DEBUG][2021-08-09 20:52:48]	Name of frozen parameters are: dict_keys(['sobel.0.weight', 'sobel.0.bias'])
[DEBUG][2021-08-09 20:52:48]	Going to use [Adam] optimizer for training with betas (0.9, 0.999), eps 0.000000, weight decay 0.000000 without amsgrad
[DEBUG][2021-08-09 20:52:48]	Going to use [fixed] learning policy for optimization with base learning rate [0.00001]
[INFO][2021-08-09 20:52:48]	Start to resume session for file: [sessions/0807binary/checkpoint/latest.ckpt]
[DEBUG][2021-08-09 20:52:48]	Totally loaded [222] parameters
[INFO][2021-08-09 20:52:48]	Data parallel will be used for acceleration purpose
[INFO][2021-08-09 20:52:48]	Start to evaluate after 350 epoch of training
[INFO][2021-08-09 20:53:18]	num_classes
[INFO][2021-08-09 20:53:18]	6
